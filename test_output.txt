Makefile:181: warning: overriding commands for target `test-health'
Makefile:120: warning: ignoring old commands for target `test-health'
âš¡ Running fast tests in parallel...
ðŸ“Š Test breakdown:
   â€¢ Total tests: 2424
   â€¢ Fast tests: 2266 (93.5%)
   â€¢ Excluded: 158 (6.5% - slow/benchmark)

ðŸ”„ Starting test execution with limited parallelism...
/Users/alvaro/Documents/Code/flujo/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.
  warner(PytestBenchmarkWarning(text))
bringing up nodes...
bringing up nodes...

.................F.FF..F........F..............................F....F... [  3%]
............F.F......................................................... [  6%]
.................F...F.F.F....F..F.....FF.F...FFF......F.F..F.F.......F. [  9%]
FFFFF.FFFF.......F.F............F....F...............F.....F.......F.... [ 12%]
........F...F.............F....F.......FF............................... [ 15%]
..............................F.F..F...F.Fs......F.......F.......F...... [ 18%]
........................................................................ [ 21%]
..........F..F.......................................................... [ 25%]
..........F.F...........F.F......F..F....................F.F.F.F........ [ 28%]
......F.....F...........................................F..............F [ 31%]
...................................................................F..s. [ 34%]
........................................................................ [ 37%]
.............F.......................................................... [ 40%]
...............F.............................................F.......... [ 43%]
........................................................................ [ 46%]
................................FFF........F............................ [ 50%]
..F.......................F..F........F.....................F........... [ 53%]
........................................................................ [ 56%]
........................................................................ [ 59%]
.....................FF...........F..................................... [ 62%]
.............................F.F........................................ [ 65%]
...............................................s........F............... [ 68%]
................................................FF..F..........F....F.F. [ 71%]
...........F.....F...F....................................F............. [ 75%]
..F.F..............................................F.................... [ 78%]
...F....F............................................................... [ 81%]
........................................................................ [ 84%]
.......................F...............F.................s.............. [ 87%]
...............F.FF.F........F...................FFFFFFF.............F.. [ 90%]
........F...F...............................................F...FF..F... [ 93%]
............F................F.F............F...F.....s..F.............. [ 97%]
....................FF....F.FF..FFFFFFFFF............................    [100%]
==================================== ERRORS ====================================
______________ ERROR collecting tests/utils/test_serialization.py ______________
import file mismatch:
imported module 'test_serialization' has this __file__ attribute:
  /Users/alvaro/Documents/Code/flujo/tests/benchmarks/test_serialization.py
which is not the same as the test file we want to collect:
  /Users/alvaro/Documents/Code/flujo/tests/utils/test_serialization.py
HINT: remove __pycache__ / .pyc files and/or use a unique basename for your test file modules
=================================== FAILURES ===================================
_ TestExecutorCoreHITLStepMigration.test_handle_hitl_step_context_preservation _
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_hitl_step_migration.py:244: in test_handle_hitl_step_context_preservation
    assert mock_context.scratchpad["existing_key"] == "existing_value"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   KeyError: 'existing_key'
___________________ test_fsd11_context_aware_agent_explicit ____________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_FSD11_bug_fix.py:154: in test_fsd11_context_aware_agent_explicit
    assert isinstance(step_result.output, FSD11TestOutput)
E   assert False
E    +  where False = isinstance("Mock response to: User test_user: {'message': 'Hello, how are you?'}", FSD11TestOutput)
E    +    where "Mock response to: User test_user: {'message': 'Hello, how are you?'}" = StepResult(name='context_aware_agent', output="Mock response to: User test_user: {'message': 'Hello, how are you?'}", ...h_context=FSD11TestContext(user_id='test_user', session_id='test_session', metadata={}), metadata_={}, step_history=[]).output
__ TestExecutorCoreHITLStepMigration.test_handle_hitl_step_context_isolation ___
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_hitl_step_migration.py:313: in test_handle_hitl_step_context_isolation
    assert mock_context.scratchpad[key] == value
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   KeyError: 'key1'
____________________ test_fsd11_context_aware_agent_kwargs _____________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_FSD11_bug_fix.py:197: in test_fsd11_context_aware_agent_kwargs
    assert isinstance(step_result.output, FSD11TestOutput)
E   assert False
E    +  where False = isinstance("Mock response to: User test_user: {'message': 'Hello, how are you?'}", FSD11TestOutput)
E    +    where "Mock response to: User test_user: {'message': 'Hello, how are you?'}" = StepResult(name='kwargs_context_agent', output="Mock response to: User test_user: {'message': 'Hello, how are you?'}",...h_context=FSD11TestContext(user_id='test_user', session_id='test_session', metadata={}), metadata_={}, step_history=[]).output
__________ TestExecutorCoreSimpleStep.test_plugin_failure_propagates ___________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core.py:467: in test_plugin_failure_propagates
    assert result.attempts == 3  # 3 attempts total
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert 1 == 3
E    +  where 1 = StepResult(name='test_step', output=PluginOutcome(success=False, feedback='Plugin execution error', redirect_to=None, ...00125, feedback='Plugin validation failed: Plugin execution error', branch_context=None, metadata_={}, step_history=[]).attempts
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:05,280 - flujo - INFO - Extracted tokens for step 'test_step': prompt=10, completion=5
2025-08-05 14:57:05,280 - flujo - INFO - Extracted model ID for step 'test_step' from 'model_id': openai:gpt-4o
2025-08-05 14:57:05,280 - flujo - INFO - CostCalculator: provider=openai, model=gpt-4o, pricing=prompt_tokens_per_1k=0.005 completion_tokens_per_1k=0.015 price_per_image_standard_1024x1024=None price_per_image_hd_1024x1024=None price_per_image_standard_1792x1024=None price_per_image_hd_1792x1024=None price_per_image_standard_1024x1792=None price_per_image_hd_1024x1792=None
2025-08-05 14:57:05,280 - flujo - INFO - Cost calculation: prompt_cost=5e-05, completion_cost=7.5e-05, total=0.000125
2025-08-05 14:57:05,280 - flujo - INFO - Calculated cost for step 'test_step': 0.000125 USD for model gpt-4o
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:05,281 - flujo - ERROR - Step 'test_step' plugin failed after 1 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Extracted tokens for step 'test_step': prompt=10, completion=5
INFO     flujo:telemetry.py:54 Extracted model ID for step 'test_step' from 'model_id': openai:gpt-4o
INFO     flujo:telemetry.py:54 CostCalculator: provider=openai, model=gpt-4o, pricing=prompt_tokens_per_1k=0.005 completion_tokens_per_1k=0.015 price_per_image_standard_1024x1024=None price_per_image_hd_1024x1024=None price_per_image_standard_1792x1024=None price_per_image_hd_1792x1024=None price_per_image_standard_1024x1792=None price_per_image_hd_1024x1792=None
INFO     flujo:telemetry.py:54 Cost calculation: prompt_cost=5e-05, completion_cost=7.5e-05, total=0.000125
INFO     flujo:telemetry.py:54 Calculated cost for step 'test_step': 0.000125 USD for model gpt-4o
ERROR    flujo:telemetry.py:54 Step 'test_step' plugin failed after 1 attempts
_ TestExecutorCoreLoopStepDispatch.test_execute_complex_step_loopstep_telemetry_logging _
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_loop_step_dispatch.py:174: in test_execute_complex_step_loopstep_telemetry_logging
    assert any("Handling LoopStep" in call for call in debug_calls)
E   assert False
E    +  where False = any(<generator object TestExecutorCoreLoopStepDispatch.test_execute_complex_step_loopstep_telemetry_logging.<locals>.<genexpr> at 0x1121a32a0>)
__________ TestLoopStepMigration.test_handle_loop_step_max_iterations __________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_loop_step_migration.py:152: in test_handle_loop_step_max_iterations
    assert result.attempts == 3  # max_retries (1 initial + 2 retries)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert 2 == 3
E    +  where 2 = StepResult(name='test_loop', output=None, success=False, attempts=2, latency_s=0.0008920829859562218, token_counts=10,... original_value=None), metadata_={'iterations': 2, 'exit_reason': 'max_iterations_with_body_failure'}, step_history=[]).attempts
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === test_loop
2025-08-05 14:57:05,480 - flujo - INFO - LoopStep 'test_loop': Starting Iteration 1/2
2025-08-05 14:57:05,480 - flujo - INFO - Using explicit cost from 'CostlyOutput' for step 'test_step': cost=$0.1, tokens=10
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] source_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'counter': 0, 'messages': [], 'data': {}, 'original_value': None}
[DEBUG] Processing field: counter
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: counter
[DEBUG] Processing field: messages
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: messages
[DEBUG] No new items to add to list field: messages
[DEBUG] Processing field: data
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: data
[DEBUG] Processing field: original_value
[DEBUG] current_value: None
[DEBUG] actual_source_value: None
[DEBUG] Field unchanged: original_value
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:05,480 - flujo - INFO - LoopStep 'test_loop': Starting Iteration 2/2
2025-08-05 14:57:05,480 - flujo - WARNING - Step 'test_step' agent execution attempt 1 failed: No more outputs available
2025-08-05 14:57:05,480 - flujo - WARNING - Step 'test_step' agent execution attempt 2 failed: No more outputs available
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] source_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'counter': 0, 'messages': [], 'data': {}, 'original_value': None}
[DEBUG] Processing field: counter
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: counter
[DEBUG] Processing field: messages
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: messages
[DEBUG] No new items to add to list field: messages
[DEBUG] Processing field: data
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: data
[DEBUG] Processing field: original_value
[DEBUG] current_value: None
[DEBUG] actual_source_value: None
[DEBUG] Field unchanged: original_value
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:05,481 - flujo - ERROR - Step 'test_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'test_loop': Starting Iteration 1/2
INFO     flujo:telemetry.py:54 Using explicit cost from 'CostlyOutput' for step 'test_step': cost=$0.1, tokens=10
INFO     flujo:telemetry.py:54 LoopStep 'test_loop': Starting Iteration 2/2
WARNING  flujo:telemetry.py:54 Step 'test_step' agent execution attempt 1 failed: No more outputs available
WARNING  flujo:telemetry.py:54 Step 'test_step' agent execution attempt 2 failed: No more outputs available
ERROR    flujo:telemetry.py:54 Step 'test_step' agent failed after 3 attempts
___________ TestLoopStepMigration.test_handle_loop_step_cost_limits ____________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_loop_step_migration.py:403: in test_handle_loop_step_cost_limits
    with pytest.raises(UsageLimitExceededError):
E   Failed: DID NOT RAISE <class 'flujo.exceptions.UsageLimitExceededError'>
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === test_loop
2025-08-05 14:57:05,507 - flujo - INFO - LoopStep 'test_loop': Starting Iteration 1/3
[DEBUG] Iteration 1: Checking usage limits before iteration - current cost: 0.0, prospective cost: 0.0, limit: 1.0
[DEBUG] Iteration 1: Usage limits check passed before iteration
2025-08-05 14:57:05,507 - flujo - INFO - Using explicit cost from 'CostlyOutput' for step 'expensive_step': cost=$0.6, tokens=10
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] source_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'counter': 0, 'messages': [], 'data': {}, 'original_value': None}
[DEBUG] Processing field: counter
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: counter
[DEBUG] Processing field: messages
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: messages
[DEBUG] No new items to add to list field: messages
[DEBUG] Processing field: data
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: data
[DEBUG] Processing field: original_value
[DEBUG] current_value: None
[DEBUG] actual_source_value: None
[DEBUG] Field unchanged: original_value
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:05,507 - flujo - INFO - LoopStep 'test_loop': Starting Iteration 2/3
[DEBUG] Iteration 2: Checking usage limits before iteration - current cost: 0.6, prospective cost: 1.2, limit: 1.0
[DEBUG] Iteration 2: Usage limits would be breached - stopping before iteration
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:05,507 - flujo - ERROR - UsageLimitExceededError in LoopStep 'test_loop': Cost limit would be exceeded
2025-08-05 14:57:05,507 - flujo - ERROR - UsageLimitExceededError in LoopStep 'test_loop': Cost limit of $1 exceeded
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'test_loop': Starting Iteration 1/3
INFO     flujo:telemetry.py:54 Using explicit cost from 'CostlyOutput' for step 'expensive_step': cost=$0.6, tokens=10
INFO     flujo:telemetry.py:54 LoopStep 'test_loop': Starting Iteration 2/3
ERROR    flujo:telemetry.py:54 UsageLimitExceededError in LoopStep 'test_loop': Cost limit would be exceeded
ERROR    flujo:telemetry.py:54 UsageLimitExceededError in LoopStep 'test_loop': Cost limit of $1 exceeded
___________ TestLoopStepMigration.test_handle_loop_step_token_limits ___________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_loop_step_migration.py:426: in test_handle_loop_step_token_limits
    with pytest.raises(UsageLimitExceededError):
E   Failed: DID NOT RAISE <class 'flujo.exceptions.UsageLimitExceededError'>
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === test_loop
2025-08-05 14:57:05,514 - flujo - INFO - LoopStep 'test_loop': Starting Iteration 1/3
[DEBUG] Iteration 1: Checking usage limits before iteration - current cost: 0.0, prospective cost: 0.0, limit: None
[DEBUG] Iteration 1: Usage limits check passed before iteration
2025-08-05 14:57:05,514 - flujo - INFO - Using explicit cost from 'CostlyOutput' for step 'token_heavy_step': cost=$0.1, tokens=60
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] source_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'counter': 0, 'messages': [], 'data': {}, 'original_value': None}
[DEBUG] Processing field: counter
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: counter
[DEBUG] Processing field: messages
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: messages
[DEBUG] No new items to add to list field: messages
[DEBUG] Processing field: data
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: data
[DEBUG] Processing field: original_value
[DEBUG] current_value: None
[DEBUG] actual_source_value: None
[DEBUG] Field unchanged: original_value
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:05,514 - flujo - INFO - LoopStep 'test_loop': Starting Iteration 2/3
[DEBUG] Iteration 2: Checking usage limits before iteration - current cost: 0.1, prospective cost: 0.2, limit: None
[DEBUG] Iteration 2: Usage limits check passed before iteration
2025-08-05 14:57:05,515 - flujo - INFO - Using explicit cost from 'CostlyOutput' for step 'token_heavy_step': cost=$0.1, tokens=60
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] source_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'counter': 0, 'messages': [], 'data': {}, 'original_value': None}
[DEBUG] Processing field: counter
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: counter
[DEBUG] Processing field: messages
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: messages
[DEBUG] No new items to add to list field: messages
[DEBUG] Processing field: data
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: data
[DEBUG] Processing field: original_value
[DEBUG] current_value: None
[DEBUG] actual_source_value: None
[DEBUG] Field unchanged: original_value
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:05,515 - flujo - INFO - LoopStep 'test_loop': Starting Iteration 3/3
[DEBUG] Iteration 3: Checking usage limits before iteration - current cost: 0.2, prospective cost: 0.30000000000000004, limit: None
[DEBUG] Iteration 3: Usage limits check passed before iteration
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] source_context type: <class 'test_executor_core_loop_step_migration.LoopTestContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'counter': 0, 'messages': [], 'data': {}, 'original_value': None}
[DEBUG] Processing field: counter
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: counter
[DEBUG] Processing field: messages
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: messages
[DEBUG] No new items to add to list field: messages
[DEBUG] Processing field: data
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: data
[DEBUG] Processing field: original_value
[DEBUG] current_value: None
[DEBUG] actual_source_value: None
[DEBUG] Field unchanged: original_value
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'test_loop': Starting Iteration 1/3
INFO     flujo:telemetry.py:54 Using explicit cost from 'CostlyOutput' for step 'token_heavy_step': cost=$0.1, tokens=60
INFO     flujo:telemetry.py:54 LoopStep 'test_loop': Starting Iteration 2/3
INFO     flujo:telemetry.py:54 Using explicit cost from 'CostlyOutput' for step 'token_heavy_step': cost=$0.1, tokens=60
INFO     flujo:telemetry.py:54 LoopStep 'test_loop': Starting Iteration 3/3
____ TestExecutorCoreConditionalStep.test_handle_conditional_step_signature ____
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_conditional_step.py:54: in test_handle_conditional_step_signature
    assert params == expected_params
E   AssertionError: assert ['step', 'dat..._setter', ...] == ['conditional...ntext_setter']
E
E     At index 0 diff: 'step' != 'conditional_step'
E     Left contains one more item: 'fallback_depth'
E
E     Full diff:
E       [
E     -     'conditional_step',
E     +     'step',
E           'data',
E           'context',
E           'resources',
E           'limits',
E           'context_setter',
E     +     'fallback_depth',
E       ]
_ TestExecutorCoreConditionalStep.test_handle_conditional_step_parameter_passing _
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_conditional_step.py:159: in test_handle_conditional_step_parameter_passing
    assert call_args[0][0] == mock_step  # step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert ExecutionFrame(step=<Mock spec='Step' id='4616419856'>, data='test_data', context=<Mock id='4616407248'>, resources=<M... stream=False, on_chunk=None, breach_event=None, context_setter=<Mock id='4616410128'>, result=None, _fallback_depth=0) == <Mock spec='Step' id='4616419856'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:05,739 - flujo - INFO - Condition evaluated to branch key 'branch_a'
2025-08-05 14:57:05,739 - flujo - INFO - Executing branch for key 'branch_a'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'unittest.mock.Mock'>
[DEBUG] source_context type: <class 'unittest.mock.Mock'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: <Mock name='mock.model_dump()' id='4595139344'>
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:05,740 - flujo.utils.context - ERROR - Failed to merge context updates: 'Mock' object is not iterable
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Condition evaluated to branch key 'branch_a'
INFO     flujo:telemetry.py:54 Executing branch for key 'branch_a'
ERROR    flujo.utils.context:context.py:276 Failed to merge context updates: 'Mock' object is not iterable
_ TestExecutorCoreConditionalStep.test_handle_conditional_step_with_limits_and_context_setter _
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_conditional_step.py:216: in test_handle_conditional_step_with_limits_and_context_setter
    test_context_setter.assert_called_once()
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/unittest/mock.py:902: in assert_called_once
    raise AssertionError(msg)
E   AssertionError: Expected 'mock' to have been called once. Called 0 times.
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:05,747 - flujo - INFO - Condition evaluated to branch key 'branch_a'
2025-08-05 14:57:05,748 - flujo - INFO - Executing branch for key 'branch_a'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'dict'>
[DEBUG] source_context type: <class 'dict'>
[DEBUG] excluded_fields: {'command_log'}
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:05,748 - flujo.utils.context - ERROR - Failed to merge context updates: 'dict' object has no attribute '__dict__'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Condition evaluated to branch key 'branch_a'
INFO     flujo:telemetry.py:54 Executing branch for key 'branch_a'
ERROR    flujo.utils.context:context.py:276 Failed to merge context updates: 'dict' object has no attribute '__dict__'
_ TestExecutorCoreConditionalStep.test_handle_conditional_step_integration_with_execute_complex_step _
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_conditional_step.py:261: in test_handle_conditional_step_integration_with_execute_complex_step
    assert result.name == "test_conditional"
E   AssertionError: assert 'test_agent' == 'test_conditional'
E
E     - test_conditional
E     + test_agent
_ TestExecutorCoreConditionalStepDispatch.test_execute_complex_step_conditionalstep_telemetry_logging _
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_conditional_step_dispatch.py:172: in test_execute_complex_step_conditionalstep_telemetry_logging
    assert any("Handling ConditionalStep" in call for call in debug_calls)
E   assert False
E    +  where False = any(<generator object TestExecutorCoreConditionalStepDispatch.test_execute_complex_step_conditionalstep_telemetry_logging.<locals>.<genexpr> at 0x1134b5f20>)
____ TestExecutorCoreConditionalStepLogic.test_branch_not_found_no_default _____
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_conditional_step_logic.py:96: in test_branch_not_found_no_default
    assert "No branch found for key 'nonexistent_branch'" in result.feedback
E   assert "No branch found for key 'nonexistent_branch'" in "No branch matches condition 'nonexistent_branch' and no default branch provided"
E    +  where "No branch matches condition 'nonexistent_branch' and no default branch provided" = StepResult(name='test_conditional', output='test_data', success=False, attempts=1, latency_s=0.00024929200299084187, t...hes condition 'nonexistent_branch' and no default branch provided", branch_context=None, metadata_={}, step_history=[]).feedback
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:05,810 - flujo - WARNING - No branch matches condition 'nonexistent_branch' and no default branch provided
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 No branch matches condition 'nonexistent_branch' and no default branch provided
___ TestExecutorCoreConditionalStepLogic.test_branch_output_mapper_exception ___
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_conditional_step_logic.py:237: in test_branch_output_mapper_exception
    assert "Branch output mapper raised an exception" in result.feedback
E   AssertionError: assert 'Branch output mapper raised an exception' in 'Error executing conditional logic or branch: Mapper failed'
E    +  where 'Error executing conditional logic or branch: Mapper failed' = StepResult(name='test_conditional', output=None, success=False, attempts=1, latency_s=0.00022187497233971953, token_co...l logic or branch: Mapper failed', branch_context=None, metadata_={'executed_branch_key': 'branch_a'}, step_history=[]).feedback
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:05,827 - flujo - INFO - Condition evaluated to branch key 'branch_a'
2025-08-05 14:57:05,827 - flujo - INFO - Executing branch for key 'branch_a'
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:05,827 - flujo - ERROR - Error in conditional step 'test_conditional': Mapper failed
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Condition evaluated to branch key 'branch_a'
INFO     flujo:telemetry.py:54 Executing branch for key 'branch_a'
ERROR    flujo:telemetry.py:54 Error in conditional step 'test_conditional': Mapper failed
________ TestExecutorCoreConditionalStepLogic.test_metrics_accumulation ________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_conditional_step_logic.py:264: in test_metrics_accumulation
    assert result.latency_s == 1.5
E   AssertionError: assert 0.00022445799550041556 == 1.5
E    +  where 0.00022445799550041556 = StepResult(name='test_conditional', output='test_output', success=True, attempts=1, latency_s=0.00022445799550041556, ...data', scratchpad={}, hitl_history=[], command_log=[]), metadata_={'executed_branch_key': 'branch_a'}, step_history=[]).latency_s
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:05,833 - flujo - INFO - Condition evaluated to branch key 'branch_a'
2025-08-05 14:57:05,833 - flujo - INFO - Executing branch for key 'branch_a'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Condition evaluated to branch key 'branch_a'
INFO     flujo:telemetry.py:54 Executing branch for key 'branch_a'
__ TestExecutorCoreConditionalStepLogic.test_context_setter_called_on_success __
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_conditional_step_logic.py:309: in test_context_setter_called_on_success
    mock_context_setter.assert_called_once()
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/unittest/mock.py:902: in assert_called_once
    raise AssertionError(msg)
E   AssertionError: Expected 'mock' to have been called once. Called 0 times.
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:05,840 - flujo - INFO - Condition evaluated to branch key 'branch_a'
2025-08-05 14:57:05,840 - flujo - INFO - Executing branch for key 'branch_a'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'dict'>
[DEBUG] source_context type: <class 'dict'>
[DEBUG] excluded_fields: {'command_log'}
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:05,840 - flujo.utils.context - ERROR - Failed to merge context updates: 'dict' object has no attribute '__dict__'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Condition evaluated to branch key 'branch_a'
INFO     flujo:telemetry.py:54 Executing branch for key 'branch_a'
ERROR    flujo.utils.context:context.py:276 Failed to merge context updates: 'dict' object has no attribute '__dict__'
__ TestExecutorCoreConditionalStepLogic.test_branch_execution_with_resources ___
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_conditional_step_logic.py:415: in test_branch_execution_with_resources
    assert call_args[1]["resources"] == resources
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   KeyError: 'resources'
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:05,869 - flujo - INFO - Condition evaluated to branch key 'branch_a'
2025-08-05 14:57:05,869 - flujo - INFO - Executing branch for key 'branch_a'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Condition evaluated to branch key 'branch_a'
INFO     flujo:telemetry.py:54 Executing branch for key 'branch_a'
____ TestExecutorCoreConditionalStepLogic.test_branch_execution_with_limits ____
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_conditional_step_logic.py:441: in test_branch_execution_with_limits
    assert call_args[1]["limits"] == limits
           ^^^^^^^^^^^^^^^^^^^^^^
E   KeyError: 'limits'
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:05,874 - flujo - INFO - Condition evaluated to branch key 'branch_a'
2025-08-05 14:57:05,874 - flujo - INFO - Executing branch for key 'branch_a'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Condition evaluated to branch key 'branch_a'
INFO     flujo:telemetry.py:54 Executing branch for key 'branch_a'
_____________________ test_resume_after_crash_file_backend _____________________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_crash_recovery.py:91: in test_resume_after_crash_file_backend
    assert crash_state["current_step_index"] == 1
E   assert 0 == 1
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:05,565 - flujo - INFO - Logfire telemetry is disabled or failed to initialize. Using standard Python logging.
2025-08-05 14:57:05,800 - flujo - INFO - Counting string output as 1 token for step 'transform': 'middle'
__________ TestExecutorCoreFallback.test_fallback_with_none_feedback ___________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:410: in test_fallback_with_none_feedback
    assert result.success is True
E   AssertionError: assert <AsyncMock name='mock.get().success' id='4616466768'> is True
E    +  where <AsyncMock name='mock.get().success' id='4616466768'> = <AsyncMock name='mock.get()' id='4616250768'>.success
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:05,926 - flujo - WARNING - Step 'primary_step' agent execution attempt 1 failed: Primary failed
2025-08-05 14:57:05,926 - flujo - WARNING - Step 'primary_step' agent execution attempt 2 failed: Primary failed
2025-08-05 14:57:05,927 - flujo - INFO - Step 'primary_step' failed, attempting fallback
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:05,926 - flujo - ERROR - Step 'primary_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 1 failed: Primary failed
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 2 failed: Primary failed
ERROR    flujo:telemetry.py:54 Step 'primary_step' agent failed after 3 attempts
INFO     flujo:telemetry.py:54 Step 'primary_step' failed, attempting fallback
___________ TestExecutorCoreFallback.test_fallback_with_usage_limits ___________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:491: in test_fallback_with_usage_limits
    assert result.success is True
E   AssertionError: assert <AsyncMock name='mock.get().success' id='4614023568'> is True
E    +  where <AsyncMock name='mock.get().success' id='4614023568'> = <AsyncMock name='mock.get()' id='4614545424'>.success
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,005 - flujo - WARNING - Step 'primary_step' agent execution attempt 1 failed: Primary failed
2025-08-05 14:57:06,005 - flujo - WARNING - Step 'primary_step' agent execution attempt 2 failed: Primary failed
2025-08-05 14:57:06,006 - flujo - INFO - Step 'primary_step' failed, attempting fallback
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,006 - flujo - ERROR - Step 'primary_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 1 failed: Primary failed
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 2 failed: Primary failed
ERROR    flujo:telemetry.py:54 Step 'primary_step' agent failed after 3 attempts
INFO     flujo:telemetry.py:54 Step 'primary_step' failed, attempting fallback
_________ TestExecutorCoreFallback.test_fallback_metadata_preservation _________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:628: in test_fallback_metadata_preservation
    assert result.success is True
E   AssertionError: assert <AsyncMock name='mock.get().success' id='4617096080'> is True
E    +  where <AsyncMock name='mock.get().success' id='4617096080'> = <AsyncMock name='mock.get()' id='4618563984'>.success
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,037 - flujo - WARNING - Step 'primary_step' agent execution attempt 1 failed: Primary failed
2025-08-05 14:57:06,037 - flujo - WARNING - Step 'primary_step' agent execution attempt 2 failed: Primary failed
2025-08-05 14:57:06,037 - flujo - INFO - Step 'primary_step' failed, attempting fallback
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,037 - flujo - ERROR - Step 'primary_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 1 failed: Primary failed
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 2 failed: Primary failed
ERROR    flujo:telemetry.py:54 Step 'primary_step' agent failed after 3 attempts
INFO     flujo:telemetry.py:54 Step 'primary_step' failed, attempting fallback
_______ TestExecutorCoreFallback.test_fallback_with_critical_exceptions ________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:679: in test_fallback_with_critical_exceptions
    with pytest.raises(UsageLimitExceededError):
E   Failed: DID NOT RAISE <class 'flujo.exceptions.UsageLimitExceededError'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,061 - flujo - WARNING - Step 'primary_step' agent execution attempt 1 failed: Cost limit exceeded
2025-08-05 14:57:06,061 - flujo - WARNING - Step 'primary_step' agent execution attempt 2 failed: Cost limit exceeded
2025-08-05 14:57:06,062 - flujo - INFO - Step 'primary_step' failed, attempting fallback
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,062 - flujo - ERROR - Step 'primary_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 1 failed: Cost limit exceeded
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 2 failed: Cost limit exceeded
ERROR    flujo:telemetry.py:54 Step 'primary_step' agent failed after 3 attempts
INFO     flujo:telemetry.py:54 Step 'primary_step' failed, attempting fallback
_________ TestExecutorCoreFallback.test_fallback_with_multiple_retries _________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:1031: in test_fallback_with_multiple_retries
    assert result.attempts == 5  # Should show all attempts were made (1 initial + 3 retries + 1 fallback)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert 4 == 5
E    +  where 4 = StepResult(name='fallback_step', output='fallback success', success=True, attempts=4, latency_s=0.10023279199376703, t...riggered': True, 'original_error': 'Agent execution failed with Exception: Primary failed attempt 3'}, step_history=[]).attempts
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,125 - flujo - WARNING - Step 'primary_step' agent execution attempt 1 failed: Primary failed attempt 1
2025-08-05 14:57:06,125 - flujo - WARNING - Step 'primary_step' agent execution attempt 2 failed: Primary failed attempt 2
2025-08-05 14:57:06,125 - flujo - INFO - Step 'primary_step' failed, attempting fallback
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,125 - flujo - ERROR - Step 'primary_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 1 failed: Primary failed attempt 1
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 2 failed: Primary failed attempt 2
ERROR    flujo:telemetry.py:54 Step 'primary_step' agent failed after 3 attempts
INFO     flujo:telemetry.py:54 Step 'primary_step' failed, attempting fallback
_______ TestExecutorCoreFallback.test_fallback_with_usage_meter_tracking _______
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:1159: in test_fallback_with_usage_meter_tracking
    assert calls[0].args == (0.0, 0, 1)
E   assert (0.1, 10, 5) == (0.0, 0, 1)
E
E     At index 0 diff: 0.1 != 0.0
E
E     Full diff:
E       (
E     -     0.0,
E     ?       ^
E     +     0.1,
E     ?       ^
E     -     0,
E     +     10,
E     ?     +
E     -     1,
E     ?     ^
E     +     5,
E     ?     ^
E       )
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,147 - flujo - WARNING - Step 'primary_step' agent execution attempt 1 failed: Primary failed
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 1 failed: Primary failed
________ TestExecutorCoreFallback.test_fallback_with_processor_pipeline ________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:1226: in test_fallback_with_processor_pipeline
    assert result.success is True
E   AssertionError: assert False is True
E    +  where False = StepResult(name='fallback_step', output=None, success=False, attempts=6, latency_s=0.000495165993925184, token_counts=...fallback_triggered': True, 'original_error': 'Agent execution failed with Exception: Primary failed'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,173 - flujo - WARNING - Step 'primary_step' agent execution attempt 1 failed: Primary failed
2025-08-05 14:57:06,174 - flujo - WARNING - Step 'primary_step' agent execution attempt 2 failed: Primary failed
2025-08-05 14:57:06,174 - flujo - INFO - Step 'primary_step' failed, attempting fallback
2025-08-05 14:57:06,174 - flujo - WARNING - Step 'fallback_step' agent execution attempt 1 failed: Primary failed
2025-08-05 14:57:06,175 - flujo - WARNING - Step 'fallback_step' agent execution attempt 2 failed:
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,174 - flujo - ERROR - Step 'primary_step' agent failed after 3 attempts
2025-08-05 14:57:06,175 - flujo - ERROR - Step 'fallback_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 1 failed: Primary failed
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 2 failed: Primary failed
ERROR    flujo:telemetry.py:54 Step 'primary_step' agent failed after 3 attempts
INFO     flujo:telemetry.py:54 Step 'primary_step' failed, attempting fallback
WARNING  flujo:telemetry.py:54 Step 'fallback_step' agent execution attempt 1 failed: Primary failed
WARNING  flujo:telemetry.py:54 Step 'fallback_step' agent execution attempt 2 failed:
ERROR    flujo:telemetry.py:54 Step 'fallback_step' agent failed after 3 attempts
__________ TestExecutorCoreFallback.test_fallback_with_plugin_runner ___________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:1293: in test_fallback_with_plugin_runner
    assert result.success is True
E   AssertionError: assert False is True
E    +  where False = StepResult(name='fallback_step', output=None, success=False, attempts=6, latency_s=0.00028962595388293266, token_count...fallback_triggered': True, 'original_error': 'Agent execution failed with Exception: Primary failed'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,190 - flujo - WARNING - Step 'primary_step' agent execution attempt 1 failed: Primary failed
2025-08-05 14:57:06,190 - flujo - WARNING - Step 'primary_step' agent execution attempt 2 failed: Primary failed
2025-08-05 14:57:06,190 - flujo - INFO - Step 'primary_step' failed, attempting fallback
2025-08-05 14:57:06,190 - flujo - WARNING - Step 'fallback_step' agent execution attempt 1 failed: Primary failed
2025-08-05 14:57:06,190 - flujo - WARNING - Step 'fallback_step' agent execution attempt 2 failed:
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,190 - flujo - ERROR - Step 'primary_step' agent failed after 3 attempts
2025-08-05 14:57:06,190 - flujo - ERROR - Step 'fallback_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 1 failed: Primary failed
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 2 failed: Primary failed
ERROR    flujo:telemetry.py:54 Step 'primary_step' agent failed after 3 attempts
INFO     flujo:telemetry.py:54 Step 'primary_step' failed, attempting fallback
WARNING  flujo:telemetry.py:54 Step 'fallback_step' agent execution attempt 1 failed: Primary failed
WARNING  flujo:telemetry.py:54 Step 'fallback_step' agent execution attempt 2 failed:
ERROR    flujo:telemetry.py:54 Step 'fallback_step' agent failed after 3 attempts
__________ TestExecutorCoreFallback.test_fallback_with_cache_backend ___________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:1334: in test_fallback_with_cache_backend
    assert result.success is True
E   assert False is True
E    +  where False = StepResult(name='primary_step', output=None, success=False, attempts=3, latency_s=0.0002884159912355244, token_counts=...llback error: unsupported operand type(s) for +: 'Mock' and 'int'", branch_context=None, metadata_={}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,262 - flujo - WARNING - Step 'primary_step' agent execution attempt 1 failed: Primary failed
2025-08-05 14:57:06,262 - flujo - WARNING - Step 'primary_step' agent execution attempt 2 failed: Primary failed
2025-08-05 14:57:06,262 - flujo - INFO - Step 'primary_step' failed, attempting fallback
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,262 - flujo - ERROR - Step 'primary_step' agent failed after 3 attempts
2025-08-05 14:57:06,263 - flujo - ERROR - Fallback for step 'primary_step' also failed: unsupported operand type(s) for +: 'Mock' and 'int'
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 1 failed: Primary failed
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 2 failed: Primary failed
ERROR    flujo:telemetry.py:54 Step 'primary_step' agent failed after 3 attempts
INFO     flujo:telemetry.py:54 Step 'primary_step' failed, attempting fallback
ERROR    flujo:telemetry.py:54 Fallback for step 'primary_step' also failed: unsupported operand type(s) for +: 'Mock' and 'int'
____________ TestExecutorCoreFallback.test_fallback_with_telemetry _____________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:1399: in test_fallback_with_telemetry
    assert result.success is True
E   AssertionError: assert False is True
E    +  where False = StepResult(name='fallback_step', output=None, success=False, attempts=6, latency_s=0.0005385010153986514, token_counts...fallback_triggered': True, 'original_error': 'Agent execution failed with Exception: Primary failed'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,275 - flujo - WARNING - Step 'primary_step' agent execution attempt 1 failed: Primary failed
2025-08-05 14:57:06,276 - flujo - WARNING - Step 'primary_step' agent execution attempt 2 failed: Primary failed
2025-08-05 14:57:06,276 - flujo - INFO - Step 'primary_step' failed, attempting fallback
2025-08-05 14:57:06,276 - flujo - WARNING - Step 'fallback_step' agent execution attempt 1 failed: Primary failed
2025-08-05 14:57:06,276 - flujo - WARNING - Step 'fallback_step' agent execution attempt 2 failed:
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,276 - flujo - ERROR - Step 'primary_step' agent failed after 3 attempts
2025-08-05 14:57:06,276 - flujo - ERROR - Step 'fallback_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 1 failed: Primary failed
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 2 failed: Primary failed
ERROR    flujo:telemetry.py:54 Step 'primary_step' agent failed after 3 attempts
INFO     flujo:telemetry.py:54 Step 'primary_step' failed, attempting fallback
WARNING  flujo:telemetry.py:54 Step 'fallback_step' agent execution attempt 1 failed: Primary failed
WARNING  flujo:telemetry.py:54 Step 'fallback_step' agent execution attempt 2 failed:
ERROR    flujo:telemetry.py:54 Step 'fallback_step' agent failed after 3 attempts
_______ TestExecutorCoreFallback.test_fallback_integration_real_pipeline _______
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:1450: in test_fallback_integration_real_pipeline
    assert result.output == "fallback success"
E   AssertionError: assert 'primary success' == 'fallback success'
E
E     - fallback success
E     + primary success
----------------------------- Captured stdout call -----------------------------
ðŸ” PrimaryAgent.run called with data: test data
ðŸ” PrimaryAgent.run returning: primary success
2025-08-05 14:57:06,287 - flujo - INFO - Counting string output as 1 token for step 'primary_step': 'primary success'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'primary_step': 'primary success'
___________ TestExecutorCoreFallback.test_fallback_on_plugin_failure ___________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:1522: in test_fallback_on_plugin_failure
    print(f"ðŸ” Result.metadata: {result.metadata}")
                                ^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/pydantic/main.py:991: in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E   AttributeError: 'StepResult' object has no attribute 'metadata'
----------------------------- Captured stdout call -----------------------------
ðŸ” primary_step.agent: <test_executor_core_fallback.TestExecutorCoreFallback.test_fallback_on_plugin_failure.<locals>.PrimaryAgent object at 0x1135c6050>
ðŸ” primary_step.agent type: <class 'test_executor_core_fallback.TestExecutorCoreFallback.test_fallback_on_plugin_failure.<locals>.PrimaryAgent'>
ðŸ” hasattr(primary_step.agent, 'run'): True
ðŸ” primary_step.agent.run: <bound method TestExecutorCoreFallback.test_fallback_on_plugin_failure.<locals>.PrimaryAgent.run of <test_executor_core_fallback.TestExecutorCoreFallback.test_fallback_on_plugin_failure.<locals>.PrimaryAgent object at 0x1135c6050>>
ðŸ” fallback_step.agent: <test_executor_core_fallback.TestExecutorCoreFallback.test_fallback_on_plugin_failure.<locals>.FallbackAgent object at 0x1135c5790>
ðŸ” fallback_step.agent type: <class 'test_executor_core_fallback.TestExecutorCoreFallback.test_fallback_on_plugin_failure.<locals>.FallbackAgent'>
ðŸ” hasattr(fallback_step.agent, 'run'): True
ðŸ” fallback_step.agent.run: <bound method TestExecutorCoreFallback.test_fallback_on_plugin_failure.<locals>.FallbackAgent.run of <test_executor_core_fallback.TestExecutorCoreFallback.test_fallback_on_plugin_failure.<locals>.FallbackAgent object at 0x1135c5790>>
2025-08-05 14:57:06,297 - flujo - INFO - Counting string output as 1 token for step 'primary_step': 'primary success'
ðŸ” Result: name='primary_step' output='primary success' success=True attempts=1 latency_s=0.00016779196448624134 token_counts=1 cost_usd=0.0 feedback=None branch_context=None metadata_={} step_history=[]
ðŸ” Result.success: True
ðŸ” Result.output: primary success
ðŸ” Result.feedback: None
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'primary_step': 'primary success'
_________ TestExecutorCoreFallback.test_fallback_on_validator_failure __________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:1580: in test_fallback_on_validator_failure
    assert result.output == "fallback success"
E   AssertionError: assert 'processed: primary success' == 'fallback success'
E
E     - fallback success
E     + processed: primary success
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,318 - flujo - INFO - Counting string output as 1 token for step 'primary_step': 'primary success'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'primary_step': 'primary success'
_______ TestExecutorCoreFallback.test_fallback_on_complex_failure_chain ________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core_fallback.py:1637: in test_fallback_on_complex_failure_chain
    assert "Primary agent failed" in result.feedback
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   TypeError: argument of type 'NoneType' is not iterable
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,328 - flujo - WARNING - Step 'primary_step' agent execution attempt 1 failed: Primary agent failed
2025-08-05 14:57:06,329 - flujo - WARNING - Step 'primary_step' agent execution attempt 2 failed: Primary agent failed
2025-08-05 14:57:06,329 - flujo - INFO - Step 'primary_step' failed, attempting fallback
2025-08-05 14:57:06,329 - flujo - INFO - Counting string output as 1 token for step 'fallback_step': 'fallback success'
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,329 - flujo - ERROR - Step 'primary_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 1 failed: Primary agent failed
WARNING  flujo:telemetry.py:54 Step 'primary_step' agent execution attempt 2 failed: Primary agent failed
ERROR    flujo:telemetry.py:54 Step 'primary_step' agent failed after 3 attempts
INFO     flujo:telemetry.py:54 Step 'primary_step' failed, attempting fallback
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'fallback_step': 'fallback success'
______________________ test_mock_output_raises_type_error ______________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_mock_output_handling.py:28: in test_mock_output_raises_type_error
    with pytest.raises(Exception, match="returned a Mock object"):
E   Failed: DID NOT RAISE <class 'Exception'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,362 - flujo - INFO - Using explicit cost from 'Mock' for step 's': cost=$0.0, tokens=0
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Using explicit cost from 'Mock' for step 's': cost=$0.0, tokens=0
_________________________ test_pipeline_stops_on_mock __________________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_mock_output_handling.py:66: in test_pipeline_stops_on_mock
    with pytest.raises(Exception, match="returned a Mock object"):
E   Failed: DID NOT RAISE <class 'Exception'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,369 - flujo - INFO - Counting string output as 1 token for step 'a': 'ok'
2025-08-05 14:57:06,369 - flujo - INFO - Using explicit cost from 'Mock' for step 'b': cost=$0.0, tokens=0
2025-08-05 14:57:06,370 - flujo - INFO - Counting string output as 1 token for step 'c': 'end'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'a': 'ok'
INFO     flujo:telemetry.py:54 Using explicit cost from 'Mock' for step 'b': cost=$0.0, tokens=0
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'c': 'end'
____________________ test_resume_after_crash_sqlite_backend ____________________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_crash_recovery.py:141: in test_resume_after_crash_sqlite_backend
    assert idx == 1
E   assert 0 == 1
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,197 - flujo - INFO - Logfire telemetry is disabled or failed to initialize. Using standard Python logging.
2025-08-05 14:57:06,411 - flujo - INFO - Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw3/test_resume_after_crash_sqlite0/state.db
2025-08-05 14:57:06,415 - flujo - INFO - Saved state for run_id=sqlite_run
2025-08-05 14:57:06,416 - flujo - INFO - Counting string output as 1 token for step 'transform': 'middle'
___________ test_dynamic_router_branch_failure_context_preservation ____________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_dynamic_parallel_router_with_context_updates.py:268: in test_dynamic_router_branch_failure_context_preservation
    assert "support_failed" in result.final_pipeline_context.context_updates
E   assert 'support_failed' in ['router_called', 'billing_processed']
E    +  where ['router_called', 'billing_processed'] = DynamicRouterContext(run_id='run_9d3acb0d8a9240c3ae58fa6159a27a32', initial_prompt='test', scratchpad={'status': 'fail...lling': 'billing:test'}, execution_count=0, router_called=True, context_updates=['router_called', 'billing_processed']).context_updates
E    +    where DynamicRouterContext(run_id='run_9d3acb0d8a9240c3ae58fa6159a27a32', initial_prompt='test', scratchpad={'status': 'fail...lling': 'billing:test'}, execution_count=0, router_called=True, context_updates=['router_called', 'billing_processed']) = PipelineResult(step_history=[StepResult(name='dynamic_router', output={'billing': {'billing_result': 'billing:test'}, ...t': Agent execution failed with ValueError: Support step failed"}, children=[], status='failed')], status='completed')).final_pipeline_context
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,444 - flujo - WARNING - Step 'support' agent execution attempt 1 failed: Support step failed
2025-08-05 14:57:06,444 - flujo - WARNING - Step 'support' agent execution attempt 2 failed: Support step failed
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_dynamic_parallel_router_with_context_updates.DynamicRouterContext'>
[DEBUG] source_context type: <class 'tests.integration.test_dynamic_parallel_router_with_context_updates.DynamicRouterContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_9d3acb0d8a9240c3ae58fa6159a27a32', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'router_selection': [], 'branch_results': {'billing': 'billing:test'}, 'execution_count': 0, 'router_called': True, 'context_updates': ['router_called', 'billing_processed']}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_9d3acb0d8a9240c3ae58fa6159a27a32
[DEBUG] actual_source_value: run_9d3acb0d8a9240c3ae58fa6159a27a32
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: router_selection
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: router_selection
[DEBUG] No new items to add to list field: router_selection
[DEBUG] Processing field: branch_results
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {'billing': 'billing:test'}
[DEBUG] Merging dictionaries for field: branch_results
[DEBUG] Updated dict field: branch_results
[DEBUG] Processing field: execution_count
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: execution_count
[DEBUG] Processing field: router_called
[DEBUG] current_value: True
[DEBUG] actual_source_value: True
[DEBUG] Field unchanged: router_called
[DEBUG] Processing field: context_updates
[DEBUG] current_value: ['router_called']
[DEBUG] actual_source_value: ['router_called', 'billing_processed']
[DEBUG] Merging lists for field: context_updates
[DEBUG] Updated list field: context_updates with new items: ['billing_processed']
[DEBUG] Total fields updated: 2
[DEBUG] Validation errors: []
2025-08-05 14:57:06,445 - flujo - WARNING - Step 'dynamic_router' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,444 - flujo - ERROR - Step 'support' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'support' agent execution attempt 1 failed: Support step failed
WARNING  flujo:telemetry.py:54 Step 'support' agent execution attempt 2 failed: Support step failed
ERROR    flujo:telemetry.py:54 Step 'support' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'dynamic_router' failed. Halting pipeline execution.
___________ test_dynamic_router_with_context_updates_error_handling ____________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_dynamic_router_with_context_updates.py:348: in test_dynamic_router_with_context_updates_error_handling
    assert "branch 'failing_branch' failed" in result.step_history[-1].feedback.lower()
E   assert "branch 'failing_branch' failed" in "parallel step failed: branch 'failing_branch': agent execution failed with runtimeerror: intentional router branch failure"
E    +  where "parallel step failed: branch 'failing_branch': agent execution failed with runtimeerror: intentional router branch failure" = <built-in method lower of str object at 0x105829c60>()
E    +    where <built-in method lower of str object at 0x105829c60> = "Parallel step failed: Branch 'failing_branch': Agent execution failed with RuntimeError: Intentional router branch failure".lower
E    +      where "Parallel step failed: Branch 'failing_branch': Agent execution failed with RuntimeError: Intentional router branch failure" = StepResult(name='error_router', output={'failing_branch': StepResult(name='error_router_failing_branch', output=None, ...ch_executed='', branch_count=0, total_updates=0, router_metadata={}, branch_results={}), metadata_={}, step_history=[]).feedback
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,490 - flujo - WARNING - Step 'failing_branch' agent execution attempt 1 failed: Intentional router branch failure
2025-08-05 14:57:06,490 - flujo - WARNING - Step 'failing_branch' agent execution attempt 2 failed: Intentional router branch failure
2025-08-05 14:57:06,490 - flujo - WARNING - Step 'error_router' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,490 - flujo - ERROR - Step 'failing_branch' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'failing_branch' agent execution attempt 1 failed: Intentional router branch failure
WARNING  flujo:telemetry.py:54 Step 'failing_branch' agent execution attempt 2 failed: Intentional router branch failure
ERROR    flujo:telemetry.py:54 Step 'failing_branch' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'error_router' failed. Halting pipeline execution.
_ TestEmbeddingCostIntegration.test_embedding_cost_tracking_strict_mode_failure _
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_embedding_cost_integration.py:210: in test_embedding_cost_tracking_strict_mode_failure
    with pytest.raises(PricingNotConfiguredError) as exc_info:
E   Failed: DID NOT RAISE <class 'flujo.exceptions.PricingNotConfiguredError'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,521 - flujo - INFO - Extracted tokens for step 'EmbedDocument': prompt=100, completion=0
2025-08-05 14:57:06,521 - flujo - INFO - Extracted model ID for step 'EmbedDocument' from 'model_id': openai:text-embedding-3-large
2025-08-05 14:57:06,521 - flujo - WARNING - Step 'EmbedDocument' agent execution attempt 1 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='text-embedding-3-large' in flujo.toml.
2025-08-05 14:57:06,521 - flujo - INFO - Extracted tokens for step 'EmbedDocument': prompt=100, completion=0
2025-08-05 14:57:06,521 - flujo - WARNING - Step 'EmbedDocument' agent execution attempt 2 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='text-embedding-3-large' in flujo.toml.
2025-08-05 14:57:06,521 - flujo - INFO - Extracted tokens for step 'EmbedDocument': prompt=100, completion=0
2025-08-05 14:57:06,521 - flujo - WARNING - Step 'EmbedDocument' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,521 - flujo - ERROR - Step 'EmbedDocument' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Extracted tokens for step 'EmbedDocument': prompt=100, completion=0
INFO     flujo:telemetry.py:54 Extracted model ID for step 'EmbedDocument' from 'model_id': openai:text-embedding-3-large
WARNING  flujo:telemetry.py:54 Step 'EmbedDocument' agent execution attempt 1 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='text-embedding-3-large' in flujo.toml.
INFO     flujo:telemetry.py:54 Extracted tokens for step 'EmbedDocument': prompt=100, completion=0
WARNING  flujo:telemetry.py:54 Step 'EmbedDocument' agent execution attempt 2 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='text-embedding-3-large' in flujo.toml.
INFO     flujo:telemetry.py:54 Extracted tokens for step 'EmbedDocument': prompt=100, completion=0
ERROR    flujo:telemetry.py:54 Step 'EmbedDocument' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'EmbedDocument' failed. Halting pipeline execution.
_________ TestEmbeddingRegression.test_strict_mode_behavior_unchanged __________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_embedding_regression.py:302: in test_strict_mode_behavior_unchanged
    with pytest.raises(PricingNotConfiguredError) as exc_info:
E   Failed: DID NOT RAISE <class 'flujo.exceptions.PricingNotConfiguredError'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,544 - flujo - INFO - Extracted tokens for step 'ChatResponse': prompt=50, completion=25
2025-08-05 14:57:06,544 - flujo - INFO - Extracted model ID for step 'ChatResponse' from 'model_id': openai:unknown-model
2025-08-05 14:57:06,544 - flujo - WARNING - Step 'ChatResponse' agent execution attempt 1 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='unknown-model' in flujo.toml.
2025-08-05 14:57:06,544 - flujo - INFO - Extracted tokens for step 'ChatResponse': prompt=50, completion=25
2025-08-05 14:57:06,544 - flujo - WARNING - Step 'ChatResponse' agent execution attempt 2 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='unknown-model' in flujo.toml.
2025-08-05 14:57:06,544 - flujo - INFO - Extracted tokens for step 'ChatResponse': prompt=50, completion=25
2025-08-05 14:57:06,544 - flujo - WARNING - Step 'ChatResponse' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,544 - flujo - ERROR - Step 'ChatResponse' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Extracted tokens for step 'ChatResponse': prompt=50, completion=25
INFO     flujo:telemetry.py:54 Extracted model ID for step 'ChatResponse' from 'model_id': openai:unknown-model
WARNING  flujo:telemetry.py:54 Step 'ChatResponse' agent execution attempt 1 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='unknown-model' in flujo.toml.
INFO     flujo:telemetry.py:54 Extracted tokens for step 'ChatResponse': prompt=50, completion=25
WARNING  flujo:telemetry.py:54 Step 'ChatResponse' agent execution attempt 2 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='unknown-model' in flujo.toml.
INFO     flujo:telemetry.py:54 Extracted tokens for step 'ChatResponse': prompt=50, completion=25
ERROR    flujo:telemetry.py:54 Step 'ChatResponse' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'ChatResponse' failed. Halting pipeline execution.
________________________ test_pause_and_resume_in_loop _________________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_agentic_loop_recipe.py:101: in test_pause_and_resume_in_loop
    assert ctx.scratchpad["status"] == "paused"
E   AssertionError: assert 'failed' == 'paused'
E
E     - paused
E     + failed
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === AgenticExplorationLoop
2025-08-05 14:57:06,587 - flujo - INFO - LoopStep 'AgenticExplorationLoop': Starting Iteration 1/10
2025-08-05 14:57:06,588 - flujo - WARNING - Step 'AgenticExplorationLoop' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,588 - flujo - ERROR - Step 'command_executor_step' encountered critical exception: Need input
2025-08-05 14:57:06,588 - flujo - ERROR - Error in LoopStep 'AgenticExplorationLoop': Need input
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'AgenticExplorationLoop': Starting Iteration 1/10
ERROR    flujo:telemetry.py:54 Step 'command_executor_step' encountered critical exception: Need input
ERROR    flujo:telemetry.py:54 Error in LoopStep 'AgenticExplorationLoop': Need input
WARNING  flujo:telemetry.py:54 Step 'AgenticExplorationLoop' failed. Halting pipeline execution.
________ TestComponentIntegration.test_component_interface_optimization ________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_executor_core_architecture_validation.py:149: in test_component_interface_optimization
    assert serializer.serialize_calls > 0, "Serializer should be called"
E   AssertionError: Serializer should be called
E   assert 0 > 0
E    +  where 0 = <tests.integration.test_executor_core_architecture_validation.MockSerializer object at 0x13008c890>.serialize_calls
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,597 - flujo - INFO - Counting string output as 1 token for step 'test_step': 'interface_test'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'test_step': 'interface_test'
__________________ test_parallel_overwrite_multi_branch_order __________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_parallel_step.py:155: in test_parallel_overwrite_multi_branch_order
    assert result.final_pipeline_context.scratchpad["v"] == 2
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   KeyError: 'v'
_______________________________ test_sync_resume _______________________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_agentic_loop_recipe.py:129: in test_sync_resume
    resumed = asyncio.run(run_agentic_loop_pipeline(pipeline, "goal", resume_from=paused))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py:190: in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py:118: in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:650: in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
flujo/recipes/factories.py:433: in run_agentic_loop_pipeline
    result = await runner.resume_async(resume_from, human_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/runner.py:770: in resume_async
    raise OrchestratorError("Pipeline is not paused")
E   flujo.exceptions.OrchestratorError: Pipeline is not paused
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === AgenticExplorationLoop
2025-08-05 14:57:06,596 - flujo - INFO - LoopStep 'AgenticExplorationLoop': Starting Iteration 1/10
2025-08-05 14:57:06,596 - flujo - WARNING - Step 'AgenticExplorationLoop' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,596 - flujo - ERROR - Step 'command_executor_step' encountered critical exception: Need input
2025-08-05 14:57:06,596 - flujo - ERROR - Error in LoopStep 'AgenticExplorationLoop': Need input
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'AgenticExplorationLoop': Starting Iteration 1/10
ERROR    flujo:telemetry.py:54 Step 'command_executor_step' encountered critical exception: Need input
ERROR    flujo:telemetry.py:54 Error in LoopStep 'AgenticExplorationLoop': Need input
WARNING  flujo:telemetry.py:54 Step 'AgenticExplorationLoop' failed. Halting pipeline execution.
____________________ test_as_step_context_inheritance_error ____________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_as_step_composition.py:185: in test_as_step_context_inheritance_error
    with pytest.raises(ContextInheritanceError) as exc:
E   Failed: DID NOT RAISE <class 'flujo.exceptions.ContextInheritanceError'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,729 - flujo - WARNING - Step 'inner' agent execution attempt 1 failed: Failed to inherit context for ChildCtx. Missing required fields: extra. Parent context provided: run_id, initial_prompt, scratchpad, hitl_history, command_log.
2025-08-05 14:57:06,729 - flujo - WARNING - Step 'inner' agent execution attempt 2 failed: Failed to inherit context for ChildCtx. Missing required fields: extra. Parent context provided: run_id, initial_prompt, scratchpad, hitl_history, command_log.
2025-08-05 14:57:06,729 - flujo - WARNING - Step 'inner' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,729 - flujo - ERROR - Step 'inner' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'inner' agent execution attempt 1 failed: Failed to inherit context for ChildCtx. Missing required fields: extra. Parent context provided: run_id, initial_prompt, scratchpad, hitl_history, command_log.
WARNING  flujo:telemetry.py:54 Step 'inner' agent execution attempt 2 failed: Failed to inherit context for ChildCtx. Missing required fields: extra. Parent context provided: run_id, initial_prompt, scratchpad, hitl_history, command_log.
ERROR    flujo:telemetry.py:54 Step 'inner' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'inner' failed. Halting pipeline execution.
____________________ test_direct_context_inheritance_error _____________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_as_step_composition.py:212: in test_direct_context_inheritance_error
    with pytest.raises(ContextInheritanceError) as exc:
E   Failed: DID NOT RAISE <class 'flujo.exceptions.ContextInheritanceError'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:06,735 - flujo - WARNING - Step 'inner' agent execution attempt 1 failed: Failed to inherit context for ChildCtx. Missing required fields: extra. Parent context provided: run_id, initial_prompt, scratchpad, hitl_history, command_log.
2025-08-05 14:57:06,735 - flujo - WARNING - Step 'inner' agent execution attempt 2 failed: Failed to inherit context for ChildCtx. Missing required fields: extra. Parent context provided: run_id, initial_prompt, scratchpad, hitl_history, command_log.
2025-08-05 14:57:06,735 - flujo - WARNING - Step 'inner' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:06,735 - flujo - ERROR - Step 'inner' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'inner' agent execution attempt 1 failed: Failed to inherit context for ChildCtx. Missing required fields: extra. Parent context provided: run_id, initial_prompt, scratchpad, hitl_history, command_log.
WARNING  flujo:telemetry.py:54 Step 'inner' agent execution attempt 2 failed: Failed to inherit context for ChildCtx. Missing required fields: extra. Parent context provided: run_id, initial_prompt, scratchpad, hitl_history, command_log.
ERROR    flujo:telemetry.py:54 Step 'inner' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'inner' failed. Halting pipeline execution.
____________________ test_context_include_keys_optimization ____________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_parallel_step_enhancements.py:135: in test_context_include_keys_optimization
    result_selective = await gather_result(
flujo/testing/utils.py:84: in gather_result
    async for result in runner.run_async(data, **kwargs):
flujo/application/runner.py:582: in run_async
    async for chunk in self._execute_steps(
flujo/application/runner.py:413: in _execute_steps
    async for item in execution_manager.execute_steps(
flujo/application/core/execution_manager.py:155: in execute_steps
    async for item in self.step_coordinator.execute_step(
flujo/application/core/step_coordinator.py:115: in execute_step
    step_result = await backend.execute_step(request)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/infra/backends.py:53: in execute_step
    return await self._executor.execute(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/core/ultra_executor.py:552: in execute
    result = await self._handle_parallel_step(
flujo/application/core/ultra_executor.py:1888: in _handle_parallel_step
    branch_context = type(context)(initial_prompt=context.initial_prompt)
                                                  ^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/pydantic/main.py:991: in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E   AttributeError: 'LargeContext' object has no attribute 'initial_prompt'
________________ test_as_step_state_persistence_and_resumption _________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_as_step_state_persistence.py:62: in test_as_step_state_persistence_and_resumption
    assert saved["current_step_index"] == 1
E   assert 0 == 1
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:07,068 - flujo - INFO - Logfire telemetry is disabled or failed to initialize. Using standard Python logging.
2025-08-05 14:57:07,310 - flujo - INFO - Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw2/test_as_step_state_persistence0/state.db
2025-08-05 14:57:07,314 - flujo - INFO - Saved state for run_id=inner_run
2025-08-05 14:57:07,322 - flujo - INFO - Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw2/test_as_step_state_persistence0/state.db
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw2/test_as_step_state_persistence0/state.db
_________ TestErrorHandlingIntegration.test_error_recovery_integration _________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_executor_core_optimization_integration.py:480: in test_error_recovery_integration
    result = await error_handling_executor.execute(failing_step, test_data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/core/ultra_executor.py:582: in execute
    result = await self._execute_agent_step(
flujo/application/core/ultra_executor.py:1180: in _execute_agent_step
    result = StepResult(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for StepResult
E   name
E     Input should be a valid string [type=string_type, input_value=<Mock name='mock.step.name' id='4426035920'>, input_type=Mock]
E       For further information visit https://errors.pydantic.dev/2.11/v/string_type
________________ test_cache_with_context_updates_error_handling ________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_cache_with_context_updates.py:207: in test_cache_with_context_updates_error_handling
    assert result1.final_pipeline_context.operation_count == 1
E   AssertionError: assert 3 == 1
E    +  where 3 = CacheContext(run_id='run_71c4856c11d5464487c34cfe22facca5', initial_prompt='test', scratchpad={'status': 'failed'}, hi... cached_results={}, processing_history=[], current_operation='', operation_count=3, cache_timestamps={}, cache_keys=[]).operation_count
E    +    where CacheContext(run_id='run_71c4856c11d5464487c34cfe22facca5', initial_prompt='test', scratchpad={'status': 'failed'}, hi... cached_results={}, processing_history=[], current_operation='', operation_count=3, cache_timestamps={}, cache_keys=[]) = PipelineResult(step_history=[StepResult(name='failing_cache_step', output=None, success=False, attempts=3, latency_s=0...failed with RuntimeError: Intentional failure for cache testing'}, children=[], status='failed')], status='completed')).final_pipeline_context
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:07,367 - flujo - WARNING - Step 'failing_cache_step' agent execution attempt 1 failed: Intentional failure for cache testing
2025-08-05 14:57:07,367 - flujo - WARNING - Step 'failing_cache_step' agent execution attempt 2 failed: Intentional failure for cache testing
2025-08-05 14:57:07,368 - flujo - WARNING - Step 'failing_cache_step' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:07,368 - flujo - ERROR - Step 'failing_cache_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'failing_cache_step' agent execution attempt 1 failed: Intentional failure for cache testing
WARNING  flujo:telemetry.py:54 Step 'failing_cache_step' agent execution attempt 2 failed: Intentional failure for cache testing
ERROR    flujo:telemetry.py:54 Step 'failing_cache_step' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'failing_cache_step' failed. Halting pipeline execution.
________ TestErrorHandlingIntegration.test_circuit_breaker_integration _________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_executor_core_optimization_integration.py:520: in test_circuit_breaker_integration
    result = await error_handling_executor.execute(always_failing_step, test_data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/core/ultra_executor.py:582: in execute
    result = await self._execute_agent_step(
flujo/application/core/ultra_executor.py:1180: in _execute_agent_step
    result = StepResult(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for StepResult
E   name
E     Input should be a valid string [type=string_type, input_value=<Mock name='mock.step.name' id='5101950288'>, input_type=Mock]
E       For further information visit https://errors.pydantic.dev/2.11/v/string_type
_____________________ test_context_include_keys_isolation ______________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_parallel_step_enhancements.py:171: in test_context_include_keys_isolation
    result = await gather_result(runner, "input", initial_context_data=context.model_dump())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/testing/utils.py:84: in gather_result
    async for result in runner.run_async(data, **kwargs):
flujo/application/runner.py:582: in run_async
    async for chunk in self._execute_steps(
flujo/application/runner.py:413: in _execute_steps
    async for item in execution_manager.execute_steps(
flujo/application/core/execution_manager.py:155: in execute_steps
    async for item in self.step_coordinator.execute_step(
flujo/application/core/step_coordinator.py:115: in execute_step
    step_result = await backend.execute_step(request)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/infra/backends.py:53: in execute_step
    return await self._executor.execute(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/core/ultra_executor.py:552: in execute
    result = await self._handle_parallel_step(
flujo/application/core/ultra_executor.py:1888: in _handle_parallel_step
    branch_context = type(context)(initial_prompt=context.initial_prompt)
                                                  ^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/pydantic/main.py:991: in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E   AttributeError: 'LargeContext' object has no attribute 'initial_prompt'
_____________________ test_caching_pipeline_speed_and_hits _____________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_caching_and_fallbacks.py:61: in test_caching_pipeline_speed_and_hits
    assert first_meta is None or "cache_hit" not in first_meta
E   AssertionError: assert ({'cache_hit': True} is None or 'cache_hit' not in {'cache_hit': True})
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:07,436 - flujo - INFO - Counting string output as 1 token for step 'solution': 'ok'
2025-08-05 14:57:07,439 - flujo - INFO - Counting string output as 1 token for step 'passthrough': 'ok'
2025-08-05 14:57:07,440 - flujo - INFO - Counting string output as 1 token for step 'passthrough': 'ok'
2025-08-05 14:57:07,441 - flujo - INFO - Counting string output as 1 token for step 'solution': 'ok'
2025-08-05 14:57:07,441 - flujo - INFO - Counting string output as 1 token for step 'passthrough': 'ok'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'solution': 'ok'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'passthrough': 'ok'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'passthrough': 'ok'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'solution': 'ok'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'passthrough': 'ok'
______________________ test_loop_step_fallback_continues _______________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_caching_and_fallbacks.py:135: in test_loop_step_fallback_continues
    assert sr.success is True
E   AssertionError: assert False is True
E    +  where False = StepResult(name='loop', output=PluginOutcome(success=True, feedback=None, redirect_to=None, new_solution=None), success...led'}, hitl_history=[], command_log=[]), metadata_={'iterations': 2, 'exit_reason': 'max_iterations'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === loop
2025-08-05 14:57:07,452 - flujo - INFO - LoopStep 'loop': Starting Iteration 1/2
2025-08-05 14:57:07,452 - flujo - INFO - Counting string output as 1 token for step 'body': 'bad'
2025-08-05 14:57:07,453 - flujo - INFO - Step 'body' plugin validation failed, attempting fallback
2025-08-05 14:57:07,453 - flujo - INFO - Counting string output as 1 token for step 'fb': 'recover'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'flujo.domain.models.PipelineContext'>
[DEBUG] source_context type: <class 'flujo.domain.models.PipelineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_1c181fbc12694dc9b4fde7271bf0d5df', 'initial_prompt': 'start', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': []}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_1c181fbc12694dc9b4fde7271bf0d5df
[DEBUG] actual_source_value: run_1c181fbc12694dc9b4fde7271bf0d5df
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: start
[DEBUG] actual_source_value: start
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:07,453 - flujo - INFO - LoopStep 'loop': Starting Iteration 2/2
2025-08-05 14:57:07,453 - flujo - INFO - Counting string output as 1 token for step 'body': 'done'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'flujo.domain.models.PipelineContext'>
[DEBUG] source_context type: <class 'flujo.domain.models.PipelineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_1c181fbc12694dc9b4fde7271bf0d5df', 'initial_prompt': 'start', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': []}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_1c181fbc12694dc9b4fde7271bf0d5df
[DEBUG] actual_source_value: run_1c181fbc12694dc9b4fde7271bf0d5df
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: start
[DEBUG] actual_source_value: start
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:07,453 - flujo - WARNING - Step 'loop' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:07,453 - flujo - ERROR - Step 'body' plugin failed after 1 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'loop': Starting Iteration 1/2
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'body': 'bad'
ERROR    flujo:telemetry.py:54 Step 'body' plugin failed after 1 attempts
INFO     flujo:telemetry.py:54 Step 'body' plugin validation failed, attempting fallback
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'fb': 'recover'
INFO     flujo:telemetry.py:54 LoopStep 'loop': Starting Iteration 2/2
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'body': 'done'
WARNING  flujo:telemetry.py:54 Step 'loop' failed. Halting pipeline execution.
______________________ test_persist_feedback_and_results _______________________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_validation_persistence.py:43: in test_persist_feedback_and_results
    assert ctx.feedback_history and ctx.feedback_history[0] == result.step_history[0].feedback
E   assert ([])
E    +  where [] = Ctx(feedback_history=[], validation_history=[]).feedback_history
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:07,620 - flujo - INFO - Counting string output as 1 token for step 'validate': 'bad'
2025-08-05 14:57:07,620 - flujo - WARNING - Step 'validate' validation failed: bad output
2025-08-05 14:57:07,620 - flujo - WARNING - Step 'validate' agent execution attempt 2 failed: No more outputs available
2025-08-05 14:57:07,620 - flujo - WARNING - Step 'validate' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:07,620 - flujo - ERROR - Step 'validate' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'validate': 'bad'
WARNING  flujo:telemetry.py:54 Step 'validate' validation failed: bad output
WARNING  flujo:telemetry.py:54 Step 'validate' agent execution attempt 2 failed: No more outputs available
ERROR    flujo:telemetry.py:54 Step 'validate' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'validate' failed. Halting pipeline execution.
_______________________ test_persist_results_on_success ________________________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_validation_persistence.py:65: in test_persist_results_on_success
    assert len(ctx.validation_history) == 1
E   assert 0 == 1
E    +  where 0 = len([])
E    +    where [] = Ctx(feedback_history=[], validation_history=[]).validation_history
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:07,623 - flujo - INFO - Counting string output as 1 token for step 'validate': 'ok'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'validate': 'ok'
______ TestStrictPricingModeIntegration.test_strict_mode_on_failure_case _______
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_cost_tracking_integration.py:307: in test_strict_mode_on_failure_case
    with pytest.raises(PricingNotConfiguredError) as exc_info:
E   Failed: DID NOT RAISE <class 'flujo.exceptions.PricingNotConfiguredError'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:07,742 - flujo - INFO - Extracted tokens for step 'test_step': prompt=100, completion=50
2025-08-05 14:57:07,742 - flujo - INFO - Extracted model ID for step 'test_step' from 'model_id': openai:gpt-4o
2025-08-05 14:57:07,742 - flujo - WARNING - Step 'test_step' agent execution attempt 1 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='gpt-4o' in flujo.toml.
2025-08-05 14:57:07,742 - flujo - INFO - Extracted tokens for step 'test_step': prompt=100, completion=50
2025-08-05 14:57:07,742 - flujo - WARNING - Step 'test_step' agent execution attempt 2 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='gpt-4o' in flujo.toml.
2025-08-05 14:57:07,742 - flujo - INFO - Extracted tokens for step 'test_step': prompt=100, completion=50
2025-08-05 14:57:07,743 - flujo - WARNING - Step 'test_step' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:07,743 - flujo - ERROR - Step 'test_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Extracted tokens for step 'test_step': prompt=100, completion=50
INFO     flujo:telemetry.py:54 Extracted model ID for step 'test_step' from 'model_id': openai:gpt-4o
WARNING  flujo:telemetry.py:54 Step 'test_step' agent execution attempt 1 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='gpt-4o' in flujo.toml.
INFO     flujo:telemetry.py:54 Extracted tokens for step 'test_step': prompt=100, completion=50
WARNING  flujo:telemetry.py:54 Step 'test_step' agent execution attempt 2 failed: Strict pricing is enabled, but no configuration was found for provider='openai', model='gpt-4o' in flujo.toml.
INFO     flujo:telemetry.py:54 Extracted tokens for step 'test_step': prompt=100, completion=50
ERROR    flujo:telemetry.py:54 Step 'test_step' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'test_step' failed. Halting pipeline execution.
__ TestStrictPricingModeIntegration.test_strict_mode_on_with_unknown_provider __
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_cost_tracking_integration.py:445: in test_strict_mode_on_with_unknown_provider
    with pytest.raises(PricingNotConfiguredError) as exc_info:
E   Failed: DID NOT RAISE <class 'flujo.exceptions.PricingNotConfiguredError'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:07,752 - flujo - INFO - Extracted tokens for step 'test_step': prompt=100, completion=50
2025-08-05 14:57:07,752 - flujo - INFO - Extracted model ID for step 'test_step' from 'model_id': unknown:unknown-model
2025-08-05 14:57:07,752 - flujo - WARNING - Step 'test_step' agent execution attempt 1 failed: Strict pricing is enabled, but no configuration was found for provider='unknown', model='unknown-model' in flujo.toml.
2025-08-05 14:57:07,752 - flujo - INFO - Extracted tokens for step 'test_step': prompt=100, completion=50
2025-08-05 14:57:07,752 - flujo - WARNING - Step 'test_step' agent execution attempt 2 failed: Strict pricing is enabled, but no configuration was found for provider='unknown', model='unknown-model' in flujo.toml.
2025-08-05 14:57:07,752 - flujo - INFO - Extracted tokens for step 'test_step': prompt=100, completion=50
2025-08-05 14:57:07,752 - flujo - WARNING - Step 'test_step' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:07,752 - flujo - ERROR - Step 'test_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Extracted tokens for step 'test_step': prompt=100, completion=50
INFO     flujo:telemetry.py:54 Extracted model ID for step 'test_step' from 'model_id': unknown:unknown-model
WARNING  flujo:telemetry.py:54 Step 'test_step' agent execution attempt 1 failed: Strict pricing is enabled, but no configuration was found for provider='unknown', model='unknown-model' in flujo.toml.
INFO     flujo:telemetry.py:54 Extracted tokens for step 'test_step': prompt=100, completion=50
WARNING  flujo:telemetry.py:54 Step 'test_step' agent execution attempt 2 failed: Strict pricing is enabled, but no configuration was found for provider='unknown', model='unknown-model' in flujo.toml.
INFO     flujo:telemetry.py:54 Extracted tokens for step 'test_step': prompt=100, completion=50
ERROR    flujo:telemetry.py:54 Step 'test_step' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'test_step' failed. Halting pipeline execution.
__________ TestOptimizationIntegration.test_configuration_management ___________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/regression/test_executor_core_optimization_regression.py:538: in test_configuration_management
    assert config_manager.current_config is not None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'dict' object has no attribute 'current_config'
_________ TestOptimizationIntegration.test_performance_recommendations _________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/regression/test_executor_core_optimization_regression.py:556: in test_performance_recommendations
    assert "type" in rec
E   AssertionError: assert 'type' in 'Consider increasing cache size for better performance'
______ TestConditionalStepRegression.test_metrics_accumulation_regression ______
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/regression/test_conditional_step_regression.py:136: in test_metrics_accumulation_regression
    assert result.latency_s == 1.0
E   AssertionError: assert 0.00011962500866502523 == 1.0
E    +  where 0.00011962500866502523 = StepResult(name='test_conditional', output='test_output', success=True, attempts=1, latency_s=0.00011962500866502523, ...data', scratchpad={}, hitl_history=[], command_log=[]), metadata_={'executed_branch_key': 'branch_a'}, step_history=[]).latency_s
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:07,792 - flujo - INFO - Condition evaluated to branch key 'branch_a'
2025-08-05 14:57:07,792 - flujo - INFO - Executing branch for key 'branch_a'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Condition evaluated to branch key 'branch_a'
INFO     flujo:telemetry.py:54 Executing branch for key 'branch_a'
________ TestConditionalStepRegression.test_context_handling_regression ________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/regression/test_conditional_step_regression.py:181: in test_context_handling_regression
    assert context_setter_called is True
E   assert False is True
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:07,797 - flujo - INFO - Condition evaluated to branch key 'branch_a'
2025-08-05 14:57:07,797 - flujo - INFO - Executing branch for key 'branch_a'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'dict'>
[DEBUG] source_context type: <class 'dict'>
[DEBUG] excluded_fields: {'command_log'}
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:07,797 - flujo.utils.context - ERROR - Failed to merge context updates: 'dict' object has no attribute '__dict__'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Condition evaluated to branch key 'branch_a'
INFO     flujo:telemetry.py:54 Executing branch for key 'branch_a'
ERROR    flujo.utils.context:context.py:276 Failed to merge context updates: 'dict' object has no attribute '__dict__'
_______ TestLegacyFunctionUsageAnalysis.test_import_dependency_analysis ________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/regression/test_legacy_cleanup_impact.py:38: in test_import_dependency_analysis
    with pytest.raises(ModuleNotFoundError):
E   Failed: DID NOT RAISE <class 'ModuleNotFoundError'>
____ TestOptimizationBackwardCompatibility.test_configuration_serialization ____
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/regression/test_executor_core_optimization_regression.py:292: in test_configuration_serialization
    restored_config = OptimizationConfig.from_dict(config_dict)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: type object 'OptimizationConfig' has no attribute 'from_dict'
___ TestLegacyFunctionUsageAnalysis.test_backward_compatibility_verification ___
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/regression/test_legacy_cleanup_impact.py:78: in test_backward_compatibility_verification
    result = await executor._handle_cache_step(
flujo/application/core/ultra_executor.py:2713: in _handle_cache_step
    result = await self.execute(frame)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/core/ultra_executor.py:582: in execute
    result = await self._execute_agent_step(
flujo/application/core/ultra_executor.py:1233: in _execute_agent_step
    for attempt in range(1, max_retries + 1):  # +1 because we want max_retries total attempts
                            ^^^^^^^^^^^^^^^
E   TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
___________ TestOptimizationErrorHandling.test_invalid_step_handling ___________
[gw3] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/regression/test_executor_core_optimization_regression.py:352: in test_invalid_step_handling
    result = await error_prone_executor.execute(invalid_step, test_data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/core/ultra_executor.py:582: in execute
    result = await self._execute_agent_step(
flujo/application/core/ultra_executor.py:1180: in _execute_agent_step
    result = StepResult(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for StepResult
E   name
E     Input should be a valid string [type=string_type, input_value=<Mock name='mock.step.name' id='5102819216'>, input_type=Mock]
E       For further information visit https://errors.pydantic.dev/2.11/v/string_type
__________ TestMigrationCompleteness.test_legacy_function_deprecation __________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/regression/test_legacy_cleanup_impact.py:134: in test_legacy_function_deprecation
    result = await executor._handle_cache_step(
flujo/application/core/ultra_executor.py:2713: in _handle_cache_step
    result = await self.execute(frame)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/core/ultra_executor.py:582: in execute
    result = await self._execute_agent_step(
flujo/application/core/ultra_executor.py:1233: in _execute_agent_step
    for attempt in range(1, max_retries + 1):  # +1 because we want max_retries total attempts
                            ^^^^^^^^^^^^^^^
E   TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
__________ TestDeprecationDecorator.test_deprecation_warning_message ___________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/regression/test_legacy_cleanup_impact.py:259: in test_deprecation_warning_message
    result = await executor._handle_cache_step(
flujo/application/core/ultra_executor.py:2713: in _handle_cache_step
    result = await self.execute(frame)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/core/ultra_executor.py:582: in execute
    result = await self._execute_agent_step(
flujo/application/core/ultra_executor.py:1233: in _execute_agent_step
    for attempt in range(1, max_retries + 1):  # +1 because we want max_retries total attempts
                            ^^^^^^^^^^^^^^^
E   TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
__________________________ test_adapter_pipeline_runs __________________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_adapter_step.py:29: in test_adapter_pipeline_runs
    async for item in runner.run_async("abc"):
flujo/application/runner.py:582: in run_async
    async for chunk in self._execute_steps(
flujo/application/runner.py:413: in _execute_steps
    async for item in execution_manager.execute_steps(
flujo/application/core/execution_manager.py:184: in execute_steps
    self.type_validator.validate_step_output(
flujo/application/core/type_validator.py:58: in validate_step_output
    raise TypeMismatchError(
E   flujo.exceptions.TypeMismatchError: Type mismatch: Output of 'adapt' (returns `<class 'str'>`) is not compatible with 'follow' (expects `<class 'tests.unit.test_adapter_step.ComplexInput'>`). For best results, use a static type checker like mypy to catch these issues before runtime.
_____________ TestAgenticLoopLogging.test_pause_and_resume_logging _____________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_agentic_loop_logging.py:170: in test_pause_and_resume_logging
    resumed = await run_agentic_loop_pipeline(pipeline, "goal", resume_from=paused)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/recipes/factories.py:433: in run_agentic_loop_pipeline
    result = await runner.resume_async(resume_from, human_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/runner.py:770: in resume_async
    raise OrchestratorError("Pipeline is not paused")
E   flujo.exceptions.OrchestratorError: Pipeline is not paused
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === AgenticExplorationLoop
2025-08-05 14:57:08,196 - flujo - INFO - LoopStep 'AgenticExplorationLoop': Starting Iteration 1/10
2025-08-05 14:57:08,197 - flujo - WARNING - Step 'AgenticExplorationLoop' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:08,197 - flujo - ERROR - Step 'command_executor_step' encountered critical exception: Need input
2025-08-05 14:57:08,197 - flujo - ERROR - Error in LoopStep 'AgenticExplorationLoop': Need input
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'AgenticExplorationLoop': Starting Iteration 1/10
ERROR    flujo:telemetry.py:54 Step 'command_executor_step' encountered critical exception: Need input
ERROR    flujo:telemetry.py:54 Error in LoopStep 'AgenticExplorationLoop': Need input
WARNING  flujo:telemetry.py:54 Step 'AgenticExplorationLoop' failed. Halting pipeline execution.
______________ TestCIErrorRecovery.test_partial_failure_handling _______________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_ci_compatibility.py:280: in test_partial_failure_handling
    assert isinstance(result, dict)
E   AssertionError: assert False
E    +  where False = isinstance('<unserializable: dict>', dict)
______________ test_proactive_cancellation_with_multiple_branches ______________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_parallel_step_enhancements.py:259: in test_proactive_cancellation_with_multiple_branches
    assert execution_time < 0.3  # Should be much faster than the 0.5s delay of branch_4
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert 0.5482313749962486 < 0.3
----------------------------- Captured stdout call -----------------------------
[DEBUG] CostlyAgent.run called with breach_event: True
[DEBUG] CostlyAgent starting sleep for 0.1s
[DEBUG] CostlyAgent.run called with breach_event: True
[DEBUG] CostlyAgent starting sleep for 0.1s
[DEBUG] CostlyAgent.run called with breach_event: True
[DEBUG] CostlyAgent starting sleep for 0.1s
[DEBUG] CostlyAgent.run called with breach_event: True
[DEBUG] CostlyAgent starting sleep for 0.5s
[DEBUG] CostlyAgent completed sleep, returning result
2025-08-05 14:57:08,078 - flujo - INFO - Using explicit cost from 'Output' for step 'branch_1': cost=$0.05, tokens=100
[DEBUG] CostlyAgent completed sleep, returning result
2025-08-05 14:57:08,078 - flujo - INFO - Using explicit cost from 'Output' for step 'branch_2': cost=$0.05, tokens=100
[DEBUG] CostlyAgent completed sleep, returning result
2025-08-05 14:57:08,079 - flujo - INFO - Using explicit cost from 'Output' for step 'branch_3': cost=$0.05, tokens=100
[DEBUG] CostlyAgent completed sleep, returning result
2025-08-05 14:57:08,517 - flujo - INFO - Using explicit cost from 'Output' for step 'branch_4': cost=$0.01, tokens=100
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:08,517 - flujo - ERROR - Parallel step usage limit breached: Cost limit of $0.12 exceeded
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Using explicit cost from 'Output' for step 'branch_1': cost=$0.05, tokens=100
INFO     flujo:telemetry.py:54 Using explicit cost from 'Output' for step 'branch_2': cost=$0.05, tokens=100
INFO     flujo:telemetry.py:54 Using explicit cost from 'Output' for step 'branch_3': cost=$0.05, tokens=100
INFO     flujo:telemetry.py:54 Using explicit cost from 'Output' for step 'branch_4': cost=$0.01, tokens=100
ERROR    flujo:telemetry.py:54 Parallel step usage limit breached: Cost limit of $0.12 exceeded
______________________ test_runner_uses_sqlite_by_default ______________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
/Users/alvaro/Documents/Code/flujo/tests/unit/test_default_backend.py:20: in test_runner_uses_sqlite_by_default
    assert isinstance(runner.state_backend, SQLiteBackend)
E   assert False
E    +  where False = isinstance(<tests.conftest.NoOpStateBackend object at 0x113e18350>, SQLiteBackend)
E    +    where <tests.conftest.NoOpStateBackend object at 0x113e18350> = <flujo.application.runner.Flujo object at 0x113e1a890>.state_backend
_________________ test_dummy_remote_backend_dict_of_primitives _________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_dummy_remote_backend.py:163: in test_dummy_remote_backend_dict_of_primitives
    result = await gather_result(runner, payload)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/testing/utils.py:84: in gather_result
    async for result in runner.run_async(data, **kwargs):
flujo/application/runner.py:582: in run_async
    async for chunk in self._execute_steps(
flujo/application/runner.py:413: in _execute_steps
    async for item in execution_manager.execute_steps(
flujo/application/core/execution_manager.py:155: in execute_steps
    async for item in self.step_coordinator.execute_step(
flujo/application/core/step_coordinator.py:115: in execute_step
    step_result = await backend.execute_step(request)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/testing/utils.py:283: in execute_step
    reconstructed_payload[key] = reconstruct(original_value, data[key])
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/testing/utils.py:207: in reconstruct
    fixed_value[k] = reconstruct(getattr(original, k, None), v)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/testing/utils.py:268: in reconstruct
    reconstruct(original_value, v) if original_value is not None else v
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/testing/utils.py:253: in reconstruct
    return type(original).model_validate(value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for Nested
E     Input should be a valid dictionary or instance of Nested [type=model_type, input_value=None, input_type=NoneType]
E       For further information visit https://errors.pydantic.dev/2.11/v/model_type
______________ TestDefaultValidatorRunner.test_validation_failure ______________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_executor_components.py:366: in test_validation_failure
    with pytest.raises(ValueError, match="Validation failed"):
E   Failed: DID NOT RAISE <class 'ValueError'>
________________ TestDefaultPluginRunner.test_plugin_execution _________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_executor_components.py:392: in test_plugin_execution
    assert result == "processed data"
E   AssertionError: assert PluginOutcome(success=True, feedback=None, redirect_to=None, new_solution='processed data') == 'processed data'
__________ TestDefaultPluginRunner.test_plugin_with_priority_ordering __________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_executor_components.py:423: in test_plugin_with_priority_ordering
    assert result == "processed by plugin1"
E   AssertionError: assert PluginOutcome(success=True, feedback=None, redirect_to=None, new_solution='processed by plugin2') == 'processed by plugin1'
_ TestExecutorCoreParallelMigration.test_executor_core_dynamic_router_delegates_to_parallel _
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_executor_core_parallel_migration.py:164: in test_executor_core_dynamic_router_delegates_to_parallel
    result = await executor_core._handle_dynamic_router_step(
E   TypeError: ExecutorCore._handle_dynamic_router_step() got an unexpected keyword argument 'router_step'
___________________ test_proactive_cancellation_token_limits ___________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_parallel_step_enhancements.py:305: in test_proactive_cancellation_token_limits
    assert execution_time < threshold, (
E   AssertionError: Execution took too long: 0.560s (threshold: 0.400s). This indicates proactive cancellation may not be working correctly.
E   assert 0.5600467500044033 < 0.4
----------------------------- Captured stdout call -----------------------------
[DEBUG] CostlyAgent.run called with breach_event: True
[DEBUG] CostlyAgent starting sleep for 0.05s
[DEBUG] CostlyAgent.run called with breach_event: True
[DEBUG] CostlyAgent starting sleep for 0.5s
[DEBUG] CostlyAgent completed sleep, returning result
2025-08-05 14:57:08,580 - flujo - INFO - Using explicit cost from 'Output' for step 'high_tokens': cost=$0.01, tokens=150
[DEBUG] CostlyAgent completed sleep, returning result
2025-08-05 14:57:09,080 - flujo - INFO - Using explicit cost from 'Output' for step 'low_tokens': cost=$0.01, tokens=10
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:09,083 - flujo - ERROR - Parallel step usage limit breached: Token limit of 100 exceeded
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Using explicit cost from 'Output' for step 'high_tokens': cost=$0.01, tokens=150
INFO     flujo:telemetry.py:54 Using explicit cost from 'Output' for step 'low_tokens': cost=$0.01, tokens=10
ERROR    flujo:telemetry.py:54 Parallel step usage limit breached: Token limit of 100 exceeded
_____________________ test_fallback_with_high_cost_agents ______________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_fallback_edge_cases.py:119: in test_fallback_with_high_cost_agents
    assert sr.cost_usd == 999.99  # Should be fallback cost
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert 1999.98 == 999.99
E    +  where 1999.98 = StepResult(name='fb', output='fallback', success=True, attempts=2, latency_s=0.0001717920093616545, token_counts=19999... metadata_={'fallback_triggered': True, 'original_error': 'Plugin validation failed: primary failed'}, step_history=[]).cost_usd
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:09,201 - flujo - INFO - Using explicit cost from 'HighCostResult' for step 'p': cost=$999.99, tokens=999999
2025-08-05 14:57:09,201 - flujo - INFO - Step 'p' plugin validation failed, attempting fallback
2025-08-05 14:57:09,201 - flujo - INFO - Using explicit cost from 'HighCostResult' for step 'fb': cost=$999.99, tokens=999999
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:09,201 - flujo - ERROR - Step 'p' plugin failed after 1 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Using explicit cost from 'HighCostResult' for step 'p': cost=$999.99, tokens=999999
ERROR    flujo:telemetry.py:54 Step 'p' plugin failed after 1 attempts
INFO     flujo:telemetry.py:54 Step 'p' plugin validation failed, attempting fallback
INFO     flujo:telemetry.py:54 Using explicit cost from 'HighCostResult' for step 'fb': cost=$999.99, tokens=999999
_____________________ test_fallback_with_negative_metrics ______________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_fallback_edge_cases.py:199: in test_fallback_with_negative_metrics
    assert sr.cost_usd == -0.1  # Should be fallback cost
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert -0.2 == -0.1
E    +  where -0.2 = StepResult(name='fb', output='negative', success=True, attempts=2, latency_s=0.00022316598667204381, token_counts=-10,... metadata_={'fallback_triggered': True, 'original_error': 'Plugin validation failed: primary failed'}, step_history=[]).cost_usd
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:09,211 - flujo - INFO - Using explicit cost from 'NegativeResult' for step 'p': cost=$-0.1, tokens=-5
2025-08-05 14:57:09,211 - flujo - INFO - Step 'p' plugin validation failed, attempting fallback
2025-08-05 14:57:09,211 - flujo - INFO - Using explicit cost from 'NegativeResult' for step 'fb': cost=$-0.1, tokens=-5
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:09,211 - flujo - ERROR - Step 'p' plugin failed after 1 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Using explicit cost from 'NegativeResult' for step 'p': cost=$-0.1, tokens=-5
ERROR    flujo:telemetry.py:54 Step 'p' plugin failed after 1 attempts
INFO     flujo:telemetry.py:54 Step 'p' plugin validation failed, attempting fallback
INFO     flujo:telemetry.py:54 Using explicit cost from 'NegativeResult' for step 'fb': cost=$-0.1, tokens=-5
_____________________ test_fallback_with_complex_metadata ______________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_fallback_edge_cases.py:435: in test_fallback_with_complex_metadata
    assert sr.metadata_["original_error"] == "complex failed"
E   AssertionError: assert 'Plugin valid...omplex failed' == 'complex failed'
E
E     - complex failed
E     + Plugin validation failed: complex failed
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:09,230 - flujo - INFO - Counting string output as 1 token for step 'p': 'bad'
2025-08-05 14:57:09,230 - flujo - INFO - Step 'p' plugin validation failed, attempting fallback
2025-08-05 14:57:09,230 - flujo - INFO - Using explicit cost from 'CostlyOutput' for step 'fb': cost=$0.2, tokens=5
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:09,230 - flujo - ERROR - Step 'p' plugin failed after 1 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'p': 'bad'
ERROR    flujo:telemetry.py:54 Step 'p' plugin failed after 1 attempts
INFO     flujo:telemetry.py:54 Step 'p' plugin validation failed, attempting fallback
INFO     flujo:telemetry.py:54 Using explicit cost from 'CostlyOutput' for step 'fb': cost=$0.2, tokens=5
______________ test_context_include_keys_with_nonexistent_fields _______________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_parallel_step_enhancements.py:373: in test_context_include_keys_with_nonexistent_fields
    result = await gather_result(runner, "input", initial_context_data=context.model_dump())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/testing/utils.py:84: in gather_result
    async for result in runner.run_async(data, **kwargs):
flujo/application/runner.py:582: in run_async
    async for chunk in self._execute_steps(
flujo/application/runner.py:413: in _execute_steps
    async for item in execution_manager.execute_steps(
flujo/application/core/execution_manager.py:155: in execute_steps
    async for item in self.step_coordinator.execute_step(
flujo/application/core/step_coordinator.py:115: in execute_step
    step_result = await backend.execute_step(request)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/infra/backends.py:53: in execute_step
    return await self._executor.execute(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/core/ultra_executor.py:552: in execute
    result = await self._handle_parallel_step(
flujo/application/core/ultra_executor.py:1888: in _handle_parallel_step
    branch_context = type(context)(initial_prompt=context.initial_prompt)
                                                  ^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/pydantic/main.py:991: in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E   AttributeError: 'LargeContext' object has no attribute 'initial_prompt'
_ TestPersistencePerformanceOverhead.test_default_backend_performance_overhead _
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_persistence_performance.py:101: in test_default_backend_performance_overhead
    assert overhead_percentage <= overhead_limit, (
E   AssertionError: Default persistence overhead (890.56%) exceeds 35.0% limit
E   assert 890.5554954248926 <= 35.0
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:10,400 - flujo - INFO - Counting string output as 1 token for step 'solution': 'output'
2025-08-05 14:57:10,404 - flujo - INFO - Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw2/test_default_backend_performan0/with_backend_f79fef2c.db
2025-08-05 14:57:10,406 - flujo - INFO - Saved state for run_id=run_2f0cef8d2a3a47f7b57a465844c9ff08
2025-08-05 14:57:10,410 - flujo - INFO - Saved state for run_id=run_2f0cef8d2a3a47f7b57a465844c9ff08
2025-08-05 14:57:10,412 - flujo - INFO - Saved state for run_id=run_2f0cef8d2a3a47f7b57a465844c9ff08
2025-08-05 14:57:10,414 - flujo - INFO - Saved state for run_id=run_2f0cef8d2a3a47f7b57a465844c9ff08
2025-08-05 14:57:10,421 - flujo - INFO - Saved state for run_id=run_1797fb7e40e6455c8fc138e24db5a9a8
2025-08-05 14:57:10,425 - flujo - INFO - Saved state for run_id=run_1797fb7e40e6455c8fc138e24db5a9a8
2025-08-05 14:57:10,428 - flujo - INFO - Saved state for run_id=run_1797fb7e40e6455c8fc138e24db5a9a8
2025-08-05 14:57:10,431 - flujo - INFO - Saved state for run_id=run_1797fb7e40e6455c8fc138e24db5a9a8
2025-08-05 14:57:10,437 - flujo - INFO - Saved state for run_id=run_2c470e6382254dbbbe5b863b59fec944
2025-08-05 14:57:10,440 - flujo - INFO - Saved state for run_id=run_2c470e6382254dbbbe5b863b59fec944
2025-08-05 14:57:10,442 - flujo - INFO - Saved state for run_id=run_2c470e6382254dbbbe5b863b59fec944
2025-08-05 14:57:10,444 - flujo - INFO - Saved state for run_id=run_2c470e6382254dbbbe5b863b59fec944
2025-08-05 14:57:10,451 - flujo - INFO - Saved state for run_id=run_053e79e8e8bb42229081bd4d10b1f66a
2025-08-05 14:57:10,454 - flujo - INFO - Saved state for run_id=run_053e79e8e8bb42229081bd4d10b1f66a
2025-08-05 14:57:10,455 - flujo - INFO - Saved state for run_id=run_053e79e8e8bb42229081bd4d10b1f66a
2025-08-05 14:57:10,457 - flujo - INFO - Saved state for run_id=run_053e79e8e8bb42229081bd4d10b1f66a
2025-08-05 14:57:10,465 - flujo - INFO - Saved state for run_id=run_1927b545382841fb918531d4a9152856
2025-08-05 14:57:10,468 - flujo - INFO - Saved state for run_id=run_1927b545382841fb918531d4a9152856
2025-08-05 14:57:10,470 - flujo - INFO - Saved state for run_id=run_1927b545382841fb918531d4a9152856
2025-08-05 14:57:10,472 - flujo - INFO - Saved state for run_id=run_1927b545382841fb918531d4a9152856
2025-08-05 14:57:10,479 - flujo - INFO - Saved state for run_id=run_4d14eac927454a359209ff39b9e8d3c4
2025-08-05 14:57:10,482 - flujo - INFO - Saved state for run_id=run_4d14eac927454a359209ff39b9e8d3c4
2025-08-05 14:57:10,485 - flujo - INFO - Saved state for run_id=run_4d14eac927454a359209ff39b9e8d3c4
2025-08-05 14:57:10,488 - flujo - INFO - Saved state for run_id=run_4d14eac927454a359209ff39b9e8d3c4
2025-08-05 14:57:10,496 - flujo - INFO - Saved state for run_id=run_25791cf0ec674c3397308b8ca823d3cc
2025-08-05 14:57:10,498 - flujo - INFO - Saved state for run_id=run_25791cf0ec674c3397308b8ca823d3cc
2025-08-05 14:57:10,501 - flujo - INFO - Saved state for run_id=run_25791cf0ec674c3397308b8ca823d3cc
2025-08-05 14:57:10,503 - flujo - INFO - Saved state for run_id=run_25791cf0ec674c3397308b8ca823d3cc
2025-08-05 14:57:10,510 - flujo - INFO - Saved state for run_id=run_8ba969861a1f475ca1a2e08a83de694f
2025-08-05 14:57:10,513 - flujo - INFO - Saved state for run_id=run_8ba969861a1f475ca1a2e08a83de694f
2025-08-05 14:57:10,516 - flujo - INFO - Saved state for run_id=run_8ba969861a1f475ca1a2e08a83de694f
2025-08-05 14:57:10,518 - flujo - INFO - Saved state for run_id=run_8ba969861a1f475ca1a2e08a83de694f
2025-08-05 14:57:10,525 - flujo - INFO - Saved state for run_id=run_cdbea80d09ef4a0eb9574c09a2a6e50a
2025-08-05 14:57:10,528 - flujo - INFO - Saved state for run_id=run_cdbea80d09ef4a0eb9574c09a2a6e50a
2025-08-05 14:57:10,530 - flujo - INFO - Saved state for run_id=run_cdbea80d09ef4a0eb9574c09a2a6e50a
2025-08-05 14:57:10,532 - flujo - INFO - Saved state for run_id=run_cdbea80d09ef4a0eb9574c09a2a6e50a
2025-08-05 14:57:10,539 - flujo - INFO - Saved state for run_id=run_c5db4247516e46a6be57bb75b7bce5ca
2025-08-05 14:57:10,542 - flujo - INFO - Saved state for run_id=run_c5db4247516e46a6be57bb75b7bce5ca
2025-08-05 14:57:10,544 - flujo - INFO - Saved state for run_id=run_c5db4247516e46a6be57bb75b7bce5ca
2025-08-05 14:57:10,547 - flujo - INFO - Saved state for run_id=run_c5db4247516e46a6be57bb75b7bce5ca
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:10,407 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,417 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,422 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,434 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,438 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,448 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,452 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,461 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,465 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,475 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,480 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,491 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,496 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,506 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,511 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,522 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,525 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,536 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,540 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
DEBUG    flujo:telemetry.py:54 Flujo backend: LocalBackend, executor: <class 'flujo.application.core.ultra_executor.ExecutorCore'>
DEBUG    flujo:telemetry.py:54 Flujo backend: LocalBackend, executor: <class 'flujo.application.core.ultra_executor.ExecutorCore'>
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_e05a20735eca4fdcb2bcc5519212fe08
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_e05a20735eca4fdcb2bcc5519212fe08
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_e05a20735eca4fdcb2bcc5519212fe08
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: b24b85d5b50c4b58b8383d983f6e27820c5c39d6b41fcf98f90302c528d06038
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'solution': 'output'
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_e05a20735eca4fdcb2bcc5519212fe08
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_e05a20735eca4fdcb2bcc5519212fe08
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_e05a20735eca4fdcb2bcc5519212fe08
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_e05a20735eca4fdcb2bcc5519212fe08
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_e05a20735eca4fdcb2bcc5519212fe08
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_e05a20735eca4fdcb2bcc5519212fe08
INFO     flujo:telemetry.py:54 Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw2/test_default_backend_performan0/with_backend_f79fef2c.db
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_2f0cef8d2a3a47f7b57a465844c9ff08
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_2f0cef8d2a3a47f7b57a465844c9ff08
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_2f0cef8d2a3a47f7b57a465844c9ff08
INFO     flujo:telemetry.py:54 Saved state for run_id=run_2f0cef8d2a3a47f7b57a465844c9ff08
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: cbabb10e45ccbe52e90cc111b7d3d5f2e9a7d1114ebf258c3977cecb4792d3b4
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_2f0cef8d2a3a47f7b57a465844c9ff08
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_2f0cef8d2a3a47f7b57a465844c9ff08
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_2f0cef8d2a3a47f7b57a465844c9ff08
INFO     flujo:telemetry.py:54 Saved state for run_id=run_2f0cef8d2a3a47f7b57a465844c9ff08
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_2f0cef8d2a3a47f7b57a465844c9ff08
INFO     flujo:telemetry.py:54 Saved state for run_id=run_2f0cef8d2a3a47f7b57a465844c9ff08
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_2f0cef8d2a3a47f7b57a465844c9ff08
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_2f0cef8d2a3a47f7b57a465844c9ff08
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_2f0cef8d2a3a47f7b57a465844c9ff08
INFO     flujo:telemetry.py:54 Saved state for run_id=run_2f0cef8d2a3a47f7b57a465844c9ff08
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_dcbdc1bd5eb244e9ad1dc1829c388373
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_dcbdc1bd5eb244e9ad1dc1829c388373
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_dcbdc1bd5eb244e9ad1dc1829c388373
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: b4d212e0e904344f7b03fc38cce26f555302a57fcc157003152c35e7973a4d18
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_dcbdc1bd5eb244e9ad1dc1829c388373
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_dcbdc1bd5eb244e9ad1dc1829c388373
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_dcbdc1bd5eb244e9ad1dc1829c388373
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_dcbdc1bd5eb244e9ad1dc1829c388373
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_dcbdc1bd5eb244e9ad1dc1829c388373
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_dcbdc1bd5eb244e9ad1dc1829c388373
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_dcbdc1bd5eb244e9ad1dc1829c388373
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_1797fb7e40e6455c8fc138e24db5a9a8
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_1797fb7e40e6455c8fc138e24db5a9a8
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_1797fb7e40e6455c8fc138e24db5a9a8
INFO     flujo:telemetry.py:54 Saved state for run_id=run_1797fb7e40e6455c8fc138e24db5a9a8
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 95b964da75a3677375d94e5c8ba403da24d7c174a70890bc924b8626f9e94cf7
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_1797fb7e40e6455c8fc138e24db5a9a8
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_1797fb7e40e6455c8fc138e24db5a9a8
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_1797fb7e40e6455c8fc138e24db5a9a8
INFO     flujo:telemetry.py:54 Saved state for run_id=run_1797fb7e40e6455c8fc138e24db5a9a8
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_1797fb7e40e6455c8fc138e24db5a9a8
INFO     flujo:telemetry.py:54 Saved state for run_id=run_1797fb7e40e6455c8fc138e24db5a9a8
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_1797fb7e40e6455c8fc138e24db5a9a8
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_1797fb7e40e6455c8fc138e24db5a9a8
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_1797fb7e40e6455c8fc138e24db5a9a8
INFO     flujo:telemetry.py:54 Saved state for run_id=run_1797fb7e40e6455c8fc138e24db5a9a8
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_6e9cc59c588e4d9e93f7bd190edabdd1
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_6e9cc59c588e4d9e93f7bd190edabdd1
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_6e9cc59c588e4d9e93f7bd190edabdd1
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: d3c3b267fa7861c4d5b8ce6e122ce1c33580073692122a95e8b41f9ced896ff9
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_6e9cc59c588e4d9e93f7bd190edabdd1
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_6e9cc59c588e4d9e93f7bd190edabdd1
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_6e9cc59c588e4d9e93f7bd190edabdd1
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_6e9cc59c588e4d9e93f7bd190edabdd1
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_6e9cc59c588e4d9e93f7bd190edabdd1
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_6e9cc59c588e4d9e93f7bd190edabdd1
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_6e9cc59c588e4d9e93f7bd190edabdd1
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_2c470e6382254dbbbe5b863b59fec944
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_2c470e6382254dbbbe5b863b59fec944
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_2c470e6382254dbbbe5b863b59fec944
INFO     flujo:telemetry.py:54 Saved state for run_id=run_2c470e6382254dbbbe5b863b59fec944
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: e05245abd74ab6ebbf7c2bacea66e3ce3109d9d6f9b6c80448e7dd46ff639537
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_2c470e6382254dbbbe5b863b59fec944
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_2c470e6382254dbbbe5b863b59fec944
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_2c470e6382254dbbbe5b863b59fec944
INFO     flujo:telemetry.py:54 Saved state for run_id=run_2c470e6382254dbbbe5b863b59fec944
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_2c470e6382254dbbbe5b863b59fec944
INFO     flujo:telemetry.py:54 Saved state for run_id=run_2c470e6382254dbbbe5b863b59fec944
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_2c470e6382254dbbbe5b863b59fec944
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_2c470e6382254dbbbe5b863b59fec944
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_2c470e6382254dbbbe5b863b59fec944
INFO     flujo:telemetry.py:54 Saved state for run_id=run_2c470e6382254dbbbe5b863b59fec944
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_737f6f729ede43c98e0603f704161fce
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_737f6f729ede43c98e0603f704161fce
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_737f6f729ede43c98e0603f704161fce
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 4b7b0936b2a411b24a042be1c5744ccf2ecfec0a813a2fad67070874ff42ddce
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_737f6f729ede43c98e0603f704161fce
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_737f6f729ede43c98e0603f704161fce
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_737f6f729ede43c98e0603f704161fce
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_737f6f729ede43c98e0603f704161fce
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_737f6f729ede43c98e0603f704161fce
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_737f6f729ede43c98e0603f704161fce
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_737f6f729ede43c98e0603f704161fce
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_053e79e8e8bb42229081bd4d10b1f66a
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_053e79e8e8bb42229081bd4d10b1f66a
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_053e79e8e8bb42229081bd4d10b1f66a
INFO     flujo:telemetry.py:54 Saved state for run_id=run_053e79e8e8bb42229081bd4d10b1f66a
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: a98f2ea8cc75a39f5dd6e4ddfce648e8b70bd48eeea000f6f329735fdb0fb172
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_053e79e8e8bb42229081bd4d10b1f66a
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_053e79e8e8bb42229081bd4d10b1f66a
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_053e79e8e8bb42229081bd4d10b1f66a
INFO     flujo:telemetry.py:54 Saved state for run_id=run_053e79e8e8bb42229081bd4d10b1f66a
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_053e79e8e8bb42229081bd4d10b1f66a
INFO     flujo:telemetry.py:54 Saved state for run_id=run_053e79e8e8bb42229081bd4d10b1f66a
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_053e79e8e8bb42229081bd4d10b1f66a
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_053e79e8e8bb42229081bd4d10b1f66a
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_053e79e8e8bb42229081bd4d10b1f66a
INFO     flujo:telemetry.py:54 Saved state for run_id=run_053e79e8e8bb42229081bd4d10b1f66a
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_95f6f8bbc5a84ab78f083dddd9a5517e
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_95f6f8bbc5a84ab78f083dddd9a5517e
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_95f6f8bbc5a84ab78f083dddd9a5517e
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: d5d23f52f02c73fdd1d830ca7bca00d65fb4cb074c754eba6ccf96852da25b5c
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_95f6f8bbc5a84ab78f083dddd9a5517e
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_95f6f8bbc5a84ab78f083dddd9a5517e
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_95f6f8bbc5a84ab78f083dddd9a5517e
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_95f6f8bbc5a84ab78f083dddd9a5517e
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_95f6f8bbc5a84ab78f083dddd9a5517e
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_95f6f8bbc5a84ab78f083dddd9a5517e
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_95f6f8bbc5a84ab78f083dddd9a5517e
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_1927b545382841fb918531d4a9152856
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_1927b545382841fb918531d4a9152856
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_1927b545382841fb918531d4a9152856
INFO     flujo:telemetry.py:54 Saved state for run_id=run_1927b545382841fb918531d4a9152856
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 5bb7f525bcd2ab7d9d7d399e41dda7926db969181fb6b391cad4d1fba4856e2d
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_1927b545382841fb918531d4a9152856
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_1927b545382841fb918531d4a9152856
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_1927b545382841fb918531d4a9152856
INFO     flujo:telemetry.py:54 Saved state for run_id=run_1927b545382841fb918531d4a9152856
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_1927b545382841fb918531d4a9152856
INFO     flujo:telemetry.py:54 Saved state for run_id=run_1927b545382841fb918531d4a9152856
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_1927b545382841fb918531d4a9152856
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_1927b545382841fb918531d4a9152856
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_1927b545382841fb918531d4a9152856
INFO     flujo:telemetry.py:54 Saved state for run_id=run_1927b545382841fb918531d4a9152856
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_ea999694241e411f8b96f226c7347a03
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_ea999694241e411f8b96f226c7347a03
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_ea999694241e411f8b96f226c7347a03
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 786ac7b39e127884989e895972e7aec5b9cde437531abe0f61a2ac1393fa83d4
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_ea999694241e411f8b96f226c7347a03
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_ea999694241e411f8b96f226c7347a03
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_ea999694241e411f8b96f226c7347a03
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_ea999694241e411f8b96f226c7347a03
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_ea999694241e411f8b96f226c7347a03
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_ea999694241e411f8b96f226c7347a03
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_ea999694241e411f8b96f226c7347a03
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_4d14eac927454a359209ff39b9e8d3c4
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_4d14eac927454a359209ff39b9e8d3c4
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_4d14eac927454a359209ff39b9e8d3c4
INFO     flujo:telemetry.py:54 Saved state for run_id=run_4d14eac927454a359209ff39b9e8d3c4
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 195fbf9604bc49c372bf78e7ad9aa51e5bdf0f3274a9bee623932ff2ad27ccd7
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_4d14eac927454a359209ff39b9e8d3c4
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_4d14eac927454a359209ff39b9e8d3c4
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_4d14eac927454a359209ff39b9e8d3c4
INFO     flujo:telemetry.py:54 Saved state for run_id=run_4d14eac927454a359209ff39b9e8d3c4
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_4d14eac927454a359209ff39b9e8d3c4
INFO     flujo:telemetry.py:54 Saved state for run_id=run_4d14eac927454a359209ff39b9e8d3c4
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_4d14eac927454a359209ff39b9e8d3c4
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_4d14eac927454a359209ff39b9e8d3c4
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_4d14eac927454a359209ff39b9e8d3c4
INFO     flujo:telemetry.py:54 Saved state for run_id=run_4d14eac927454a359209ff39b9e8d3c4
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_f988e0a7e73742b7af737ac8a4b7b88d
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_f988e0a7e73742b7af737ac8a4b7b88d
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_f988e0a7e73742b7af737ac8a4b7b88d
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 1ba35ea2b4d36c7761fcf89e822fc65b950b4ca3878c036549e8d65f085496ac
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_f988e0a7e73742b7af737ac8a4b7b88d
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_f988e0a7e73742b7af737ac8a4b7b88d
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_f988e0a7e73742b7af737ac8a4b7b88d
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_f988e0a7e73742b7af737ac8a4b7b88d
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_f988e0a7e73742b7af737ac8a4b7b88d
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_f988e0a7e73742b7af737ac8a4b7b88d
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_f988e0a7e73742b7af737ac8a4b7b88d
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_25791cf0ec674c3397308b8ca823d3cc
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_25791cf0ec674c3397308b8ca823d3cc
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_25791cf0ec674c3397308b8ca823d3cc
INFO     flujo:telemetry.py:54 Saved state for run_id=run_25791cf0ec674c3397308b8ca823d3cc
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 0c0aa730b6c5e00fc575f332e322e97b590ba2901011b1cf79b6aac49a0e439d
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_25791cf0ec674c3397308b8ca823d3cc
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_25791cf0ec674c3397308b8ca823d3cc
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_25791cf0ec674c3397308b8ca823d3cc
INFO     flujo:telemetry.py:54 Saved state for run_id=run_25791cf0ec674c3397308b8ca823d3cc
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_25791cf0ec674c3397308b8ca823d3cc
INFO     flujo:telemetry.py:54 Saved state for run_id=run_25791cf0ec674c3397308b8ca823d3cc
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_25791cf0ec674c3397308b8ca823d3cc
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_25791cf0ec674c3397308b8ca823d3cc
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_25791cf0ec674c3397308b8ca823d3cc
INFO     flujo:telemetry.py:54 Saved state for run_id=run_25791cf0ec674c3397308b8ca823d3cc
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_4c4e5ccdcc1c4d4ab965e8feff2fdf4d
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_4c4e5ccdcc1c4d4ab965e8feff2fdf4d
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_4c4e5ccdcc1c4d4ab965e8feff2fdf4d
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 7f97ba3778e25373a4bf51d58ce69f5a9e5c9f3bb5271cac6753057037f344fb
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_4c4e5ccdcc1c4d4ab965e8feff2fdf4d
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_4c4e5ccdcc1c4d4ab965e8feff2fdf4d
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_4c4e5ccdcc1c4d4ab965e8feff2fdf4d
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_4c4e5ccdcc1c4d4ab965e8feff2fdf4d
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_4c4e5ccdcc1c4d4ab965e8feff2fdf4d
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_4c4e5ccdcc1c4d4ab965e8feff2fdf4d
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_4c4e5ccdcc1c4d4ab965e8feff2fdf4d
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_8ba969861a1f475ca1a2e08a83de694f
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_8ba969861a1f475ca1a2e08a83de694f
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_8ba969861a1f475ca1a2e08a83de694f
INFO     flujo:telemetry.py:54 Saved state for run_id=run_8ba969861a1f475ca1a2e08a83de694f
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 31dab69761ac1860b673c39ffb4db419d47d446ed26c5ca6ed330513432c1f05
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_8ba969861a1f475ca1a2e08a83de694f
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_8ba969861a1f475ca1a2e08a83de694f
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_8ba969861a1f475ca1a2e08a83de694f
INFO     flujo:telemetry.py:54 Saved state for run_id=run_8ba969861a1f475ca1a2e08a83de694f
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_8ba969861a1f475ca1a2e08a83de694f
INFO     flujo:telemetry.py:54 Saved state for run_id=run_8ba969861a1f475ca1a2e08a83de694f
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_8ba969861a1f475ca1a2e08a83de694f
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_8ba969861a1f475ca1a2e08a83de694f
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_8ba969861a1f475ca1a2e08a83de694f
INFO     flujo:telemetry.py:54 Saved state for run_id=run_8ba969861a1f475ca1a2e08a83de694f
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_4643cfcce41d4c788aabe34db018011d
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_4643cfcce41d4c788aabe34db018011d
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_4643cfcce41d4c788aabe34db018011d
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: ea2ee2ea856a4a6e8ede499db9321c67479a33531651cb396a30a27442a907ed
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_4643cfcce41d4c788aabe34db018011d
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_4643cfcce41d4c788aabe34db018011d
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_4643cfcce41d4c788aabe34db018011d
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_4643cfcce41d4c788aabe34db018011d
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_4643cfcce41d4c788aabe34db018011d
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_4643cfcce41d4c788aabe34db018011d
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_4643cfcce41d4c788aabe34db018011d
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_cdbea80d09ef4a0eb9574c09a2a6e50a
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_cdbea80d09ef4a0eb9574c09a2a6e50a
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_cdbea80d09ef4a0eb9574c09a2a6e50a
INFO     flujo:telemetry.py:54 Saved state for run_id=run_cdbea80d09ef4a0eb9574c09a2a6e50a
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 1430191d014d4ec18ecdb408471d415e10a8cbc2f04c1944491f89356a01749a
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_cdbea80d09ef4a0eb9574c09a2a6e50a
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_cdbea80d09ef4a0eb9574c09a2a6e50a
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_cdbea80d09ef4a0eb9574c09a2a6e50a
INFO     flujo:telemetry.py:54 Saved state for run_id=run_cdbea80d09ef4a0eb9574c09a2a6e50a
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_cdbea80d09ef4a0eb9574c09a2a6e50a
INFO     flujo:telemetry.py:54 Saved state for run_id=run_cdbea80d09ef4a0eb9574c09a2a6e50a
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_cdbea80d09ef4a0eb9574c09a2a6e50a
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_cdbea80d09ef4a0eb9574c09a2a6e50a
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_cdbea80d09ef4a0eb9574c09a2a6e50a
INFO     flujo:telemetry.py:54 Saved state for run_id=run_cdbea80d09ef4a0eb9574c09a2a6e50a
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_53e638b45c6d4f98a2de11888e9cd5b0
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_53e638b45c6d4f98a2de11888e9cd5b0
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_53e638b45c6d4f98a2de11888e9cd5b0
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: f4a78a4cf901aca693885af0735dcccaa4e26918829ea94cc3b798d121bdb1af
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_53e638b45c6d4f98a2de11888e9cd5b0
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_53e638b45c6d4f98a2de11888e9cd5b0
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_53e638b45c6d4f98a2de11888e9cd5b0
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_53e638b45c6d4f98a2de11888e9cd5b0
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_53e638b45c6d4f98a2de11888e9cd5b0
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_53e638b45c6d4f98a2de11888e9cd5b0
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_53e638b45c6d4f98a2de11888e9cd5b0
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_c5db4247516e46a6be57bb75b7bce5ca
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_c5db4247516e46a6be57bb75b7bce5ca
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_c5db4247516e46a6be57bb75b7bce5ca
INFO     flujo:telemetry.py:54 Saved state for run_id=run_c5db4247516e46a6be57bb75b7bce5ca
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 92bb406212358cc3ea2b5af749e28a4adcaaf14dd3a85bf5e4d4504a228fc673
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_c5db4247516e46a6be57bb75b7bce5ca
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_c5db4247516e46a6be57bb75b7bce5ca
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_c5db4247516e46a6be57bb75b7bce5ca
INFO     flujo:telemetry.py:54 Saved state for run_id=run_c5db4247516e46a6be57bb75b7bce5ca
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_c5db4247516e46a6be57bb75b7bce5ca
INFO     flujo:telemetry.py:54 Saved state for run_id=run_c5db4247516e46a6be57bb75b7bce5ca
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_c5db4247516e46a6be57bb75b7bce5ca
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_c5db4247516e46a6be57bb75b7bce5ca
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_c5db4247516e46a6be57bb75b7bce5ca
INFO     flujo:telemetry.py:54 Saved state for run_id=run_c5db4247516e46a6be57bb75b7bce5ca
_ TestPersistencePerformanceOverhead.test_persistence_overhead_with_large_context _
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_persistence_performance.py:182: in test_persistence_overhead_with_large_context
    assert overhead_percentage <= overhead_limit, (
E   AssertionError: Persistence overhead with large context (884.36%) exceeds 35.0%
E   assert 884.3614790926946 <= 35.0
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:10,561 - flujo - INFO - Counting string output as 1 token for step 'solution': 'output'
2025-08-05 14:57:10,566 - flujo - INFO - Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw2/test_persistence_overhead_with0/with_backend_36555ed7.db
2025-08-05 14:57:10,571 - flujo - INFO - Saved state for run_id=run_e79eee515c3a4fc08f1d7141c4c7a6d9
2025-08-05 14:57:10,574 - flujo - INFO - Saved state for run_id=run_e79eee515c3a4fc08f1d7141c4c7a6d9
2025-08-05 14:57:10,579 - flujo - INFO - Saved state for run_id=run_e79eee515c3a4fc08f1d7141c4c7a6d9
2025-08-05 14:57:10,583 - flujo - INFO - Saved state for run_id=run_e79eee515c3a4fc08f1d7141c4c7a6d9
2025-08-05 14:57:10,591 - flujo - INFO - Saved state for run_id=run_e310f2c70e514578bbe1c68ac3fbe080
2025-08-05 14:57:10,595 - flujo - INFO - Saved state for run_id=run_e310f2c70e514578bbe1c68ac3fbe080
2025-08-05 14:57:10,598 - flujo - INFO - Saved state for run_id=run_e310f2c70e514578bbe1c68ac3fbe080
2025-08-05 14:57:10,600 - flujo - INFO - Saved state for run_id=run_e310f2c70e514578bbe1c68ac3fbe080
2025-08-05 14:57:10,608 - flujo - INFO - Saved state for run_id=run_f436e11423414f8a848bb65de0679f06
2025-08-05 14:57:10,611 - flujo - INFO - Saved state for run_id=run_f436e11423414f8a848bb65de0679f06
2025-08-05 14:57:10,614 - flujo - INFO - Saved state for run_id=run_f436e11423414f8a848bb65de0679f06
2025-08-05 14:57:10,617 - flujo - INFO - Saved state for run_id=run_f436e11423414f8a848bb65de0679f06
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:10,572 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,587 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,592 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,604 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
2025-08-05 14:57:10,608 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
DEBUG    flujo:telemetry.py:54 Flujo backend: LocalBackend, executor: <class 'flujo.application.core.ultra_executor.ExecutorCore'>
DEBUG    flujo:telemetry.py:54 Flujo backend: LocalBackend, executor: <class 'flujo.application.core.ultra_executor.ExecutorCore'>
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_3da1c740b33c43e4952c4babb9bf545e
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_3da1c740b33c43e4952c4babb9bf545e
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_3da1c740b33c43e4952c4babb9bf545e
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 180e0f620086327ee890b9e14ea62d00b4675c238266cfdc734253740e07342d
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'solution': 'output'
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_3da1c740b33c43e4952c4babb9bf545e
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_3da1c740b33c43e4952c4babb9bf545e
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_3da1c740b33c43e4952c4babb9bf545e
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_3da1c740b33c43e4952c4babb9bf545e
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_3da1c740b33c43e4952c4babb9bf545e
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_3da1c740b33c43e4952c4babb9bf545e
INFO     flujo:telemetry.py:54 Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw2/test_persistence_overhead_with0/with_backend_36555ed7.db
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_e79eee515c3a4fc08f1d7141c4c7a6d9
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_e79eee515c3a4fc08f1d7141c4c7a6d9
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_e79eee515c3a4fc08f1d7141c4c7a6d9
INFO     flujo:telemetry.py:54 Saved state for run_id=run_e79eee515c3a4fc08f1d7141c4c7a6d9
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: ffe90a8c4b9e54ce977d82e5cae1b35405fb07a8571e61eb561b2bba85710d30
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_e79eee515c3a4fc08f1d7141c4c7a6d9
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_e79eee515c3a4fc08f1d7141c4c7a6d9
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_e79eee515c3a4fc08f1d7141c4c7a6d9
INFO     flujo:telemetry.py:54 Saved state for run_id=run_e79eee515c3a4fc08f1d7141c4c7a6d9
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_e79eee515c3a4fc08f1d7141c4c7a6d9
INFO     flujo:telemetry.py:54 Saved state for run_id=run_e79eee515c3a4fc08f1d7141c4c7a6d9
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_e79eee515c3a4fc08f1d7141c4c7a6d9
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_e79eee515c3a4fc08f1d7141c4c7a6d9
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_e79eee515c3a4fc08f1d7141c4c7a6d9
INFO     flujo:telemetry.py:54 Saved state for run_id=run_e79eee515c3a4fc08f1d7141c4c7a6d9
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_12eababf1c42422ba75cd9353b4c0efe
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_12eababf1c42422ba75cd9353b4c0efe
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_12eababf1c42422ba75cd9353b4c0efe
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 090839b983d31fdb36b1fc1f97df360278e2edc095727b6dbd572f32bf6613e7
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_12eababf1c42422ba75cd9353b4c0efe
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_12eababf1c42422ba75cd9353b4c0efe
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_12eababf1c42422ba75cd9353b4c0efe
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_12eababf1c42422ba75cd9353b4c0efe
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_12eababf1c42422ba75cd9353b4c0efe
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_12eababf1c42422ba75cd9353b4c0efe
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_12eababf1c42422ba75cd9353b4c0efe
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_e310f2c70e514578bbe1c68ac3fbe080
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_e310f2c70e514578bbe1c68ac3fbe080
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_e310f2c70e514578bbe1c68ac3fbe080
INFO     flujo:telemetry.py:54 Saved state for run_id=run_e310f2c70e514578bbe1c68ac3fbe080
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: d34de9a7b7596b807ec0749e89e481cee9c1c2c7da7223fedee72fd2fa7f7714
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_e310f2c70e514578bbe1c68ac3fbe080
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_e310f2c70e514578bbe1c68ac3fbe080
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_e310f2c70e514578bbe1c68ac3fbe080
INFO     flujo:telemetry.py:54 Saved state for run_id=run_e310f2c70e514578bbe1c68ac3fbe080
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_e310f2c70e514578bbe1c68ac3fbe080
INFO     flujo:telemetry.py:54 Saved state for run_id=run_e310f2c70e514578bbe1c68ac3fbe080
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_e310f2c70e514578bbe1c68ac3fbe080
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_e310f2c70e514578bbe1c68ac3fbe080
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_e310f2c70e514578bbe1c68ac3fbe080
INFO     flujo:telemetry.py:54 Saved state for run_id=run_e310f2c70e514578bbe1c68ac3fbe080
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_f7044b88d85242cbbb27a734e8a08851
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_f7044b88d85242cbbb27a734e8a08851
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_f7044b88d85242cbbb27a734e8a08851
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 62c559ac107d7cda9b86671cf92cac9bfb4a5cb8714713ded7bebc05b2f0c3a2
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_f7044b88d85242cbbb27a734e8a08851
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_f7044b88d85242cbbb27a734e8a08851
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_f7044b88d85242cbbb27a734e8a08851
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_f7044b88d85242cbbb27a734e8a08851
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_f7044b88d85242cbbb27a734e8a08851
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_f7044b88d85242cbbb27a734e8a08851
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_f7044b88d85242cbbb27a734e8a08851
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_f436e11423414f8a848bb65de0679f06
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_f436e11423414f8a848bb65de0679f06
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_f436e11423414f8a848bb65de0679f06
INFO     flujo:telemetry.py:54 Saved state for run_id=run_f436e11423414f8a848bb65de0679f06
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: solution
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 0715898706fe28bb87aa814f9a4be560765ab170051c3a701f7bbfda82471e37
DEBUG    flujo:telemetry.py:54 Cache miss for step: solution
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: solution
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
DEBUG    flujo:telemetry.py:54 Cached result for step: solution
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_f436e11423414f8a848bb65de0679f06
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_f436e11423414f8a848bb65de0679f06
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_f436e11423414f8a848bb65de0679f06
INFO     flujo:telemetry.py:54 Saved state for run_id=run_f436e11423414f8a848bb65de0679f06
DEBUG    flujo.application.core.state_manager:state_manager.py:294 Skipped context serialization for unchanged run run_f436e11423414f8a848bb65de0679f06
INFO     flujo:telemetry.py:54 Saved state for run_id=run_f436e11423414f8a848bb65de0679f06
DEBUG    flujo.application.core.state_manager:state_manager.py:259 About to serialize context for run run_f436e11423414f8a848bb65de0679f06
DEBUG    flujo.application.core.state_manager:state_manager.py:262 Successfully serialized context for run run_f436e11423414f8a848bb65de0679f06
DEBUG    flujo.application.core.state_manager:state_manager.py:266 Serialized and cached context for run run_f436e11423414f8a848bb65de0679f06
INFO     flujo:telemetry.py:54 Saved state for run_id=run_f436e11423414f8a848bb65de0679f06
____________ test_plugin_receives_context_and_strict_plugin_errors _____________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_pipeline_context.py:123: in test_plugin_receives_context_and_strict_plugin_errors
    assert kwargs_plugin.kwargs == {}
E   assert None == {}
E    +  where None = <tests.unit.test_pipeline_context.KwargsPlugin object at 0x1141b5f50>.kwargs
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:10,677 - flujo - INFO - Counting string output as 1 token for step 's': 'in'
------------------------------ Captured log call -------------------------------
DEBUG    flujo:telemetry.py:54 Flujo backend: LocalBackend, executor: <class 'flujo.application.core.ultra_executor.ExecutorCore'>
DEBUG    flujo:telemetry.py:54 === LOCAL BACKEND EXECUTE STEP ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: s
DEBUG    flujo:telemetry.py:54 Step is ParallelStep: False
DEBUG    flujo:telemetry.py:54 === EXECUTOR CORE EXECUTE ===
DEBUG    flujo:telemetry.py:54 Step type: <class 'flujo.domain.dsl.step.Step'>
DEBUG    flujo:telemetry.py:54 Step name: s
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with breach_event: False
DEBUG    flujo:telemetry.py:54 ExecutorCore.execute called with limits: None
DEBUG    flujo:telemetry.py:54 Generated cache key: 787fac5a5193ea9ef0d0007ffb70067dcb101f60db811db2a05941668f2c6576
DEBUG    flujo:telemetry.py:54 Cache miss for step: s
DEBUG    flujo:telemetry.py:54 Routing to agent step handler: s
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 's': 'in'
DEBUG    flujo:telemetry.py:54 Cached result for step: s
_____________________ test_file_backend_resume_after_crash _____________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_persistence_backends.py:96: in test_file_backend_resume_after_crash
    assert wf.current_step_index == 3
E   AssertionError: assert 2 == 3
E    +  where 2 = WorkflowState(run_id='run_file', pipeline_id='unknown', pipeline_name='unknown', pipeline_version='latest', current_st...ted_at=datetime.datetime(2025, 8, 5, 14, 57, 10, 889170), updated_at=datetime.datetime(2025, 8, 5, 14, 57, 10, 897858)).current_step_index
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:10,689 - flujo - INFO - Logfire telemetry is disabled or failed to initialize. Using standard Python logging.
2025-08-05 14:57:10,890 - flujo - INFO - Counting string output as 1 token for step 's1': 'mid'
2025-08-05 14:57:10,896 - flujo - INFO - Counting string output as 1 token for step 's1': 'mid'
2025-08-05 14:57:10,896 - flujo - INFO - Counting string output as 1 token for step 's2': 'mid done'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 's1': 'mid'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 's2': 'mid done'
_ TestSchemaMigrationRobustness.test_migration_handles_schema_version_changes __
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_schema_migration_robustness.py:317: in test_migration_handles_schema_version_changes
    await backend2.save_run_start(run_data)
flujo/state/backends/sqlite.py:1197: in save_run_start
    await self._with_retries(_save)
flujo/state/backends/sqlite.py:690: in _with_retries
    result = await coro_func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/state/backends/sqlite.py:1173: in _save
    await db.execute(
.venv/lib/python3.11/site-packages/aiosqlite/core.py:183: in execute
    cursor = await self._execute(self._conn.execute, sql, parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:122: in _execute
    return await future
           ^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:105: in run
    result = function()
             ^^^^^^^^^^
E   sqlite3.OperationalError: table runs has no column named execution_time_ms
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:10,976 - flujo - INFO - Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw2/test_migration_handles_schema_0/test_migration.db
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw2/test_migration_handles_schema_0/test_migration.db
____________________ test_sqlite_backend_resume_after_crash ____________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_persistence_backends.py:125: in test_sqlite_backend_resume_after_crash
    assert wf.current_step_index == 3
E   AssertionError: assert 2 == 3
E    +  where 2 = WorkflowState(run_id='run_sqlite', pipeline_id='unknown', pipeline_name='unknown', pipeline_version='latest', current_...ted_at=datetime.datetime(2025, 8, 5, 14, 57, 11, 535383), updated_at=datetime.datetime(2025, 8, 5, 14, 57, 11, 554389)).current_step_index
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:11,227 - flujo - INFO - Logfire telemetry is disabled or failed to initialize. Using standard Python logging.
{
    "name": "s",
    "context": {
        "trace_id": "0x7def78a7a5612fcccb5f42770b6ad00f",
        "span_id": "0xd125f8afc10ff9a4",
        "trace_state": "[]"
    },
    "kind": "SpanKind.INTERNAL",
    "parent_id": "0x15167691638b5cf9",
    "start_time": "2025-08-05T21:57:06.408449Z",
    "end_time": "2025-08-05T21:57:06.408751Z",
    "status": {
        "status_code": "OK"
    },
    "attributes": {
        "step_input": "in",
        "success": true,
        "latency_s": 0.000140583
    },
    "events": [],
    "links": [],
    "resource": {
        "attributes": {
            "telemetry.sdk.language": "python",
            "telemetry.sdk.name": "opentelemetry",
            "telemetry.sdk.version": "1.36.0",
            "service.name": "unknown_service"
        },
        "schema_url": ""
    }
}
{
    "name": "pipeline_run",
    "context": {
        "trace_id": "0x7def78a7a5612fcccb5f42770b6ad00f",
        "span_id": "0x15167691638b5cf9",
        "trace_state": "[]"
    },
    "kind": "SpanKind.INTERNAL",
    "parent_id": null,
    "start_time": "2025-08-05T21:57:06.408334Z",
    "end_time": "2025-08-05T21:57:06.409342Z",
    "status": {
        "status_code": "OK"
    },
    "attributes": {
        "initial_input": "in"
    },
    "events": [],
    "links": [],
    "resource": {
        "attributes": {
            "telemetry.sdk.language": "python",
            "telemetry.sdk.name": "opentelemetry",
            "telemetry.sdk.version": "1.36.0",
            "service.name": "unknown_service"
        },
        "schema_url": ""
    }
}
2025-08-05 14:57:11,531 - flujo - INFO - Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_sqlite_backend_resume_aft0/state.db
2025-08-05 14:57:11,536 - flujo - INFO - Saved state for run_id=run_sqlite
2025-08-05 14:57:11,537 - flujo - INFO - Counting string output as 1 token for step 's1': 'mid'
2025-08-05 14:57:11,545 - flujo - INFO - Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_sqlite_backend_resume_aft0/state.db
2025-08-05 14:57:11,548 - flujo - INFO - Saved state for run_id=run_sqlite
2025-08-05 14:57:11,548 - flujo - INFO - Counting string output as 1 token for step 's1': 'mid'
2025-08-05 14:57:11,550 - flujo - INFO - Counting string output as 1 token for step 's2': 'mid done'
2025-08-05 14:57:11,552 - flujo - INFO - Saved state for run_id=run_sqlite
2025-08-05 14:57:11,555 - flujo - INFO - Saved state for run_id=run_sqlite
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_sqlite_backend_resume_aft0/state.db
INFO     flujo:telemetry.py:54 Saved state for run_id=run_sqlite
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 's1': 'mid'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 's2': 'mid done'
INFO     flujo:telemetry.py:54 Saved state for run_id=run_sqlite
INFO     flujo:telemetry.py:54 Saved state for run_id=run_sqlite
_______________________ test_runner_respects_max_retries _______________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_pipeline_runner.py:35: in test_runner_respects_max_retries
    assert agent.call_count == 3
E   assert 1 == 3
E    +  where 1 = <flujo.testing.utils.StubAgent object at 0x11341c510>.call_count
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:11,833 - flujo - INFO - Counting string output as 1 token for step 'test': 'a'
2025-08-05 14:57:11,833 - flujo - WARNING - Step 'test' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:11,833 - flujo - ERROR - Step 'test' plugin failed: Plugin failed: None
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'test': 'a'
ERROR    flujo:telemetry.py:54 Step 'test' plugin failed: Plugin failed: None
WARNING  flujo:telemetry.py:54 Step 'test' failed. Halting pipeline execution.
________________________ test_feedback_enriches_prompt _________________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_pipeline_runner.py:51: in test_feedback_enriches_prompt
    assert sol_agent.call_count == 2
E   assert 1 == 2
E    +  where 1 = <flujo.testing.utils.StubAgent object at 0x1130b0050>.call_count
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:11,839 - flujo - INFO - Counting string output as 1 token for step 'solution': 'sol1'
2025-08-05 14:57:11,840 - flujo - WARNING - Step 'solution' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:11,840 - flujo - ERROR - Step 'solution' plugin failed: Plugin failed: SQL Error: XYZ
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'solution': 'sol1'
ERROR    flujo:telemetry.py:54 Step 'solution' plugin failed: Plugin failed: SQL Error: XYZ
WARNING  flujo:telemetry.py:54 Step 'solution' failed. Halting pipeline execution.
___________________ test_timeout_and_redirect_loop_detection ___________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_pipeline_runner.py:142: in test_timeout_and_redirect_loop_detection
    with pytest.raises(InfiniteRedirectError):
E   Failed: DID NOT RAISE <class 'flujo.exceptions.InfiniteRedirectError'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:11,853 - flujo - INFO - Counting string output as 1 token for step 's': 'ok'
2025-08-05 14:57:11,904 - flujo - INFO - Counting string output as 1 token for step 'loop': 'a1'
2025-08-05 14:57:11,904 - flujo - INFO - Step 'loop' redirecting to agent: <flujo.testing.utils.StubAgent object at 0x11329ad10>
2025-08-05 14:57:11,904 - flujo - INFO - Counting string output as 1 token for step 'loop': 'a2'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 's': 'ok'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'loop': 'a1'
INFO     flujo:telemetry.py:54 Step 'loop' redirecting to agent: <flujo.testing.utils.StubAgent object at 0x11329ad10>
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'loop': 'a2'
_______________________ test_resources_passed_to_plugin ________________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_pipeline_runner_with_resources.py:93: in test_resources_passed_to_plugin
    assert result.step_history[0].success
E   assert False
E    +  where False = StepResult(name='plugin_step', output='queried_products', success=False, attempts=1, latency_s=-334744522224296.5, tok....validate() missing 1 required keyword-only argument: 'resources'", branch_context=None, metadata_={}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:11,943 - flujo - INFO - Counting string output as 1 token for step 'plugin_step': 'queried_products'
2025-08-05 14:57:11,943 - flujo - WARNING - Step 'plugin_step' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:11,943 - flujo - ERROR - Plugin ResourceUsingPlugin failed: ResourceUsingPlugin.validate() missing 1 required keyword-only argument: 'resources'
2025-08-05 14:57:11,943 - flujo - ERROR - Step 'plugin_step' plugin failed: Plugin ResourceUsingPlugin failed: ResourceUsingPlugin.validate() missing 1 required keyword-only argument: 'resources'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'plugin_step': 'queried_products'
ERROR    flujo:telemetry.py:54 Plugin ResourceUsingPlugin failed: ResourceUsingPlugin.validate() missing 1 required keyword-only argument: 'resources'
ERROR    flujo:telemetry.py:54 Step 'plugin_step' plugin failed: Plugin ResourceUsingPlugin failed: ResourceUsingPlugin.validate() missing 1 required keyword-only argument: 'resources'
WARNING  flujo:telemetry.py:54 Step 'plugin_step' failed. Halting pipeline execution.
_____________________ test_prompt_processor_modifies_input _____________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_processors.py:51: in test_prompt_processor_modifies_input
    assert agent.inputs[0] == "hello world"
E   AssertionError: assert 'hello' == 'hello world'
E
E     - hello world
E     + hello
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:11,995 - flujo - INFO - Counting string output as 1 token for step 'solution': 'ok'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'solution': 'ok'
_______________________ test_processor_receives_context ________________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_processors.py:71: in test_processor_receives_context
    assert agent.inputs[0].startswith("X:")
E   AssertionError: assert False
E    +  where False = <built-in method startswith of str object at 0x1120a0770>('X:')
E    +    where <built-in method startswith of str object at 0x1120a0770> = 'hello'.startswith
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:12,003 - flujo - INFO - Counting string output as 1 token for step 'solution': 'ok'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'solution': 'ok'
______________ test_redirect_loop_detected_with_unhashable_agents ______________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_redirect_loop_unhashable.py:41: in test_redirect_loop_detected_with_unhashable_agents
    with pytest.raises(InfiniteRedirectError):
E   Failed: DID NOT RAISE <class 'flujo.exceptions.InfiniteRedirectError'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:12,108 - flujo - INFO - Counting string output as 1 token for step 'loop': 'a1'
2025-08-05 14:57:12,109 - flujo - INFO - Step 'loop' redirecting to agent: <tests.integration.test_redirect_loop_unhashable.UnhashableAgent object at 0x113543810>
2025-08-05 14:57:12,109 - flujo - INFO - Counting string output as 1 token for step 'loop': 'a2'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'loop': 'a1'
INFO     flujo:telemetry.py:54 Step 'loop' redirecting to agent: <tests.integration.test_redirect_loop_unhashable.UnhashableAgent object at 0x113543810>
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'loop': 'a2'
____________ test_refine_until_with_context_updates_error_handling _____________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_refine_until_with_context_updates.py:146: in test_refine_until_with_context_updates_error_handling
    assert (
E   AssertionError: assert 'loop exited by condition, but last iteration body failed' in 'loop terminated after reaching max_loops (5)'
E    +  where 'loop terminated after reaching max_loops (5)' = <built-in method lower of str object at 0x1136f6550>()
E    +    where <built-in method lower of str object at 0x1136f6550> = 'Loop terminated after reaching max_loops (5)'.lower
E    +      where 'Loop terminated after reaching max_loops (5)' = StepResult(name='error_refine', output='refined_content_6', success=False, attempts=5, latency_s=0.006436416995711625,....16999999999999998, refinement_data={}), metadata_={'iterations': 5, 'exit_reason': 'max_iterations'}, step_history=[]).feedback
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === error_refine
2025-08-05 14:57:12,146 - flujo - INFO - LoopStep 'error_refine': Starting Iteration 1/5
2025-08-05 14:57:12,147 - flujo - INFO - Counting string output as 1 token for step 'refine_with_error_step': 'refined_content_1'
2025-08-05 14:57:12,147 - flujo - INFO - Counting string output as 1 token for step '_capture_artifact': 'refined_content_1'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] source_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_bed9c702567c4e5390bbefaef0b51cfa', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'refinement_count': 1, 'total_iterations': 2, 'refinement_history': ['refinement_1'], 'current_quality': 0.07, 'best_quality': 0.07, 'refinement_data': {}}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_bed9c702567c4e5390bbefaef0b51cfa
[DEBUG] actual_source_value: run_bed9c702567c4e5390bbefaef0b51cfa
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: refinement_count
[DEBUG] current_value: 1
[DEBUG] actual_source_value: 1
[DEBUG] Field unchanged: refinement_count
[DEBUG] Processing field: total_iterations
[DEBUG] current_value: 2
[DEBUG] actual_source_value: 2
[DEBUG] Field unchanged: total_iterations
[DEBUG] Processing field: refinement_history
[DEBUG] current_value: ['refinement_1']
[DEBUG] actual_source_value: ['refinement_1']
[DEBUG] Merging lists for field: refinement_history
[DEBUG] No new items to add to list field: refinement_history
[DEBUG] Processing field: current_quality
[DEBUG] current_value: 0.07
[DEBUG] actual_source_value: 0.07
[DEBUG] Field unchanged: current_quality
[DEBUG] Processing field: best_quality
[DEBUG] current_value: 0.07
[DEBUG] actual_source_value: 0.07
[DEBUG] Field unchanged: best_quality
[DEBUG] Processing field: refinement_data
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: refinement_data
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:12,148 - flujo - INFO - LoopStep 'error_refine': Starting Iteration 2/5
2025-08-05 14:57:12,148 - flujo - WARNING - Step 'refine_with_error_step' agent execution attempt 1 failed: Intentional failure in refinement 2
2025-08-05 14:57:12,148 - flujo - INFO - Counting string output as 1 token for step 'refine_with_error_step': 'refined_content_3'
2025-08-05 14:57:12,148 - flujo - INFO - Counting string output as 1 token for step '_capture_artifact': 'refined_content_3'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] source_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_bed9c702567c4e5390bbefaef0b51cfa', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'refinement_count': 3, 'total_iterations': 5, 'refinement_history': ['refinement_1', 'refinement_2', 'refinement_3'], 'current_quality': 0.11, 'best_quality': 0.11, 'refinement_data': {}}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_bed9c702567c4e5390bbefaef0b51cfa
[DEBUG] actual_source_value: run_bed9c702567c4e5390bbefaef0b51cfa
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: refinement_count
[DEBUG] current_value: 3
[DEBUG] actual_source_value: 3
[DEBUG] Field unchanged: refinement_count
[DEBUG] Processing field: total_iterations
[DEBUG] current_value: 5
[DEBUG] actual_source_value: 5
[DEBUG] Field unchanged: total_iterations
[DEBUG] Processing field: refinement_history
[DEBUG] current_value: ['refinement_1', 'refinement_2', 'refinement_3']
[DEBUG] actual_source_value: ['refinement_1', 'refinement_2', 'refinement_3']
[DEBUG] Merging lists for field: refinement_history
[DEBUG] No new items to add to list field: refinement_history
[DEBUG] Processing field: current_quality
[DEBUG] current_value: 0.11
[DEBUG] actual_source_value: 0.11
[DEBUG] Field unchanged: current_quality
[DEBUG] Processing field: best_quality
[DEBUG] current_value: 0.11
[DEBUG] actual_source_value: 0.11
[DEBUG] Field unchanged: best_quality
[DEBUG] Processing field: refinement_data
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: refinement_data
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:12,149 - flujo - INFO - LoopStep 'error_refine': Starting Iteration 3/5
2025-08-05 14:57:12,150 - flujo - INFO - Counting string output as 1 token for step 'refine_with_error_step': 'refined_content_4'
2025-08-05 14:57:12,150 - flujo - INFO - Counting string output as 1 token for step '_capture_artifact': 'refined_content_4'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] source_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_bed9c702567c4e5390bbefaef0b51cfa', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'refinement_count': 4, 'total_iterations': 7, 'refinement_history': ['refinement_1', 'refinement_2', 'refinement_3', 'refinement_4'], 'current_quality': 0.13, 'best_quality': 0.13, 'refinement_data': {}}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_bed9c702567c4e5390bbefaef0b51cfa
[DEBUG] actual_source_value: run_bed9c702567c4e5390bbefaef0b51cfa
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: refinement_count
[DEBUG] current_value: 4
[DEBUG] actual_source_value: 4
[DEBUG] Field unchanged: refinement_count
[DEBUG] Processing field: total_iterations
[DEBUG] current_value: 7
[DEBUG] actual_source_value: 7
[DEBUG] Field unchanged: total_iterations
[DEBUG] Processing field: refinement_history
[DEBUG] current_value: ['refinement_1', 'refinement_2', 'refinement_3', 'refinement_4']
[DEBUG] actual_source_value: ['refinement_1', 'refinement_2', 'refinement_3', 'refinement_4']
[DEBUG] Merging lists for field: refinement_history
[DEBUG] No new items to add to list field: refinement_history
[DEBUG] Processing field: current_quality
[DEBUG] current_value: 0.13
[DEBUG] actual_source_value: 0.13
[DEBUG] Field unchanged: current_quality
[DEBUG] Processing field: best_quality
[DEBUG] current_value: 0.13
[DEBUG] actual_source_value: 0.13
[DEBUG] Field unchanged: best_quality
[DEBUG] Processing field: refinement_data
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: refinement_data
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:12,151 - flujo - INFO - LoopStep 'error_refine': Starting Iteration 4/5
2025-08-05 14:57:12,151 - flujo - INFO - Counting string output as 1 token for step 'refine_with_error_step': 'refined_content_5'
2025-08-05 14:57:12,151 - flujo - INFO - Counting string output as 1 token for step '_capture_artifact': 'refined_content_5'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] source_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_bed9c702567c4e5390bbefaef0b51cfa', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'refinement_count': 5, 'total_iterations': 9, 'refinement_history': ['refinement_1', 'refinement_2', 'refinement_3', 'refinement_4', 'refinement_5'], 'current_quality': 0.15000000000000002, 'best_quality': 0.15000000000000002, 'refinement_data': {}}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_bed9c702567c4e5390bbefaef0b51cfa
[DEBUG] actual_source_value: run_bed9c702567c4e5390bbefaef0b51cfa
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: refinement_count
[DEBUG] current_value: 5
[DEBUG] actual_source_value: 5
[DEBUG] Field unchanged: refinement_count
[DEBUG] Processing field: total_iterations
[DEBUG] current_value: 9
[DEBUG] actual_source_value: 9
[DEBUG] Field unchanged: total_iterations
[DEBUG] Processing field: refinement_history
[DEBUG] current_value: ['refinement_1', 'refinement_2', 'refinement_3', 'refinement_4', 'refinement_5']
[DEBUG] actual_source_value: ['refinement_1', 'refinement_2', 'refinement_3', 'refinement_4', 'refinement_5']
[DEBUG] Merging lists for field: refinement_history
[DEBUG] No new items to add to list field: refinement_history
[DEBUG] Processing field: current_quality
[DEBUG] current_value: 0.15000000000000002
[DEBUG] actual_source_value: 0.15000000000000002
[DEBUG] Field unchanged: current_quality
[DEBUG] Processing field: best_quality
[DEBUG] current_value: 0.15000000000000002
[DEBUG] actual_source_value: 0.15000000000000002
[DEBUG] Field unchanged: best_quality
[DEBUG] Processing field: refinement_data
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: refinement_data
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:12,152 - flujo - INFO - LoopStep 'error_refine': Starting Iteration 5/5
2025-08-05 14:57:12,152 - flujo - INFO - Counting string output as 1 token for step 'refine_with_error_step': 'refined_content_6'
2025-08-05 14:57:12,152 - flujo - INFO - Counting string output as 1 token for step '_capture_artifact': 'refined_content_6'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] source_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_bed9c702567c4e5390bbefaef0b51cfa', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'refinement_count': 6, 'total_iterations': 11, 'refinement_history': ['refinement_1', 'refinement_2', 'refinement_3', 'refinement_4', 'refinement_5', 'refinement_6'], 'current_quality': 0.16999999999999998, 'best_quality': 0.16999999999999998, 'refinement_data': {}}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_bed9c702567c4e5390bbefaef0b51cfa
[DEBUG] actual_source_value: run_bed9c702567c4e5390bbefaef0b51cfa
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: refinement_count
[DEBUG] current_value: 6
[DEBUG] actual_source_value: 6
[DEBUG] Field unchanged: refinement_count
[DEBUG] Processing field: total_iterations
[DEBUG] current_value: 11
[DEBUG] actual_source_value: 11
[DEBUG] Field unchanged: total_iterations
[DEBUG] Processing field: refinement_history
[DEBUG] current_value: ['refinement_1', 'refinement_2', 'refinement_3', 'refinement_4', 'refinement_5', 'refinement_6']
[DEBUG] actual_source_value: ['refinement_1', 'refinement_2', 'refinement_3', 'refinement_4', 'refinement_5', 'refinement_6']
[DEBUG] Merging lists for field: refinement_history
[DEBUG] No new items to add to list field: refinement_history
[DEBUG] Processing field: current_quality
[DEBUG] current_value: 0.16999999999999998
[DEBUG] actual_source_value: 0.16999999999999998
[DEBUG] Field unchanged: current_quality
[DEBUG] Processing field: best_quality
[DEBUG] current_value: 0.16999999999999998
[DEBUG] actual_source_value: 0.16999999999999998
[DEBUG] Field unchanged: best_quality
[DEBUG] Processing field: refinement_data
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: refinement_data
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:12,153 - flujo - WARNING - Step 'error_refine' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'error_refine': Starting Iteration 1/5
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'refine_with_error_step': 'refined_content_1'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step '_capture_artifact': 'refined_content_1'
INFO     flujo:telemetry.py:54 LoopStep 'error_refine': Starting Iteration 2/5
WARNING  flujo:telemetry.py:54 Step 'refine_with_error_step' agent execution attempt 1 failed: Intentional failure in refinement 2
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'refine_with_error_step': 'refined_content_3'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step '_capture_artifact': 'refined_content_3'
INFO     flujo:telemetry.py:54 LoopStep 'error_refine': Starting Iteration 3/5
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'refine_with_error_step': 'refined_content_4'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step '_capture_artifact': 'refined_content_4'
INFO     flujo:telemetry.py:54 LoopStep 'error_refine': Starting Iteration 4/5
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'refine_with_error_step': 'refined_content_5'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step '_capture_artifact': 'refined_content_5'
INFO     flujo:telemetry.py:54 LoopStep 'error_refine': Starting Iteration 5/5
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'refine_with_error_step': 'refined_content_6'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step '_capture_artifact': 'refined_content_6'
WARNING  flujo:telemetry.py:54 Step 'error_refine' failed. Halting pipeline execution.
__________ test_refine_until_with_context_updates_metadata_conflicts ___________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_refine_until_with_context_updates.py:350: in test_refine_until_with_context_updates_metadata_conflicts
    assert "reached max_loops" in result.step_history[-1].feedback.lower()
E   AssertionError: assert 'reached max_loops' in 'loop terminated after reaching max_loops (3)'
E    +  where 'loop terminated after reaching max_loops (3)' = <built-in method lower of str object at 0x1136b9bf0>()
E    +    where <built-in method lower of str object at 0x1136b9bf0> = 'Loop terminated after reaching max_loops (3)'.lower
E    +      where 'Loop terminated after reaching max_loops (3)' = StepResult(name='metadata_refine', output='metadata_content_3', success=False, attempts=3, latency_s=0.003604208002798...amp': 'now', 'data': 'refinement_3'}}}), metadata_={'iterations': 3, 'exit_reason': 'max_iterations'}, step_history=[]).feedback
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === metadata_refine
2025-08-05 14:57:12,185 - flujo - INFO - LoopStep 'metadata_refine': Starting Iteration 1/3
2025-08-05 14:57:12,185 - flujo - INFO - Counting string output as 1 token for step 'metadata_generator_step': 'metadata_content_1'
2025-08-05 14:57:12,186 - flujo - INFO - Counting string output as 1 token for step '_capture_artifact': 'metadata_content_1'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] source_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_8abd2e83759d41a59ea198a4cec85676', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'refinement_count': 1, 'total_iterations': 2, 'refinement_history': [], 'current_quality': 0.07, 'best_quality': 0.07, 'refinement_data': {'metadata_1': {'refine_index': 1, 'refine_iteration': 1, 'refine_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'refinement_1'}}}}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_8abd2e83759d41a59ea198a4cec85676
[DEBUG] actual_source_value: run_8abd2e83759d41a59ea198a4cec85676
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: refinement_count
[DEBUG] current_value: 1
[DEBUG] actual_source_value: 1
[DEBUG] Field unchanged: refinement_count
[DEBUG] Processing field: total_iterations
[DEBUG] current_value: 2
[DEBUG] actual_source_value: 2
[DEBUG] Field unchanged: total_iterations
[DEBUG] Processing field: refinement_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: refinement_history
[DEBUG] No new items to add to list field: refinement_history
[DEBUG] Processing field: current_quality
[DEBUG] current_value: 0.07
[DEBUG] actual_source_value: 0.07
[DEBUG] Field unchanged: current_quality
[DEBUG] Processing field: best_quality
[DEBUG] current_value: 0.07
[DEBUG] actual_source_value: 0.07
[DEBUG] Field unchanged: best_quality
[DEBUG] Processing field: refinement_data
[DEBUG] current_value: {'metadata_1': {'refine_index': 1, 'refine_iteration': 1, 'refine_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'refinement_1'}}}
[DEBUG] actual_source_value: {'metadata_1': {'refine_index': 1, 'refine_iteration': 1, 'refine_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'refinement_1'}}}
[DEBUG] Merging dictionaries for field: refinement_data
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:12,186 - flujo - INFO - LoopStep 'metadata_refine': Starting Iteration 2/3
2025-08-05 14:57:12,187 - flujo - INFO - Counting string output as 1 token for step 'metadata_generator_step': 'metadata_content_2'
2025-08-05 14:57:12,187 - flujo - INFO - Counting string output as 1 token for step '_capture_artifact': 'metadata_content_2'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] source_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_8abd2e83759d41a59ea198a4cec85676', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'refinement_count': 2, 'total_iterations': 4, 'refinement_history': [], 'current_quality': 0.09, 'best_quality': 0.09, 'refinement_data': {'metadata_1': {'refine_index': 1, 'refine_iteration': 1, 'refine_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'refinement_1'}}, 'metadata_2': {'refine_index': 2, 'refine_iteration': 3, 'refine_metadata': {'iteration': 2, 'timestamp': 'now', 'data': 'refinement_2'}}}}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_8abd2e83759d41a59ea198a4cec85676
[DEBUG] actual_source_value: run_8abd2e83759d41a59ea198a4cec85676
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: refinement_count
[DEBUG] current_value: 2
[DEBUG] actual_source_value: 2
[DEBUG] Field unchanged: refinement_count
[DEBUG] Processing field: total_iterations
[DEBUG] current_value: 4
[DEBUG] actual_source_value: 4
[DEBUG] Field unchanged: total_iterations
[DEBUG] Processing field: refinement_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: refinement_history
[DEBUG] No new items to add to list field: refinement_history
[DEBUG] Processing field: current_quality
[DEBUG] current_value: 0.09
[DEBUG] actual_source_value: 0.09
[DEBUG] Field unchanged: current_quality
[DEBUG] Processing field: best_quality
[DEBUG] current_value: 0.09
[DEBUG] actual_source_value: 0.09
[DEBUG] Field unchanged: best_quality
[DEBUG] Processing field: refinement_data
[DEBUG] current_value: {'metadata_1': {'refine_index': 1, 'refine_iteration': 1, 'refine_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'refinement_1'}}, 'metadata_2': {'refine_index': 2, 'refine_iteration': 3, 'refine_metadata': {'iteration': 2, 'timestamp': 'now', 'data': 'refinement_2'}}}
[DEBUG] actual_source_value: {'metadata_1': {'refine_index': 1, 'refine_iteration': 1, 'refine_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'refinement_1'}}, 'metadata_2': {'refine_index': 2, 'refine_iteration': 3, 'refine_metadata': {'iteration': 2, 'timestamp': 'now', 'data': 'refinement_2'}}}
[DEBUG] Merging dictionaries for field: refinement_data
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:12,188 - flujo - INFO - LoopStep 'metadata_refine': Starting Iteration 3/3
2025-08-05 14:57:12,188 - flujo - INFO - Counting string output as 1 token for step 'metadata_generator_step': 'metadata_content_3'
2025-08-05 14:57:12,188 - flujo - INFO - Counting string output as 1 token for step '_capture_artifact': 'metadata_content_3'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] source_context type: <class 'tests.integration.test_refine_until_with_context_updates.RefineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_8abd2e83759d41a59ea198a4cec85676', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'refinement_count': 3, 'total_iterations': 6, 'refinement_history': [], 'current_quality': 0.11, 'best_quality': 0.11, 'refinement_data': {'metadata_1': {'refine_index': 1, 'refine_iteration': 1, 'refine_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'refinement_1'}}, 'metadata_2': {'refine_index': 2, 'refine_iteration': 3, 'refine_metadata': {'iteration': 2, 'timestamp': 'now', 'data': 'refinement_2'}}, 'metadata_3': {'refine_index': 3, 'refine_iteration': 5, 'refine_metadata': {'iteration': 3, 'timestamp': 'now', 'data': 'refinement_3'}}}}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_8abd2e83759d41a59ea198a4cec85676
[DEBUG] actual_source_value: run_8abd2e83759d41a59ea198a4cec85676
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: refinement_count
[DEBUG] current_value: 3
[DEBUG] actual_source_value: 3
[DEBUG] Field unchanged: refinement_count
[DEBUG] Processing field: total_iterations
[DEBUG] current_value: 6
[DEBUG] actual_source_value: 6
[DEBUG] Field unchanged: total_iterations
[DEBUG] Processing field: refinement_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: refinement_history
[DEBUG] No new items to add to list field: refinement_history
[DEBUG] Processing field: current_quality
[DEBUG] current_value: 0.11
[DEBUG] actual_source_value: 0.11
[DEBUG] Field unchanged: current_quality
[DEBUG] Processing field: best_quality
[DEBUG] current_value: 0.11
[DEBUG] actual_source_value: 0.11
[DEBUG] Field unchanged: best_quality
[DEBUG] Processing field: refinement_data
[DEBUG] current_value: {'metadata_1': {'refine_index': 1, 'refine_iteration': 1, 'refine_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'refinement_1'}}, 'metadata_2': {'refine_index': 2, 'refine_iteration': 3, 'refine_metadata': {'iteration': 2, 'timestamp': 'now', 'data': 'refinement_2'}}, 'metadata_3': {'refine_index': 3, 'refine_iteration': 5, 'refine_metadata': {'iteration': 3, 'timestamp': 'now', 'data': 'refinement_3'}}}
[DEBUG] actual_source_value: {'metadata_1': {'refine_index': 1, 'refine_iteration': 1, 'refine_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'refinement_1'}}, 'metadata_2': {'refine_index': 2, 'refine_iteration': 3, 'refine_metadata': {'iteration': 2, 'timestamp': 'now', 'data': 'refinement_2'}}, 'metadata_3': {'refine_index': 3, 'refine_iteration': 5, 'refine_metadata': {'iteration': 3, 'timestamp': 'now', 'data': 'refinement_3'}}}
[DEBUG] Merging dictionaries for field: refinement_data
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:12,189 - flujo - WARNING - Step 'metadata_refine' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'metadata_refine': Starting Iteration 1/3
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'metadata_generator_step': 'metadata_content_1'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step '_capture_artifact': 'metadata_content_1'
INFO     flujo:telemetry.py:54 LoopStep 'metadata_refine': Starting Iteration 2/3
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'metadata_generator_step': 'metadata_content_2'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step '_capture_artifact': 'metadata_content_2'
INFO     flujo:telemetry.py:54 LoopStep 'metadata_refine': Starting Iteration 3/3
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'metadata_generator_step': 'metadata_content_3'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step '_capture_artifact': 'metadata_content_3'
WARNING  flujo:telemetry.py:54 Step 'metadata_refine' failed. Halting pipeline execution.
__________ TestSQLiteBackendEdgeCases.test_backup_stat_error_handling __________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_sqlite_backend_edge_cases.py:401: in test_backup_stat_error_handling
    await backend._init_db()
flujo/state/backends/sqlite.py:478: in _init_db
    await self._init_db(retry_count + 1, max_retries)
flujo/state/backends/sqlite.py:342: in _init_db
    await db.execute("PRAGMA journal_mode = WAL")  # Write-Ahead Logging for better concurrency
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:183: in execute
    cursor = await self._execute(self._conn.execute, sql, parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:122: in _execute
    return await future
           ^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:105: in run
    result = function()
             ^^^^^^^^^^
E   sqlite3.DatabaseError: file is not a database
----------------------------- Captured stdout call -----------------------------
2009-02-13 15:31:30,000 - flujo - WARNING - Database corruption detected during initialization, creating backup: file is not a database
----------------------------- Captured stderr call -----------------------------
2009-02-13 15:31:30,000 - flujo - ERROR - Failed to initialize database after 1 retries: file is not a database
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Database corruption detected during initialization, creating backup: file is not a database
ERROR    flujo:telemetry.py:54 Failed to initialize database after 1 retries: file is not a database
________ TestSQLiteBackendEdgeCases.test_backup_cleanup_attempts_limit _________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
flujo/state/backends/sqlite.py:342: in _init_db
    await db.execute("PRAGMA journal_mode = WAL")  # Write-Ahead Logging for better concurrency
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:183: in execute
    cursor = await self._execute(self._conn.execute, sql, parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:122: in _execute
    return await future
           ^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:105: in run
    result = function()
             ^^^^^^^^^^
E   sqlite3.DatabaseError: file is not a database

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:326: in _init_db
    file_size = self.db_path.stat().st_size
                ^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1013: in stat
    return os.stat(self, follow_symlinks=follow_symlinks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:524: in _backup_corrupted_database
    self.db_path.rename(backup_path)
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1175: in rename
    os.rename(self, target)
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db' -> '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db.corrupt.1234567890.1000'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:530: in _backup_corrupted_database
    shutil.copy2(str(self.db_path), str(backup_path))
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:436: in copy2
    copyfile(src, dst, follow_symlinks=follow_symlinks)
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:256: in copyfile
    with open(src, 'rb') as fsrc:
         ^^^^^^^^^^^^^^^
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:536: in _backup_corrupted_database
    self.db_path.unlink()
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1147: in unlink
    os.unlink(self)
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db'

The above exception was the direct cause of the following exception:
flujo/state/backends/sqlite.py:334: in _init_db
    await self._backup_corrupted_database()
flujo/state/backends/sqlite.py:541: in _backup_corrupted_database
    raise sqlite3.DatabaseError("Database corruption recovery failed") from remove_error
E   sqlite3.DatabaseError: Database corruption recovery failed

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:524: in _backup_corrupted_database
    self.db_path.rename(backup_path)
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1175: in rename
    os.rename(self, target)
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db' -> '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db.corrupt.1234567890.1000'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:530: in _backup_corrupted_database
    shutil.copy2(str(self.db_path), str(backup_path))
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:436: in copy2
    copyfile(src, dst, follow_symlinks=follow_symlinks)
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:256: in copyfile
    with open(src, 'rb') as fsrc:
         ^^^^^^^^^^^^^^^
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:536: in _backup_corrupted_database
    self.db_path.unlink()
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1147: in unlink
    os.unlink(self)
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db'

The above exception was the direct cause of the following exception:
tests/integration/test_sqlite_backend_edge_cases.py:654: in test_backup_cleanup_attempts_limit
    await backend._init_db()
flujo/state/backends/sqlite.py:478: in _init_db
    await self._init_db(retry_count + 1, max_retries)
flujo/state/backends/sqlite.py:338: in _init_db
    await self._backup_corrupted_database()
flujo/state/backends/sqlite.py:541: in _backup_corrupted_database
    raise sqlite3.DatabaseError("Database corruption recovery failed") from remove_error
E   sqlite3.DatabaseError: Database corruption recovery failed
----------------------------- Captured stdout call -----------------------------
2009-02-13 15:31:30,000 - flujo - WARNING - Database corruption detected during initialization, creating backup: file is not a database
2009-02-13 15:31:30,000 - flujo - WARNING - Corrupted database backed up to /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db.corrupt.1234567890.1000
2009-02-13 15:31:30,000 - flujo - WARNING - File stat failed, assuming corrupted: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db'
2009-02-13 15:31:30,000 - flujo - WARNING - Database appears to be corrupted, creating backup: Database corruption recovery failed
----------------------------- Captured stderr call -----------------------------
2009-02-13 15:31:30,000 - flujo - ERROR - Failed to remove corrupted database: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db'
2009-02-13 15:31:30,000 - flujo - ERROR - Failed to remove corrupted database: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db'
2009-02-13 15:31:30,000 - flujo - ERROR - Failed to initialize database after 1 retries: Database corruption recovery failed
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Database corruption detected during initialization, creating backup: file is not a database
WARNING  flujo:telemetry.py:54 Corrupted database backed up to /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db.corrupt.1234567890.1000
WARNING  flujo:telemetry.py:54 File stat failed, assuming corrupted: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db'
ERROR    flujo:telemetry.py:54 Failed to remove corrupted database: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db'
WARNING  flujo:telemetry.py:54 Database appears to be corrupted, creating backup: Database corruption recovery failed
ERROR    flujo:telemetry.py:54 Failed to remove corrupted database: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_cleanup_attempts_l0/test.db'
ERROR    flujo:telemetry.py:54 Failed to initialize database after 1 retries: Database corruption recovery failed
________ TestSQLiteBackendEdgeCases.test_backup_stat_exception_handling ________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_sqlite_backend_edge_cases.py:688: in test_backup_stat_exception_handling
    await backend._init_db()
flujo/state/backends/sqlite.py:478: in _init_db
    await self._init_db(retry_count + 1, max_retries)
flujo/state/backends/sqlite.py:342: in _init_db
    await db.execute("PRAGMA journal_mode = WAL")  # Write-Ahead Logging for better concurrency
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:183: in execute
    cursor = await self._execute(self._conn.execute, sql, parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:122: in _execute
    return await future
           ^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:105: in run
    result = function()
             ^^^^^^^^^^
E   sqlite3.DatabaseError: file is not a database
----------------------------- Captured stdout call -----------------------------
2009-02-13 15:31:30,000 - flujo - WARNING - Database corruption detected during initialization, creating backup: file is not a database
----------------------------- Captured stderr call -----------------------------
2009-02-13 15:31:30,000 - flujo - ERROR - Failed to initialize database after 1 retries: file is not a database
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Database corruption detected during initialization, creating backup: file is not a database
ERROR    flujo:telemetry.py:54 Failed to initialize database after 1 retries: file is not a database
_______ TestSQLiteBackendEdgeCases.test_backup_fallback_timestamp_naming _______
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
flujo/state/backends/sqlite.py:342: in _init_db
    await db.execute("PRAGMA journal_mode = WAL")  # Write-Ahead Logging for better concurrency
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:183: in execute
    cursor = await self._execute(self._conn.execute, sql, parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:122: in _execute
    return await future
           ^^^^^^^^^^^^
.venv/lib/python3.11/site-packages/aiosqlite/core.py:105: in run
    result = function()
             ^^^^^^^^^^
E   sqlite3.DatabaseError: file is not a database

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:326: in _init_db
    file_size = self.db_path.stat().st_size
                ^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1013: in stat
    return os.stat(self, follow_symlinks=follow_symlinks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:524: in _backup_corrupted_database
    self.db_path.rename(backup_path)
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1175: in rename
    os.rename(self, target)
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db' -> '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db.corrupt.9876543210.1000'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:530: in _backup_corrupted_database
    shutil.copy2(str(self.db_path), str(backup_path))
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:436: in copy2
    copyfile(src, dst, follow_symlinks=follow_symlinks)
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:256: in copyfile
    with open(src, 'rb') as fsrc:
         ^^^^^^^^^^^^^^^
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:536: in _backup_corrupted_database
    self.db_path.unlink()
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1147: in unlink
    os.unlink(self)
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db'

The above exception was the direct cause of the following exception:
flujo/state/backends/sqlite.py:334: in _init_db
    await self._backup_corrupted_database()
flujo/state/backends/sqlite.py:541: in _backup_corrupted_database
    raise sqlite3.DatabaseError("Database corruption recovery failed") from remove_error
E   sqlite3.DatabaseError: Database corruption recovery failed

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:524: in _backup_corrupted_database
    self.db_path.rename(backup_path)
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1175: in rename
    os.rename(self, target)
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db' -> '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db.corrupt.9876543210.1000'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:530: in _backup_corrupted_database
    shutil.copy2(str(self.db_path), str(backup_path))
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:436: in copy2
    copyfile(src, dst, follow_symlinks=follow_symlinks)
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:256: in copyfile
    with open(src, 'rb') as fsrc:
         ^^^^^^^^^^^^^^^
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:536: in _backup_corrupted_database
    self.db_path.unlink()
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1147: in unlink
    os.unlink(self)
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db'

The above exception was the direct cause of the following exception:
tests/integration/test_sqlite_backend_edge_cases.py:761: in test_backup_fallback_timestamp_naming
    await backend._init_db()
flujo/state/backends/sqlite.py:478: in _init_db
    await self._init_db(retry_count + 1, max_retries)
flujo/state/backends/sqlite.py:338: in _init_db
    await self._backup_corrupted_database()
flujo/state/backends/sqlite.py:541: in _backup_corrupted_database
    raise sqlite3.DatabaseError("Database corruption recovery failed") from remove_error
E   sqlite3.DatabaseError: Database corruption recovery failed
----------------------------- Captured stdout call -----------------------------
2282-12-22 12:13:30,000 - flujo - WARNING - Database corruption detected during initialization, creating backup: file is not a database
2282-12-22 12:13:30,000 - flujo - WARNING - Corrupted database backed up to /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db.corrupt.9876543210.1000
2282-12-22 12:13:30,000 - flujo - WARNING - File stat failed, assuming corrupted: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db'
2282-12-22 12:13:30,000 - flujo - WARNING - Database appears to be corrupted, creating backup: Database corruption recovery failed
----------------------------- Captured stderr call -----------------------------
2282-12-22 12:13:30,000 - flujo - ERROR - Failed to remove corrupted database: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db'
2282-12-22 12:13:30,000 - flujo - ERROR - Failed to remove corrupted database: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db'
2282-12-22 12:13:30,000 - flujo - ERROR - Failed to initialize database after 1 retries: Database corruption recovery failed
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Database corruption detected during initialization, creating backup: file is not a database
WARNING  flujo:telemetry.py:54 Corrupted database backed up to /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db.corrupt.9876543210.1000
WARNING  flujo:telemetry.py:54 File stat failed, assuming corrupted: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db'
ERROR    flujo:telemetry.py:54 Failed to remove corrupted database: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db'
WARNING  flujo:telemetry.py:54 Database appears to be corrupted, creating backup: Database corruption recovery failed
ERROR    flujo:telemetry.py:54 Failed to remove corrupted database: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_fallback_timestamp0/test.db'
ERROR    flujo:telemetry.py:54 Failed to initialize database after 1 retries: Database corruption recovery failed
____ TestSQLiteBackendEdgeCases.test_backup_all_slots_undeletable_fallback _____
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
flujo/state/backends/sqlite.py:334: in _init_db
    await self._backup_corrupted_database()
flujo/state/backends/sqlite.py:541: in _backup_corrupted_database
    raise sqlite3.DatabaseError("Database corruption recovery failed") from remove_error
E   sqlite3.DatabaseError: Database corruption recovery failed

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:524: in _backup_corrupted_database
    self.db_path.rename(backup_path)
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1175: in rename
    os.rename(self, target)
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_all_slots_undeleta0/test.db' -> '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_all_slots_undeleta0/test.db.corrupt.9876543210.1000'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:530: in _backup_corrupted_database
    shutil.copy2(str(self.db_path), str(backup_path))
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:436: in copy2
    copyfile(src, dst, follow_symlinks=follow_symlinks)
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:256: in copyfile
    with open(src, 'rb') as fsrc:
         ^^^^^^^^^^^^^^^
E   FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_all_slots_undeleta0/test.db'

During handling of the above exception, another exception occurred:
flujo/state/backends/sqlite.py:536: in _backup_corrupted_database
    self.db_path.unlink()
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/unittest/mock.py:1108: in __call__
    return self._mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/unittest/mock.py:1112: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/unittest/mock.py:1167: in _execute_mock_call
    raise effect
flujo/state/backends/sqlite.py:536: in _backup_corrupted_database
    self.db_path.unlink()
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/unittest/mock.py:1108: in __call__
    return self._mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/unittest/mock.py:1112: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/unittest/mock.py:1167: in _execute_mock_call
    raise effect
E   OSError: Permission denied

The above exception was the direct cause of the following exception:
tests/integration/test_sqlite_backend_edge_cases.py:791: in test_backup_all_slots_undeletable_fallback
    await backend._init_db()
flujo/state/backends/sqlite.py:478: in _init_db
    await self._init_db(retry_count + 1, max_retries)
flujo/state/backends/sqlite.py:338: in _init_db
    await self._backup_corrupted_database()
flujo/state/backends/sqlite.py:541: in _backup_corrupted_database
    raise sqlite3.DatabaseError("Database corruption recovery failed") from remove_error
E   sqlite3.DatabaseError: Database corruption recovery failed
----------------------------- Captured stdout call -----------------------------
2282-12-22 12:13:30,000 - flujo - WARNING - Database corruption detected during initialization, creating backup: file is not a database
2282-12-22 12:13:30,000 - flujo - WARNING - Corrupted database backed up to /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_all_slots_undeleta0/test.db.corrupt.9876543210.1000
2282-12-22 12:13:30,000 - flujo - WARNING - File stat failed, assuming corrupted: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_all_slots_undeleta0/test.db'
2282-12-22 12:13:30,000 - flujo - WARNING - Database appears to be corrupted, creating backup: Database corruption recovery failed
----------------------------- Captured stderr call -----------------------------
2282-12-22 12:13:30,000 - flujo - ERROR - Failed to remove corrupted database: Permission denied
2282-12-22 12:13:30,000 - flujo - ERROR - Failed to remove corrupted database: Permission denied
2282-12-22 12:13:30,000 - flujo - ERROR - Failed to initialize database after 1 retries: Database corruption recovery failed
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Database corruption detected during initialization, creating backup: file is not a database
WARNING  flujo:telemetry.py:54 Corrupted database backed up to /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_all_slots_undeleta0/test.db.corrupt.9876543210.1000
WARNING  flujo:telemetry.py:54 File stat failed, assuming corrupted: [Errno 2] No such file or directory: '/private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_backup_all_slots_undeleta0/test.db'
ERROR    flujo:telemetry.py:54 Failed to remove corrupted database: Permission denied
WARNING  flujo:telemetry.py:54 Database appears to be corrupted, creating backup: Database corruption recovery failed
ERROR    flujo:telemetry.py:54 Failed to remove corrupted database: Permission denied
ERROR    flujo:telemetry.py:54 Failed to initialize database after 1 retries: Database corruption recovery failed
__________ TestSQLiteBackendEdgeCases.test_backup_stat_always_raises ___________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_sqlite_backend_edge_cases.py:812: in always_raises_stat
    raise OSError("stat failed")
E   OSError: stat failed

During handling of the above exception, another exception occurred:
tests/integration/test_sqlite_backend_edge_cases.py:818: in test_backup_stat_always_raises
    await backend._init_db()
flujo/state/backends/sqlite.py:494: in _init_db
    await self._init_db(retry_count + 1, max_retries)
flujo/state/backends/sqlite.py:322: in _init_db
    if self.db_path.exists():
       ^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1235: in exists
    self.stat()
tests/integration/test_sqlite_backend_edge_cases.py:812: in always_raises_stat
    raise OSError("stat failed")
E   OSError: stat failed
----------------------------- Captured stdout call -----------------------------
2282-12-22 12:13:30,000 - flujo - WARNING - Database initialization failed, retrying (1/1): stat failed
----------------------------- Captured stderr call -----------------------------
2282-12-22 12:13:30,000 - flujo - ERROR - Failed to initialize database after 1 retries: stat failed
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Database initialization failed, retrying (1/1): stat failed
ERROR    flujo:telemetry.py:54 Failed to initialize database after 1 retries: stat failed
____ TestSQLiteBackendEdgeCases.test_backup_permission_and_race_conditions _____
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_sqlite_backend_edge_cases.py:889: in sometimes_raises_stat
    return Path.stat(self, *a, **k)
           ^^^^^^^^^^^^^^^^^^^^^^^^
tests/integration/test_sqlite_backend_edge_cases.py:889: in sometimes_raises_stat
    return Path.stat(self, *a, **k)
           ^^^^^^^^^^^^^^^^^^^^^^^^
tests/integration/test_sqlite_backend_edge_cases.py:889: in sometimes_raises_stat
    return Path.stat(self, *a, **k)
           ^^^^^^^^^^^^^^^^^^^^^^^^
tests/integration/test_sqlite_backend_edge_cases.py:885: in sometimes_raises_stat
    raise OSError("stat failed")
E   OSError: stat failed

During handling of the above exception, another exception occurred:
tests/integration/test_sqlite_backend_edge_cases.py:895: in test_backup_permission_and_race_conditions
    await backend._init_db()
flujo/state/backends/sqlite.py:494: in _init_db
    await self._init_db(retry_count + 1, max_retries)
flujo/state/backends/sqlite.py:322: in _init_db
    if self.db_path.exists():
       ^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1235: in exists
    self.stat()
tests/integration/test_sqlite_backend_edge_cases.py:889: in sometimes_raises_stat
    return Path.stat(self, *a, **k)
           ^^^^^^^^^^^^^^^^^^^^^^^^
tests/integration/test_sqlite_backend_edge_cases.py:889: in sometimes_raises_stat
    return Path.stat(self, *a, **k)
           ^^^^^^^^^^^^^^^^^^^^^^^^
tests/integration/test_sqlite_backend_edge_cases.py:889: in sometimes_raises_stat
    return Path.stat(self, *a, **k)
           ^^^^^^^^^^^^^^^^^^^^^^^^
tests/integration/test_sqlite_backend_edge_cases.py:885: in sometimes_raises_stat
    raise OSError("stat failed")
E   OSError: stat failed
----------------------------- Captured stdout call -----------------------------
2282-12-22 12:13:30,000 - flujo - WARNING - Database initialization failed, retrying (1/1): stat failed
----------------------------- Captured stderr call -----------------------------
2282-12-22 12:13:30,000 - flujo - ERROR - Failed to initialize database after 1 retries: stat failed
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Database initialization failed, retrying (1/1): stat failed
ERROR    flujo:telemetry.py:54 Failed to initialize database after 1 retries: stat failed
__________________________ test_stateful_hitl_resume ___________________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_stateful_hitl.py:61: in test_stateful_hitl_resume
    assert ctx.scratchpad["pre"] == "hello"
           ^^^^^^^^^^^^^^^^^^^^^
E   KeyError: 'pre'
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:18,279 - flujo - INFO - Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_stateful_hitl_resume0/state.db
2025-08-05 14:57:18,282 - flujo - INFO - Saved state for run_id=hitl_run
2025-08-05 14:57:18,283 - flujo - INFO - Counting string output as 1 token for step 'setup': 'setup'
2025-08-05 14:57:18,285 - flujo - INFO - Saved state for run_id=hitl_run
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Initialized SQLite database at /private/var/folders/hh/df2rcx0n7nnb2y0hxn4dzps40000gn/T/pytest-of-alvaro/pytest-1347/popen-gw0/test_stateful_hitl_resume0/state.db
INFO     flujo:telemetry.py:54 Saved state for run_id=hitl_run
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'setup': 'setup'
INFO     flujo:telemetry.py:54 Saved state for run_id=hitl_run
_________________________ test_non_streaming_pipeline __________________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_streaming_pipeline.py:45: in test_non_streaming_pipeline
    assert len(items) == 1
E   AssertionError: assert 2 == 1
E    +  where 2 = len(['ok', PipelineResult(step_history=[StepResult(name='solution', output='ok', success=True, attempts=1, latency_s=0.000...'latency_s': 0.000252834, 'cost_usd': 0.0, 'token_counts': 1}, children=[], status='completed')], status='completed'))])
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:18,611 - flujo - INFO - Counting string output as 1 token for step 'solution': 'ok'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'solution': 'ok'
___________ test_pipeline_handles_streaming_agent_failure_gracefully ___________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_streaming_pipeline.py:101: in test_pipeline_handles_streaming_agent_failure_gracefully
    assert collected == ["H", "e", "l"]
E   AssertionError: assert ['H', 'e', 'l...'e', 'l', ...] == ['H', 'e', 'l']
E
E     Left contains 6 more items, first extra item: 'H'
E
E     Full diff:
E       [
E           'H',
E           'e',
E           'l',
E     +     'H',
E     +     'e',
E     +     'l',
E     +     'H',
E     +     'e',
E     +     'l',
E       ]
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:18,617 - flujo - WARNING - Step 'solution' agent execution attempt 1 failed: Stream connection lost
2025-08-05 14:57:18,617 - flujo - WARNING - Step 'solution' agent execution attempt 2 failed: Stream connection lost
2025-08-05 14:57:18,617 - flujo - WARNING - Step 'solution' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:18,617 - flujo - ERROR - Step 'solution' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'solution' agent execution attempt 1 failed: Stream connection lost
WARNING  flujo:telemetry.py:54 Step 'solution' agent execution attempt 2 failed: Stream connection lost
ERROR    flujo:telemetry.py:54 Step 'solution' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'solution' failed. Halting pipeline execution.
___________________ test_non_strict_validation_pass_through ____________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_strict_validation.py:22: in test_non_strict_validation_pass_through
    assert hist.success is True
E   AssertionError: assert False is True
E    +  where False = StepResult(name='validate', output=None, success=False, attempts=3, latency_s=0.0005550410132855177, token_counts=1, c...Agent execution failed with IndexError: No more outputs available', branch_context=None, metadata_={}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:18,622 - flujo - INFO - Counting string output as 1 token for step 'validate': 'ok'
2025-08-05 14:57:18,622 - flujo - WARNING - Step 'validate' validation failed: bad
2025-08-05 14:57:18,622 - flujo - WARNING - Step 'validate' agent execution attempt 2 failed: No more outputs available
2025-08-05 14:57:18,622 - flujo - WARNING - Step 'validate' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:18,622 - flujo - ERROR - Step 'validate' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'validate': 'ok'
WARNING  flujo:telemetry.py:54 Step 'validate' validation failed: bad
WARNING  flujo:telemetry.py:54 Step 'validate' agent execution attempt 2 failed: No more outputs available
ERROR    flujo:telemetry.py:54 Step 'validate' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'validate' failed. Halting pipeline execution.
_____________ test_regular_step_keeps_output_on_validation_failure _____________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_strict_validation.py:46: in test_regular_step_keeps_output_on_validation_failure
    assert hist.output == "value"
E   AssertionError: assert None == 'value'
E    +  where None = StepResult(name='regular', output=None, success=False, attempts=3, latency_s=0.000375000003259629, token_counts=1, cos...Agent execution failed with IndexError: No more outputs available', branch_context=None, metadata_={}, step_history=[]).output
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:18,631 - flujo - INFO - Counting string output as 1 token for step 'regular': 'value'
2025-08-05 14:57:18,631 - flujo - WARNING - Step 'regular' validation failed: bad
2025-08-05 14:57:18,631 - flujo - WARNING - Step 'regular' agent execution attempt 2 failed: No more outputs available
2025-08-05 14:57:18,631 - flujo - WARNING - Step 'regular' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:18,631 - flujo - ERROR - Step 'regular' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'regular': 'value'
WARNING  flujo:telemetry.py:54 Step 'regular' validation failed: bad
WARNING  flujo:telemetry.py:54 Step 'regular' agent execution attempt 2 failed: No more outputs available
ERROR    flujo:telemetry.py:54 Step 'regular' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'regular' failed. Halting pipeline execution.
_____________________ test_error_information_preservation ______________________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_unified_error_handling.py:172: in test_error_information_preservation
    assert result.attempts == 2  # 1 initial + 1 retry (max_retries=1)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert 3 == 2
E    +  where 3 = StepResult(name='failing', output=None, success=False, attempts=3, latency_s=0.00030170800164341927, token_counts=0, c... feedback='Agent execution failed with RuntimeError: Test failure', branch_context=None, metadata_={}, step_history=[]).attempts
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:18,711 - flujo - WARNING - Step 'failing' agent execution attempt 1 failed: Test failure
2025-08-05 14:57:18,711 - flujo - WARNING - Step 'failing' agent execution attempt 2 failed: Test failure
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:18,711 - flujo - ERROR - Step 'failing' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Step 'failing' agent execution attempt 1 failed: Test failure
WARNING  flujo:telemetry.py:54 Step 'failing' agent execution attempt 2 failed: Test failure
ERROR    flujo:telemetry.py:54 Step 'failing' agent failed after 3 attempts
___ TestUltraExecutorCumulativeLimits.test_usage_tracker_cumulative_tracking ___
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_ultra_executor_cumulative_limits.py:44: in test_usage_tracker_cumulative_tracking
    total_cost, total_tokens = await usage_tracker.get_current_totals()
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
_____ TestUltraExecutorCumulativeLimits.test_usage_tracker_limit_checking ______
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_ultra_executor_cumulative_limits.py:60: in test_usage_tracker_limit_checking
    cost, tokens = await usage_tracker.get_current_totals()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
______ TestUltraExecutorCumulativeLimits.test_usage_tracker_thread_safety ______
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_ultra_executor_cumulative_limits.py:84: in test_usage_tracker_thread_safety
    final_cost, final_tokens = await add_usage_concurrently()
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/unit/test_ultra_executor_cumulative_limits.py:81: in add_usage_concurrently
    return await usage_tracker.get_current_totals()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
___ TestUltraExecutorCumulativeLimits.test_legacy_guard_method_compatibility ___
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_ultra_executor_cumulative_limits.py:106: in test_legacy_guard_method_compatibility
    cost, tokens = await usage_tracker.get_current_totals()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
__ TestUltraExecutorCumulativeLimits.test_usage_tracker_multiple_limit_checks __
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_ultra_executor_cumulative_limits.py:118: in test_usage_tracker_multiple_limit_checks
    cost, tokens = await usage_tracker.get_current_totals()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
_______ TestUltraExecutorCumulativeLimits.test_usage_tracker_zero_limits _______
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_ultra_executor_cumulative_limits.py:154: in test_usage_tracker_zero_limits
    cost, tokens = await usage_tracker.get_current_totals()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
___ TestUltraExecutorCumulativeLimits.test_usage_tracker_precision_handling ____
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_ultra_executor_cumulative_limits.py:168: in test_usage_tracker_precision_handling
    total_cost, total_tokens = await usage_tracker.get_current_totals()
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
________________ TestCacheKeyGeneration.test_agent_id_stability ________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_ultra_executor_v2.py:341: in test_agent_id_stability
    assert key1 == key2  # Same config should produce same key
    ^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert '2770702b9b25...7f7e243a064d1' == 'a512b2dc57c1...07a66a56c57d9'
E
E     - a512b2dc57c11187373b2ff49ab710aad1d94fee4a8602f9e9507a66a56c57d9
E     + 2770702b9b25191adf2b2fe8356cde7536c87244bd87747b0c37f7e243a064d1
____________ TestBackwardCompatibility.test_execute_step_signature _____________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_ultra_executor_v2.py:634: in test_execute_step_signature
    result = await executor.execute_step(
flujo/application/core/ultra_executor.py:623: in execute_step
    return await self.execute(
flujo/application/core/ultra_executor.py:582: in execute
    result = await self._execute_agent_step(
flujo/application/core/ultra_executor.py:1233: in _execute_agent_step
    for attempt in range(1, max_retries + 1):  # +1 because we want max_retries total attempts
                            ^^^^^^^^^^^^^^^
E   TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
___________ TestErrorHandling.test_usage_limit_exception_propagation ___________
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/unit/test_ultra_executor_v2.py:754: in test_usage_limit_exception_propagation
    with pytest.raises(UsageLimitExceededError):
E   Failed: DID NOT RAISE <class 'flujo.exceptions.UsageLimitExceededError'>
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:19,295 - flujo - INFO - Extracted tokens for step 'test_step': prompt=100, completion=50
2025-08-05 14:57:19,295 - flujo - INFO - Extracted model ID for step 'test_step' from 'model_id': openai:gpt-4o
2025-08-05 14:57:19,296 - flujo - INFO - CostCalculator: provider=openai, model=gpt-4o, pricing=prompt_tokens_per_1k=0.005 completion_tokens_per_1k=0.015 price_per_image_standard_1024x1024=None price_per_image_hd_1024x1024=None price_per_image_standard_1792x1024=None price_per_image_hd_1792x1024=None price_per_image_standard_1024x1792=None price_per_image_hd_1024x1792=None
2025-08-05 14:57:19,296 - flujo - INFO - Cost calculation: prompt_cost=0.0005, completion_cost=0.00075, total=0.00125
2025-08-05 14:57:19,296 - flujo - INFO - Calculated cost for step 'test_step': 0.00125 USD for model gpt-4o
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Extracted tokens for step 'test_step': prompt=100, completion=50
INFO     flujo:telemetry.py:54 Extracted model ID for step 'test_step' from 'model_id': openai:gpt-4o
INFO     flujo:telemetry.py:54 CostCalculator: provider=openai, model=gpt-4o, pricing=prompt_tokens_per_1k=0.005 completion_tokens_per_1k=0.015 price_per_image_standard_1024x1024=None price_per_image_hd_1024x1024=None price_per_image_standard_1792x1024=None price_per_image_hd_1792x1024=None price_per_image_standard_1024x1792=None price_per_image_hd_1024x1792=None
INFO     flujo:telemetry.py:54 Cost calculation: prompt_cost=0.0005, completion_cost=0.00075, total=0.00125
INFO     flujo:telemetry.py:54 Calculated cost for step 'test_step': 0.00125 USD for model gpt-4o
_____________________ test_golden_transcript_agentic_loop ______________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/e2e/test_golden_transcript_agentic_loop.py:124: in test_golden_transcript_agentic_loop
    assert final_context.scratchpad.get("status") == "paused"
E   AssertionError: assert 'failed' == 'paused'
E
E     - paused
E     + failed
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === AgenticExplorationLoop
2025-08-05 14:57:28,986 - flujo - INFO - LoopStep 'AgenticExplorationLoop': Starting Iteration 1/5
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.e2e.test_golden_transcript_agentic_loop.AgenticLoopContext'>
[DEBUG] source_context type: <class 'tests.e2e.test_golden_transcript_agentic_loop.AgenticLoopContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_73f7cd461e634f9cbe1c51c8925dc9bc', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [{'turn': 2, 'generated_command': {'type': 'run_agent', 'agent_name': 'tool1', 'input_data': 'test_input_1'}, 'execution_result': 'tool1_processed_test_input_1', 'timestamp': '2025-08-05T21:57:28.987499+00:00'}], 'final_state': ''}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_73f7cd461e634f9cbe1c51c8925dc9bc
[DEBUG] actual_source_value: run_73f7cd461e634f9cbe1c51c8925dc9bc
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: final_state
[DEBUG] current_value:
[DEBUG] actual_source_value:
[DEBUG] Field unchanged: final_state
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:28,987 - flujo - INFO - LoopStep 'AgenticExplorationLoop': Starting Iteration 2/5
2025-08-05 14:57:28,988 - flujo - WARNING - Step 'AgenticExplorationLoop' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:28,988 - flujo - ERROR - Step 'command_executor_step' encountered critical exception: Please review the first result
2025-08-05 14:57:28,988 - flujo - ERROR - Error in LoopStep 'AgenticExplorationLoop': Please review the first result
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'AgenticExplorationLoop': Starting Iteration 1/5
INFO     flujo:telemetry.py:54 LoopStep 'AgenticExplorationLoop': Starting Iteration 2/5
ERROR    flujo:telemetry.py:54 Step 'command_executor_step' encountered critical exception: Please review the first result
ERROR    flujo:telemetry.py:54 Error in LoopStep 'AgenticExplorationLoop': Please review the first result
WARNING  flujo:telemetry.py:54 Step 'AgenticExplorationLoop' failed. Halting pipeline execution.
___________________ test_golden_transcript_dynamic_parallel ____________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/e2e/test_golden_transcript_dynamic_parallel.py:128: in test_golden_transcript_dynamic_parallel
    assert len(final_context.executed_branches) == 1
E   AssertionError: assert 0 == 1
E    +  where 0 = len([])
E    +    where [] = DynamicParallelContext(run_id='run_37f4f2764e8d4181952b895fa0097d6d', initial_prompt='test', scratchpad={'status': 'completed'}, hitl_history=[], command_log=[], executed_branches=[], branch_results={}, total_failures=0).executed_branches
----------------------------- Captured stdout call -----------------------------
[DEBUG] Branch branch1 called with data: test_input
[DEBUG] Branch branch1 context is None: False
[DEBUG] Branch branch1 context.executed_branches before: []
[DEBUG] Branch branch1 context.executed_branches after: ['branch1']
[DEBUG] Branch branch1 context.branch_results: {'branch1': 'branch1_processed_test_input'}
2025-08-05 14:57:29,015 - flujo - INFO - Counting string output as 1 token for step 'branch1': 'branch1_processed_test_input'
[DEBUG] Branch branch2 called with data: test_input
[DEBUG] Branch branch2 context is None: False
[DEBUG] Branch branch2 context.executed_branches before: []
[DEBUG] Branch branch2 context.executed_branches after: ['branch2']
[DEBUG] Branch branch2 context.branch_results: {'branch2': 'branch2_processed_test_input'}
2025-08-05 14:57:29,015 - flujo - INFO - Counting string output as 1 token for step 'branch2': 'branch2_processed_test_input'
[DEBUG] Branch branch3 called with data: test_input
[DEBUG] Branch branch3 context is None: False
[DEBUG] Branch branch3 will fail intentionally
2025-08-05 14:57:29,015 - flujo - WARNING - Step 'branch3' agent execution attempt 1 failed: Intentional failure in branch3
[DEBUG] Branch branch3 called with data: test_input
[DEBUG] Branch branch3 context is None: False
[DEBUG] Branch branch3 will fail intentionally
2025-08-05 14:57:29,015 - flujo - WARNING - Step 'branch3' agent execution attempt 2 failed: Intentional failure in branch3
[DEBUG] Branch branch3 called with data: test_input
[DEBUG] Branch branch3 context is None: False
[DEBUG] Branch branch3 will fail intentionally
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:29,015 - flujo - ERROR - Step 'branch3' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'branch1': 'branch1_processed_test_input'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'branch2': 'branch2_processed_test_input'
WARNING  flujo:telemetry.py:54 Step 'branch3' agent execution attempt 1 failed: Intentional failure in branch3
WARNING  flujo:telemetry.py:54 Step 'branch3' agent execution attempt 2 failed: Intentional failure in branch3
ERROR    flujo:telemetry.py:54 Step 'branch3' agent failed after 3 attempts
______________ test_golden_transcript_dynamic_parallel_selective _______________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/e2e/test_golden_transcript_dynamic_parallel.py:204: in test_golden_transcript_dynamic_parallel_selective
    assert len(final_context.executed_branches) == 1
E   AssertionError: assert 0 == 1
E    +  where 0 = len([])
E    +    where [] = DynamicParallelContext(run_id='run_bb9565495e1947b093288d1e0bc2e54a', initial_prompt='test', scratchpad={'status': 'completed'}, hitl_history=[], command_log=[], executed_branches=[], branch_results={}, total_failures=0).executed_branches
----------------------------- Captured stdout call -----------------------------
[DEBUG] Branch branch1 called with data: selective_input
[DEBUG] Branch branch1 context is None: False
[DEBUG] Branch branch1 context.executed_branches before: []
[DEBUG] Branch branch1 context.executed_branches after: ['branch1']
[DEBUG] Branch branch1 context.branch_results: {'branch1': 'branch1_processed_selective_input'}
2025-08-05 14:57:29,021 - flujo - INFO - Counting string output as 1 token for step 'branch1': 'branch1_processed_selective_input'
[DEBUG] Branch branch3 called with data: selective_input
[DEBUG] Branch branch3 context is None: False
[DEBUG] Branch branch3 context.executed_branches before: []
[DEBUG] Branch branch3 context.executed_branches after: ['branch3']
[DEBUG] Branch branch3 context.branch_results: {'branch3': 'branch3_processed_selective_input'}
2025-08-05 14:57:29,021 - flujo - INFO - Counting string output as 1 token for step 'branch3': 'branch3_processed_selective_input'
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'branch1': 'branch1_processed_selective_input'
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'branch3': 'branch3_processed_selective_input'
_________________ test_golden_transcript_refine_max_iterations _________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/e2e/test_golden_transcript_refine.py:142: in test_golden_transcript_refine_max_iterations
    assert isinstance(final_output, RefinementCheck)
E   AssertionError: assert False
E    +  where False = isinstance({'value': 2}, <class 'flujo.domain.models.RefinementCheck'>)
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === test_refinement_max
2025-08-05 14:57:29,031 - flujo - INFO - LoopStep 'test_refinement_max': Starting Iteration 1/2
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.e2e.test_golden_transcript_refine.RefinementContext'>
[DEBUG] source_context type: <class 'tests.e2e.test_golden_transcript_refine.RefinementContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_32d2fd0c989b43d38c5feba96f6b4428', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'refinement_iterations': 0, 'final_refined_value': 0}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_32d2fd0c989b43d38c5feba96f6b4428
[DEBUG] actual_source_value: run_32d2fd0c989b43d38c5feba96f6b4428
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: refinement_iterations
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: refinement_iterations
[DEBUG] Processing field: final_refined_value
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: final_refined_value
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,032 - flujo - INFO - LoopStep 'test_refinement_max': Starting Iteration 2/2
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.e2e.test_golden_transcript_refine.RefinementContext'>
[DEBUG] source_context type: <class 'tests.e2e.test_golden_transcript_refine.RefinementContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_32d2fd0c989b43d38c5feba96f6b4428', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'refinement_iterations': 0, 'final_refined_value': 0}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_32d2fd0c989b43d38c5feba96f6b4428
[DEBUG] actual_source_value: run_32d2fd0c989b43d38c5feba96f6b4428
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: refinement_iterations
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: refinement_iterations
[DEBUG] Processing field: final_refined_value
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: final_refined_value
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,033 - flujo - WARNING - Step 'test_refinement_max' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'test_refinement_max': Starting Iteration 1/2
INFO     flujo:telemetry.py:54 LoopStep 'test_refinement_max': Starting Iteration 2/2
WARNING  flujo:telemetry.py:54 Step 'test_refinement_max' failed. Halting pipeline execution.
___ TestHITLStepMigrationIntegration.test_hitl_step_with_different_contexts ____
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_hitl_step_migration_integration.py:141: in test_hitl_step_with_different_contexts
    await executor_core._handle_hitl_step(
flujo/application/core/ultra_executor.py:2583: in _handle_hitl_step
    raise PausedException(message)
E   flujo.exceptions.PausedException: test_data

During handling of the above exception, another exception occurred:
tests/integration/test_hitl_step_migration_integration.py:153: in test_hitl_step_with_different_contexts
    assert populated_context.scratchpad["existing_key"] == "existing_value"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   KeyError: 'existing_key'
_______________________ test_programmatic_check_failure ________________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_hybrid_validation.py:57: in test_programmatic_check_failure
    assert "FailValidator" in history.feedback
E   AssertionError: assert 'FailValidator' in 'Agent execution failed with IndexError: No more outputs available'
E    +  where 'Agent execution failed with IndexError: No more outputs available' = StepResult(name='validate', output=None, success=False, attempts=3, latency_s=0.0003392089856788516, token_counts=1, c...Agent execution failed with IndexError: No more outputs available', branch_context=None, metadata_={}, step_history=[]).feedback
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:29,229 - flujo - INFO - Counting string output as 1 token for step 'validate': 'bad'
2025-08-05 14:57:29,229 - flujo - WARNING - Step 'validate' validation failed: bad output
2025-08-05 14:57:29,229 - flujo - WARNING - Step 'validate' agent execution attempt 2 failed: No more outputs available
2025-08-05 14:57:29,229 - flujo - WARNING - Step 'validate' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:29,229 - flujo - ERROR - Step 'validate' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'validate': 'bad'
WARNING  flujo:telemetry.py:54 Step 'validate' validation failed: bad output
WARNING  flujo:telemetry.py:54 Step 'validate' agent execution attempt 2 failed: No more outputs available
ERROR    flujo:telemetry.py:54 Step 'validate' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'validate' failed. Halting pipeline execution.
___________________________ test_aggregated_feedback ___________________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_hybrid_validation.py:83: in test_aggregated_feedback
    assert "plugin fail" in fb
E   AssertionError: assert 'plugin fail' in 'Agent execution failed with IndexError: No more outputs available'
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:29,234 - flujo - INFO - Counting string output as 1 token for step 'validate': 'bad'
2025-08-05 14:57:29,234 - flujo - WARNING - Step 'validate' validation failed: bad output
2025-08-05 14:57:29,234 - flujo - WARNING - Step 'validate' agent execution attempt 2 failed: No more outputs available
2025-08-05 14:57:29,234 - flujo - WARNING - Step 'validate' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:29,234 - flujo - ERROR - Step 'validate' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'validate': 'bad'
WARNING  flujo:telemetry.py:54 Step 'validate' validation failed: bad output
WARNING  flujo:telemetry.py:54 Step 'validate' agent execution attempt 2 failed: No more outputs available
ERROR    flujo:telemetry.py:54 Step 'validate' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'validate' failed. Halting pipeline execution.
_____ TestRemainingFunctionPreservation.test_cache_step_logic_preservation _____
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_legacy_cleanup_validation.py:115: in test_cache_step_logic_preservation
    result = await executor._handle_cache_step(
flujo/application/core/ultra_executor.py:2713: in _handle_cache_step
    result = await self.execute(frame)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/core/ultra_executor.py:582: in execute
    result = await self._execute_agent_step(
flujo/application/core/ultra_executor.py:1233: in _execute_agent_step
    for attempt in range(1, max_retries + 1):  # +1 because we want max_retries total attempts
                            ^^^^^^^^^^^^^^^
E   TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
______ TestRemainingFunctionPreservation.test_run_step_logic_preservation ______
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_legacy_cleanup_validation.py:259: in test_run_step_logic_preservation
    result = await executor.execute_step(
flujo/application/core/ultra_executor.py:623: in execute_step
    return await self.execute(
flujo/application/core/ultra_executor.py:582: in execute
    result = await self._execute_agent_step(
flujo/application/core/ultra_executor.py:1233: in _execute_agent_step
    for attempt in range(1, max_retries + 1):  # +1 because we want max_retries total attempts
                            ^^^^^^^^^^^^^^^
E   TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
____________ TestLegacyCleanupSafety.test_error_handling_preserved _____________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_legacy_cleanup_validation.py:395: in test_error_handling_preserved
    await executor._handle_cache_step(
flujo/application/core/ultra_executor.py:2736: in _handle_cache_step
    return await self.execute(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
flujo/application/core/ultra_executor.py:582: in execute
    result = await self._execute_agent_step(
flujo/application/core/ultra_executor.py:1180: in _execute_agent_step
    result = StepResult(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for StepResult
E   name
E     Input should be a valid string [type=string_type, input_value=<Mock name='mock.wrapped_...p.name' id='4606633808'>, input_type=Mock]
E       For further information visit https://errors.pydantic.dev/2.11/v/string_type

During handling of the above exception, another exception occurred:
tests/integration/test_legacy_cleanup_validation.py:408: in test_error_handling_preserved
    assert any(error_type in error_str for error_type in ["MissingAgentError", "ValidationError", "Fallback loop detected"])
E   assert False
E    +  where False = any(<generator object TestLegacyCleanupSafety.test_error_handling_preserved.<locals>.<genexpr> at 0x1121dda80>)
----------------------------- Captured stdout call -----------------------------
2025-08-05 14:57:29,373 - flujo - WARNING - Cache key generation failed for step 'test_step': 'Mock' object is not iterable. Skipping cache.
------------------------------ Captured log call -------------------------------
WARNING  flujo:telemetry.py:54 Cache key generation failed for step 'test_step': 'Mock' object is not iterable. Skipping cache.
__________________ test_loop_step_iteration_spans_and_logging __________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_loop_step_execution.py:461: in test_loop_step_iteration_spans_and_logging
    assert "LoopStep 'loop_log' exit condition met at iteration 2." in infos
E   assert "LoopStep 'loop_log' exit condition met at iteration 2." in ["LoopStep 'loop_log': Starting Iteration 1/2", "LoopStep 'loop_log': Starting Iteration 2/2"]
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === loop_log
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'flujo.domain.models.PipelineContext'>
[DEBUG] source_context type: <class 'flujo.domain.models.PipelineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_ddcf78c956e24cd69213e5a37fc24e4d', 'initial_prompt': '0', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': []}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_ddcf78c956e24cd69213e5a37fc24e4d
[DEBUG] actual_source_value: run_ddcf78c956e24cd69213e5a37fc24e4d
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'flujo.domain.models.PipelineContext'>
[DEBUG] source_context type: <class 'flujo.domain.models.PipelineContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_ddcf78c956e24cd69213e5a37fc24e4d', 'initial_prompt': '0', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': []}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_ddcf78c956e24cd69213e5a37fc24e4d
[DEBUG] actual_source_value: run_ddcf78c956e24cd69213e5a37fc24e4d
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
__________________ test_loop_step_error_logging_in_callables ___________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_loop_step_execution.py:508: in test_loop_step_error_logging_in_callables
    assert any("Error in iteration_input_mapper for LoopStep 'loop_err_log'" in m for m in errors)
E   assert False
E    +  where False = any(<generator object test_loop_step_error_logging_in_callables.<locals>.<genexpr> at 0x113c76810>)
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === loop_err_log
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_loop_step_execution.Ctx'>
[DEBUG] source_context type: <class 'tests.integration.test_loop_step_execution.Ctx'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'counter': 0}
[DEBUG] Processing field: counter
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: counter
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
________________ test_loop_with_context_updates_error_handling _________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_loop_with_context_updates.py:227: in test_loop_with_context_updates_error_handling
    assert result.step_history[-1].success is True  # Should succeed when exiting by condition
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert False is True
E    +  where False = StepResult(name='error_loop', output=None, success=False, attempts=2, latency_s=0.0011529590119607747, token_counts=0,...reason='', final_state={}), metadata_={'iterations': 2, 'exit_reason': 'condition_with_body_failure'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === error_loop
2025-08-05 14:57:29,635 - flujo - INFO - LoopStep 'error_loop': Starting Iteration 1/5
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_loop_with_context_updates.LoopContext'>
[DEBUG] source_context type: <class 'tests.integration.test_loop_with_context_updates.LoopContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_1503bace955e41ef8d2d7cafbc9d9bc3', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'iteration_count': 1, 'accumulated_value': 0, 'loop_exit_reason': '', 'final_state': {}}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_1503bace955e41ef8d2d7cafbc9d9bc3
[DEBUG] actual_source_value: run_1503bace955e41ef8d2d7cafbc9d9bc3
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: iteration_count
[DEBUG] current_value: 1
[DEBUG] actual_source_value: 1
[DEBUG] Field unchanged: iteration_count
[DEBUG] Processing field: accumulated_value
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: accumulated_value
[DEBUG] Processing field: loop_exit_reason
[DEBUG] current_value:
[DEBUG] actual_source_value:
[DEBUG] Field unchanged: loop_exit_reason
[DEBUG] Processing field: final_state
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: final_state
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,635 - flujo - INFO - LoopStep 'error_loop': Starting Iteration 2/5
2025-08-05 14:57:29,635 - flujo - WARNING - Step 'failing_step' agent execution attempt 1 failed: Intentional failure
2025-08-05 14:57:29,635 - flujo - WARNING - Step 'failing_step' agent execution attempt 2 failed: Intentional failure
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_loop_with_context_updates.LoopContext'>
[DEBUG] source_context type: <class 'tests.integration.test_loop_with_context_updates.LoopContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_1503bace955e41ef8d2d7cafbc9d9bc3', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'iteration_count': 4, 'accumulated_value': 0, 'loop_exit_reason': '', 'final_state': {}}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_1503bace955e41ef8d2d7cafbc9d9bc3
[DEBUG] actual_source_value: run_1503bace955e41ef8d2d7cafbc9d9bc3
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: iteration_count
[DEBUG] current_value: 4
[DEBUG] actual_source_value: 4
[DEBUG] Field unchanged: iteration_count
[DEBUG] Processing field: accumulated_value
[DEBUG] current_value: 0
[DEBUG] actual_source_value: 0
[DEBUG] Field unchanged: accumulated_value
[DEBUG] Processing field: loop_exit_reason
[DEBUG] current_value:
[DEBUG] actual_source_value:
[DEBUG] Field unchanged: loop_exit_reason
[DEBUG] Processing field: final_state
[DEBUG] current_value: {}
[DEBUG] actual_source_value: {}
[DEBUG] Merging dictionaries for field: final_state
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,636 - flujo - WARNING - Step 'error_loop' failed. Halting pipeline execution.
----------------------------- Captured stderr call -----------------------------
2025-08-05 14:57:29,635 - flujo - ERROR - Step 'failing_step' agent failed after 3 attempts
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'error_loop': Starting Iteration 1/5
INFO     flujo:telemetry.py:54 LoopStep 'error_loop': Starting Iteration 2/5
WARNING  flujo:telemetry.py:54 Step 'failing_step' agent execution attempt 1 failed: Intentional failure
WARNING  flujo:telemetry.py:54 Step 'failing_step' agent execution attempt 2 failed: Intentional failure
ERROR    flujo:telemetry.py:54 Step 'failing_step' agent failed after 3 attempts
WARNING  flujo:telemetry.py:54 Step 'error_loop' failed. Halting pipeline execution.
___________________________ test_map_over_sequential ___________________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_map_over_step.py:28: in test_map_over_sequential
    assert result.step_history[-1].output == [2, 4, 6]
E   assert [2] == [2, 4, 6]
E
E     Right contains 2 more items, first extra item: 4
E
E     Full diff:
E       [
E           2,
E     -     4,
E     -     6,
E       ]
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === mapper
2025-08-05 14:57:29,648 - flujo - INFO - LoopStep 'mapper': Starting Iteration 1/1
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'nums': [1, 2, 3]}
[DEBUG] Processing field: nums
[DEBUG] current_value: [1, 2, 3]
[DEBUG] actual_source_value: [1, 2, 3]
[DEBUG] Merging lists for field: nums
[DEBUG] No new items to add to list field: nums
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,648 - flujo - WARNING - Step 'mapper' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'mapper': Starting Iteration 1/1
WARNING  flujo:telemetry.py:54 Step 'mapper' failed. Halting pipeline execution.
____________________________ test_map_over_parallel ____________________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_map_over_step.py:43: in test_map_over_parallel
    assert result.step_history[-1].output == [0, 1, 2, 3]
E   assert [0] == [0, 1, 2, 3]
E
E     Right contains 3 more items, first extra item: 1
E
E     Full diff:
E       [
E           0,
E     -     1,
E     -     2,
E     -     3,
E       ]
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === mapper_par
2025-08-05 14:57:29,652 - flujo - INFO - LoopStep 'mapper_par': Starting Iteration 1/1
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'nums': [0, 1, 2, 3]}
[DEBUG] Processing field: nums
[DEBUG] current_value: [0, 1, 2, 3]
[DEBUG] actual_source_value: [0, 1, 2, 3]
[DEBUG] Merging lists for field: nums
[DEBUG] No new items to add to list field: nums
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,664 - flujo - WARNING - Step 'mapper_par' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'mapper_par': Starting Iteration 1/1
WARNING  flujo:telemetry.py:54 Step 'mapper_par' failed. Halting pipeline execution.
______________________ test_map_over_reusable_after_empty ______________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_map_over_step.py:81: in test_map_over_reusable_after_empty
    assert second.step_history[-1].output == [6, 8]
E   assert [6] == [6, 8]
E
E     Right contains one more item: 8
E
E     Full diff:
E       [
E           6,
E     -     8,
E       ]
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === mapper_reuse
2025-08-05 14:57:29,670 - flujo - INFO - LoopStep 'mapper_reuse': Starting Iteration 1/1
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'nums': []}
[DEBUG] Processing field: nums
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: nums
[DEBUG] No new items to add to list field: nums
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
[KIRO DEBUG] === HANDLE LOOP STEP === mapper_reuse
2025-08-05 14:57:29,671 - flujo - INFO - LoopStep 'mapper_reuse': Starting Iteration 1/1
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'nums': [3, 4]}
[DEBUG] Processing field: nums
[DEBUG] current_value: [3, 4]
[DEBUG] actual_source_value: [3, 4]
[DEBUG] Merging lists for field: nums
[DEBUG] No new items to add to list field: nums
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,671 - flujo - WARNING - Step 'mapper_reuse' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'mapper_reuse': Starting Iteration 1/1
INFO     flujo:telemetry.py:54 LoopStep 'mapper_reuse': Starting Iteration 1/1
WARNING  flujo:telemetry.py:54 Step 'mapper_reuse' failed. Halting pipeline execution.
________________________ test_map_over_concurrent_runs _________________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_map_over_step.py:98: in test_map_over_concurrent_runs
    assert r1.step_history[-1].output == [2, 4]
E   assert [2] == [2, 4]
E
E     Right contains one more item: 4
E
E     Full diff:
E       [
E           2,
E     -     4,
E       ]
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === mapper_concurrent
2025-08-05 14:57:29,674 - flujo - INFO - LoopStep 'mapper_concurrent': Starting Iteration 1/1
[KIRO DEBUG] === HANDLE LOOP STEP === mapper_concurrent
2025-08-05 14:57:29,674 - flujo - INFO - LoopStep 'mapper_concurrent': Starting Iteration 1/1
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'nums': [1, 2]}
[DEBUG] Processing field: nums
[DEBUG] current_value: [1, 2]
[DEBUG] actual_source_value: [1, 2]
[DEBUG] Merging lists for field: nums
[DEBUG] No new items to add to list field: nums
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,674 - flujo - WARNING - Step 'mapper_concurrent' failed. Halting pipeline execution.
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_step.Ctx'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'nums': [5, 6]}
[DEBUG] Processing field: nums
[DEBUG] current_value: [5, 6]
[DEBUG] actual_source_value: [5, 6]
[DEBUG] Merging lists for field: nums
[DEBUG] No new items to add to list field: nums
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,675 - flujo - WARNING - Step 'mapper_concurrent' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'mapper_concurrent': Starting Iteration 1/1
INFO     flujo:telemetry.py:54 LoopStep 'mapper_concurrent': Starting Iteration 1/1
WARNING  flujo:telemetry.py:54 Step 'mapper_concurrent' failed. Halting pipeline execution.
WARNING  flujo:telemetry.py:54 Step 'mapper_concurrent' failed. Halting pipeline execution.
___________________ test_map_over_with_context_updates_basic ___________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_map_over_with_context_updates.py:125: in test_map_over_with_context_updates_basic
    assert result.step_history[-1].success is True
E   AssertionError: assert False is True
E    +  where False = StepResult(name='basic_map', output=['processed_item1'], success=False, attempts=1, latency_s=0.000671458023134619, to...processing_history=['processed_item1']), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === basic_map
2025-08-05 14:57:29,679 - flujo - INFO - LoopStep 'basic_map': Starting Iteration 1/1
2025-08-05 14:57:29,679 - flujo - INFO - Counting string output as 1 token for step 'map_item_step': 'processed_item1'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_16f89afc7845404daa9b886bfa8e9eb4', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'items': ['item1', 'item2', 'item3', 'item4'], 'processed_items': ['item1'], 'total_processed': 1, 'map_results': {'item1': 'processed_item1'}, 'current_item': 'item1', 'processing_history': ['processed_item1']}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_16f89afc7845404daa9b886bfa8e9eb4
[DEBUG] actual_source_value: run_16f89afc7845404daa9b886bfa8e9eb4
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: items
[DEBUG] current_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] actual_source_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] Merging lists for field: items
[DEBUG] No new items to add to list field: items
[DEBUG] Processing field: processed_items
[DEBUG] current_value: ['item1']
[DEBUG] actual_source_value: ['item1']
[DEBUG] Merging lists for field: processed_items
[DEBUG] No new items to add to list field: processed_items
[DEBUG] Processing field: total_processed
[DEBUG] current_value: 1
[DEBUG] actual_source_value: 1
[DEBUG] Field unchanged: total_processed
[DEBUG] Processing field: map_results
[DEBUG] current_value: {'item1': 'processed_item1'}
[DEBUG] actual_source_value: {'item1': 'processed_item1'}
[DEBUG] Merging dictionaries for field: map_results
[DEBUG] Processing field: current_item
[DEBUG] current_value: item1
[DEBUG] actual_source_value: item1
[DEBUG] Field unchanged: current_item
[DEBUG] Processing field: processing_history
[DEBUG] current_value: ['processed_item1']
[DEBUG] actual_source_value: ['processed_item1']
[DEBUG] Merging lists for field: processing_history
[DEBUG] No new items to add to list field: processing_history
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,679 - flujo - WARNING - Step 'basic_map' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'basic_map': Starting Iteration 1/1
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'map_item_step': 'processed_item1'
WARNING  flujo:telemetry.py:54 Step 'basic_map' failed. Halting pipeline execution.
______________ test_map_over_with_context_updates_error_handling _______________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_map_over_with_context_updates.py:159: in test_map_over_with_context_updates_error_handling
    assert result.step_history[-1].success is True
E   AssertionError: assert False is True
E    +  where False = StepResult(name='error_map', output=['processed_item1'], success=False, attempts=1, latency_s=0.0006040000007487833, t...processing_history=['attempted_item1']), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === error_map
2025-08-05 14:57:29,689 - flujo - INFO - LoopStep 'error_map': Starting Iteration 1/1
2025-08-05 14:57:29,689 - flujo - INFO - Counting string output as 1 token for step 'map_with_error_step': 'processed_item1'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_7a5c3dea51d249d283501f7a276eac9a', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'items': ['item1', 'item2', 'item3', 'item4'], 'processed_items': ['item1'], 'total_processed': 1, 'map_results': {'item1': 'processed_item1'}, 'current_item': 'item1', 'processing_history': ['attempted_item1']}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_7a5c3dea51d249d283501f7a276eac9a
[DEBUG] actual_source_value: run_7a5c3dea51d249d283501f7a276eac9a
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: items
[DEBUG] current_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] actual_source_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] Merging lists for field: items
[DEBUG] No new items to add to list field: items
[DEBUG] Processing field: processed_items
[DEBUG] current_value: ['item1']
[DEBUG] actual_source_value: ['item1']
[DEBUG] Merging lists for field: processed_items
[DEBUG] No new items to add to list field: processed_items
[DEBUG] Processing field: total_processed
[DEBUG] current_value: 1
[DEBUG] actual_source_value: 1
[DEBUG] Field unchanged: total_processed
[DEBUG] Processing field: map_results
[DEBUG] current_value: {'item1': 'processed_item1'}
[DEBUG] actual_source_value: {'item1': 'processed_item1'}
[DEBUG] Merging dictionaries for field: map_results
[DEBUG] Processing field: current_item
[DEBUG] current_value: item1
[DEBUG] actual_source_value: item1
[DEBUG] Field unchanged: current_item
[DEBUG] Processing field: processing_history
[DEBUG] current_value: ['attempted_item1']
[DEBUG] actual_source_value: ['attempted_item1']
[DEBUG] Merging lists for field: processing_history
[DEBUG] No new items to add to list field: processing_history
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,689 - flujo - WARNING - Step 'error_map' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'error_map': Starting Iteration 1/1
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'map_with_error_step': 'processed_item1'
WARNING  flujo:telemetry.py:54 Step 'error_map' failed. Halting pipeline execution.
_____________ test_map_over_with_context_updates_context_dependent _____________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_map_over_with_context_updates.py:195: in test_map_over_with_context_updates_context_dependent
    assert result.step_history[-1].success is True
E   AssertionError: assert False is True
E    +  where False = StepResult(name='context_dependent_map', output=['early_processed_item1'], success=False, attempts=1, latency_s=0.0006...ng_history=['context_dependent_item1']), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === context_dependent_map
2025-08-05 14:57:29,694 - flujo - INFO - LoopStep 'context_dependent_map': Starting Iteration 1/1
2025-08-05 14:57:29,695 - flujo - INFO - Counting string output as 1 token for step 'map_with_context_dependent_step': 'early_processed_item1'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_29eab1b0c59845a6b2cfce82a638656c', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'items': ['item1', 'item2', 'item3', 'item4'], 'processed_items': ['item1'], 'total_processed': 1, 'map_results': {'item1': 'early_processed_item1'}, 'current_item': 'item1', 'processing_history': ['context_dependent_item1']}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_29eab1b0c59845a6b2cfce82a638656c
[DEBUG] actual_source_value: run_29eab1b0c59845a6b2cfce82a638656c
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: items
[DEBUG] current_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] actual_source_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] Merging lists for field: items
[DEBUG] No new items to add to list field: items
[DEBUG] Processing field: processed_items
[DEBUG] current_value: ['item1']
[DEBUG] actual_source_value: ['item1']
[DEBUG] Merging lists for field: processed_items
[DEBUG] No new items to add to list field: processed_items
[DEBUG] Processing field: total_processed
[DEBUG] current_value: 1
[DEBUG] actual_source_value: 1
[DEBUG] Field unchanged: total_processed
[DEBUG] Processing field: map_results
[DEBUG] current_value: {'item1': 'early_processed_item1'}
[DEBUG] actual_source_value: {'item1': 'early_processed_item1'}
[DEBUG] Merging dictionaries for field: map_results
[DEBUG] Processing field: current_item
[DEBUG] current_value: item1
[DEBUG] actual_source_value: item1
[DEBUG] Field unchanged: current_item
[DEBUG] Processing field: processing_history
[DEBUG] current_value: ['context_dependent_item1']
[DEBUG] actual_source_value: ['context_dependent_item1']
[DEBUG] Merging lists for field: processing_history
[DEBUG] No new items to add to list field: processing_history
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,695 - flujo - WARNING - Step 'context_dependent_map' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'context_dependent_map': Starting Iteration 1/1
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'map_with_context_dependent_step': 'early_processed_item1'
WARNING  flujo:telemetry.py:54 Step 'context_dependent_map' failed. Halting pipeline execution.
______________ test_map_over_with_context_updates_nested_context _______________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_map_over_with_context_updates.py:229: in test_map_over_with_context_updates_nested_context
    assert result.step_history[-1].success is True
E   assert False is True
E    +  where False = StepResult(name='nested_context_map', output=["{'original_item': 'item1', 'processed_count': 1, 'history_length': 0}"]...', processing_history=['nested_item1']), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === nested_context_map
2025-08-05 14:57:29,700 - flujo - INFO - LoopStep 'nested_context_map': Starting Iteration 1/1
2025-08-05 14:57:29,700 - flujo - INFO - Counting string output as 1 token for step 'map_with_nested_context_step': '{'original_item': 'item1', 'processed_count': 1, '...'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_a32257e00efb46f8a709eb687bbf6b40', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'items': ['item1', 'item2', 'item3', 'item4'], 'processed_items': ['item1'], 'total_processed': 1, 'map_results': {'item1': {'original_item': 'item1', 'processed_count': 1, 'history_length': 0}}, 'current_item': 'item1', 'processing_history': ['nested_item1']}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_a32257e00efb46f8a709eb687bbf6b40
[DEBUG] actual_source_value: run_a32257e00efb46f8a709eb687bbf6b40
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: items
[DEBUG] current_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] actual_source_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] Merging lists for field: items
[DEBUG] No new items to add to list field: items
[DEBUG] Processing field: processed_items
[DEBUG] current_value: ['item1']
[DEBUG] actual_source_value: ['item1']
[DEBUG] Merging lists for field: processed_items
[DEBUG] No new items to add to list field: processed_items
[DEBUG] Processing field: total_processed
[DEBUG] current_value: 1
[DEBUG] actual_source_value: 1
[DEBUG] Field unchanged: total_processed
[DEBUG] Processing field: map_results
[DEBUG] current_value: {'item1': {'original_item': 'item1', 'processed_count': 1, 'history_length': 0}}
[DEBUG] actual_source_value: {'item1': {'original_item': 'item1', 'processed_count': 1, 'history_length': 0}}
[DEBUG] Merging dictionaries for field: map_results
[DEBUG] Processing field: current_item
[DEBUG] current_value: item1
[DEBUG] actual_source_value: item1
[DEBUG] Field unchanged: current_item
[DEBUG] Processing field: processing_history
[DEBUG] current_value: ['nested_item1']
[DEBUG] actual_source_value: ['nested_item1']
[DEBUG] Merging lists for field: processing_history
[DEBUG] No new items to add to list field: processing_history
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,701 - flujo - WARNING - Step 'nested_context_map' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'nested_context_map': Starting Iteration 1/1
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'map_with_nested_context_step': '{'original_item': 'item1', 'processed_count': 1, '...'
WARNING  flujo:telemetry.py:54 Step 'nested_context_map' failed. Halting pipeline execution.
______________ test_map_over_with_context_updates_state_isolation ______________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_map_over_with_context_updates.py:277: in test_map_over_with_context_updates_state_isolation
    assert result.step_history[-1].success is True
E   assert False is True
E    +  where False = StepResult(name='isolation_map', output=["{'item': 'item1', 'total_processed_at_start': 0, 'processed_count_at_start':...nt_item='item1', processing_history=[]), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === isolation_map
2025-08-05 14:57:29,706 - flujo - INFO - LoopStep 'isolation_map': Starting Iteration 1/1
2025-08-05 14:57:29,706 - flujo - INFO - Counting string output as 1 token for step 'isolation_map_step': '{'item': 'item1', 'total_processed_at_start': 0, '...'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_7377398e329041cc8fd4a2cfa742d496', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'items': ['item1', 'item2', 'item3', 'item4'], 'processed_items': ['item1'], 'total_processed': 1, 'map_results': {'item1': {'item': 'item1', 'total_processed_at_start': 0, 'processed_count_at_start': 0, 'current_iteration': 1}}, 'current_item': 'item1', 'processing_history': []}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_7377398e329041cc8fd4a2cfa742d496
[DEBUG] actual_source_value: run_7377398e329041cc8fd4a2cfa742d496
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: items
[DEBUG] current_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] actual_source_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] Merging lists for field: items
[DEBUG] No new items to add to list field: items
[DEBUG] Processing field: processed_items
[DEBUG] current_value: ['item1']
[DEBUG] actual_source_value: ['item1']
[DEBUG] Merging lists for field: processed_items
[DEBUG] No new items to add to list field: processed_items
[DEBUG] Processing field: total_processed
[DEBUG] current_value: 1
[DEBUG] actual_source_value: 1
[DEBUG] Field unchanged: total_processed
[DEBUG] Processing field: map_results
[DEBUG] current_value: {'item1': {'item': 'item1', 'total_processed_at_start': 0, 'processed_count_at_start': 0, 'current_iteration': 1}}
[DEBUG] actual_source_value: {'item1': {'item': 'item1', 'total_processed_at_start': 0, 'processed_count_at_start': 0, 'current_iteration': 1}}
[DEBUG] Merging dictionaries for field: map_results
[DEBUG] Processing field: current_item
[DEBUG] current_value: item1
[DEBUG] actual_source_value: item1
[DEBUG] Field unchanged: current_item
[DEBUG] Processing field: processing_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: processing_history
[DEBUG] No new items to add to list field: processing_history
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,706 - flujo - WARNING - Step 'isolation_map' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'isolation_map': Starting Iteration 1/1
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'isolation_map_step': '{'item': 'item1', 'total_processed_at_start': 0, '...'
WARNING  flujo:telemetry.py:54 Step 'isolation_map' failed. Halting pipeline execution.
____________ test_map_over_with_context_updates_complex_aggregation ____________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_map_over_with_context_updates.py:329: in test_map_over_with_context_updates_complex_aggregation
    assert result.step_history[-1].success is True
E   assert False is True
E    +  where False = StepResult(name='aggregation_map', output=["{'item': 'item1', 'running_avg_length': 5.0, 'total_chars_processed': 5, '...nt_item='item1', processing_history=[]), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === aggregation_map
2025-08-05 14:57:29,712 - flujo - INFO - LoopStep 'aggregation_map': Starting Iteration 1/1
2025-08-05 14:57:29,712 - flujo - INFO - Counting string output as 1 token for step 'aggregation_map_step': '{'item': 'item1', 'running_avg_length': 5.0, 'tota...'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_ea65ea5c0b524452a14cdf0382be04ed', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'items': ['item1', 'item2', 'item3', 'item4'], 'processed_items': ['item1'], 'total_processed': 1, 'map_results': {'item1': {'item': 'item1', 'running_avg_length': 5.0, 'total_chars_processed': 5, 'items_processed': 1, 'current_item_length': 5}}, 'current_item': 'item1', 'processing_history': []}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_ea65ea5c0b524452a14cdf0382be04ed
[DEBUG] actual_source_value: run_ea65ea5c0b524452a14cdf0382be04ed
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: items
[DEBUG] current_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] actual_source_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] Merging lists for field: items
[DEBUG] No new items to add to list field: items
[DEBUG] Processing field: processed_items
[DEBUG] current_value: ['item1']
[DEBUG] actual_source_value: ['item1']
[DEBUG] Merging lists for field: processed_items
[DEBUG] No new items to add to list field: processed_items
[DEBUG] Processing field: total_processed
[DEBUG] current_value: 1
[DEBUG] actual_source_value: 1
[DEBUG] Field unchanged: total_processed
[DEBUG] Processing field: map_results
[DEBUG] current_value: {'item1': {'item': 'item1', 'running_avg_length': 5.0, 'total_chars_processed': 5, 'items_processed': 1, 'current_item_length': 5}}
[DEBUG] actual_source_value: {'item1': {'item': 'item1', 'running_avg_length': 5.0, 'total_chars_processed': 5, 'items_processed': 1, 'current_item_length': 5}}
[DEBUG] Merging dictionaries for field: map_results
[DEBUG] Processing field: current_item
[DEBUG] current_value: item1
[DEBUG] actual_source_value: item1
[DEBUG] Field unchanged: current_item
[DEBUG] Processing field: processing_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: processing_history
[DEBUG] No new items to add to list field: processing_history
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,712 - flujo - WARNING - Step 'aggregation_map' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'aggregation_map': Starting Iteration 1/1
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'aggregation_map_step': '{'item': 'item1', 'running_avg_length': 5.0, 'tota...'
WARNING  flujo:telemetry.py:54 Step 'aggregation_map' failed. Halting pipeline execution.
____________ test_map_over_with_context_updates_metadata_conflicts _____________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/integration/test_map_over_with_context_updates.py:380: in test_map_over_with_context_updates_metadata_conflicts
    assert result.step_history[-1].success is True
E   AssertionError: assert False is True
E    +  where False = StepResult(name='metadata_map', output=['metadata_processed_item1'], success=False, attempts=1, latency_s=0.0006171250...nt_item='item1', processing_history=[]), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
----------------------------- Captured stdout call -----------------------------
[KIRO DEBUG] === HANDLE LOOP STEP === metadata_map
2025-08-05 14:57:29,717 - flujo - INFO - LoopStep 'metadata_map': Starting Iteration 1/1
2025-08-05 14:57:29,718 - flujo - INFO - Counting string output as 1 token for step 'metadata_map_step': 'metadata_processed_item1'
[DEBUG] safe_merge_context_updates called
[DEBUG] target_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] source_context type: <class 'tests.integration.test_map_over_with_context_updates.MapContext'>
[DEBUG] excluded_fields: {'command_log'}
[DEBUG] source_fields: {'run_id': 'run_f2f901920dc640ceb6016c47db9d1eda', 'initial_prompt': 'test', 'scratchpad': {'status': 'running'}, 'hitl_history': [], 'command_log': [], 'items': ['item1', 'item2', 'item3', 'item4'], 'processed_items': ['item1'], 'total_processed': 1, 'map_results': {'metadata_item1': {'map_index': 0, 'map_item': 'item1', 'map_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'item1'}}}, 'current_item': 'item1', 'processing_history': []}
[DEBUG] Processing field: run_id
[DEBUG] current_value: run_f2f901920dc640ceb6016c47db9d1eda
[DEBUG] actual_source_value: run_f2f901920dc640ceb6016c47db9d1eda
[DEBUG] Field unchanged: run_id
[DEBUG] Processing field: initial_prompt
[DEBUG] current_value: test
[DEBUG] actual_source_value: test
[DEBUG] Field unchanged: initial_prompt
[DEBUG] Processing field: scratchpad
[DEBUG] current_value: {'status': 'running'}
[DEBUG] actual_source_value: {'status': 'running'}
[DEBUG] Merging dictionaries for field: scratchpad
[DEBUG] Processing field: hitl_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: hitl_history
[DEBUG] No new items to add to list field: hitl_history
[DEBUG] Skipping excluded field: command_log
[DEBUG] Processing field: items
[DEBUG] current_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] actual_source_value: ['item1', 'item2', 'item3', 'item4']
[DEBUG] Merging lists for field: items
[DEBUG] No new items to add to list field: items
[DEBUG] Processing field: processed_items
[DEBUG] current_value: ['item1']
[DEBUG] actual_source_value: ['item1']
[DEBUG] Merging lists for field: processed_items
[DEBUG] No new items to add to list field: processed_items
[DEBUG] Processing field: total_processed
[DEBUG] current_value: 1
[DEBUG] actual_source_value: 1
[DEBUG] Field unchanged: total_processed
[DEBUG] Processing field: map_results
[DEBUG] current_value: {'metadata_item1': {'map_index': 0, 'map_item': 'item1', 'map_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'item1'}}}
[DEBUG] actual_source_value: {'metadata_item1': {'map_index': 0, 'map_item': 'item1', 'map_metadata': {'iteration': 1, 'timestamp': 'now', 'data': 'item1'}}}
[DEBUG] Merging dictionaries for field: map_results
[DEBUG] Processing field: current_item
[DEBUG] current_value: item1
[DEBUG] actual_source_value: item1
[DEBUG] Field unchanged: current_item
[DEBUG] Processing field: processing_history
[DEBUG] current_value: []
[DEBUG] actual_source_value: []
[DEBUG] Merging lists for field: processing_history
[DEBUG] No new items to add to list field: processing_history
[DEBUG] Total fields updated: 0
[DEBUG] Validation errors: []
2025-08-05 14:57:29,718 - flujo - WARNING - Step 'metadata_map' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 LoopStep 'metadata_map': Starting Iteration 1/1
INFO     flujo:telemetry.py:54 Counting string output as 1 token for step 'metadata_map_step': 'metadata_processed_item1'
WARNING  flujo:telemetry.py:54 Step 'metadata_map' failed. Halting pipeline execution.
=========================== short test summary info ============================
FAILED tests/application/core/test_executor_core_hitl_step_migration.py::TestExecutorCoreHITLStepMigration::test_handle_hitl_step_context_preservation - KeyError: 'existing_key'
FAILED tests/integration/test_FSD11_bug_fix.py::test_fsd11_context_aware_agent_explicit - assert False
 +  where False = isinstance("Mock response to: User test_user: {'message': 'Hello, how are you?'}", FSD11TestOutput)
 +    where "Mock response to: User test_user: {'message': 'Hello, how are you?'}" = StepResult(name='context_aware_agent', output="Mock response to: User test_user: {'message': 'Hello, how are you?'}", ...h_context=FSD11TestContext(user_id='test_user', session_id='test_session', metadata={}), metadata_={}, step_history=[]).output
FAILED tests/application/core/test_executor_core_hitl_step_migration.py::TestExecutorCoreHITLStepMigration::test_handle_hitl_step_context_isolation - KeyError: 'key1'
FAILED tests/integration/test_FSD11_bug_fix.py::test_fsd11_context_aware_agent_kwargs - assert False
 +  where False = isinstance("Mock response to: User test_user: {'message': 'Hello, how are you?'}", FSD11TestOutput)
 +    where "Mock response to: User test_user: {'message': 'Hello, how are you?'}" = StepResult(name='kwargs_context_agent', output="Mock response to: User test_user: {'message': 'Hello, how are you?'}",...h_context=FSD11TestContext(user_id='test_user', session_id='test_session', metadata={}), metadata_={}, step_history=[]).output
FAILED tests/application/core/test_executor_core.py::TestExecutorCoreSimpleStep::test_plugin_failure_propagates - AssertionError: assert 1 == 3
 +  where 1 = StepResult(name='test_step', output=PluginOutcome(success=False, feedback='Plugin execution error', redirect_to=None, ...00125, feedback='Plugin validation failed: Plugin execution error', branch_context=None, metadata_={}, step_history=[]).attempts
FAILED tests/application/core/test_executor_core_loop_step_dispatch.py::TestExecutorCoreLoopStepDispatch::test_execute_complex_step_loopstep_telemetry_logging - assert False
 +  where False = any(<generator object TestExecutorCoreLoopStepDispatch.test_execute_complex_step_loopstep_telemetry_logging.<locals>.<genexpr> at 0x1121a32a0>)
FAILED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_max_iterations - AssertionError: assert 2 == 3
 +  where 2 = StepResult(name='test_loop', output=None, success=False, attempts=2, latency_s=0.0008920829859562218, token_counts=10,... original_value=None), metadata_={'iterations': 2, 'exit_reason': 'max_iterations_with_body_failure'}, step_history=[]).attempts
FAILED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_cost_limits - Failed: DID NOT RAISE <class 'flujo.exceptions.UsageLimitExceededError'>
FAILED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_token_limits - Failed: DID NOT RAISE <class 'flujo.exceptions.UsageLimitExceededError'>
FAILED tests/application/core/test_executor_core_conditional_step.py::TestExecutorCoreConditionalStep::test_handle_conditional_step_signature - AssertionError: assert ['step', 'dat..._setter', ...] == ['conditional...ntext_setter']

  At index 0 diff: 'step' != 'conditional_step'
  Left contains one more item: 'fallback_depth'

  Full diff:
    [
  -     'conditional_step',
  +     'step',
        'data',
        'context',
        'resources',
        'limits',
        'context_setter',
  +     'fallback_depth',
    ]
FAILED tests/application/core/test_executor_core_conditional_step.py::TestExecutorCoreConditionalStep::test_handle_conditional_step_parameter_passing - AssertionError: assert ExecutionFrame(step=<Mock spec='Step' id='4616419856'>, data='test_data', context=<Mock id='4616407248'>, resources=<M... stream=False, on_chunk=None, breach_event=None, context_setter=<Mock id='4616410128'>, result=None, _fallback_depth=0) == <Mock spec='Step' id='4616419856'>
FAILED tests/application/core/test_executor_core_conditional_step.py::TestExecutorCoreConditionalStep::test_handle_conditional_step_with_limits_and_context_setter - AssertionError: Expected 'mock' to have been called once. Called 0 times.
FAILED tests/application/core/test_executor_core_conditional_step.py::TestExecutorCoreConditionalStep::test_handle_conditional_step_integration_with_execute_complex_step - AssertionError: assert 'test_agent' == 'test_conditional'

  - test_conditional
  + test_agent
FAILED tests/application/core/test_executor_core_conditional_step_dispatch.py::TestExecutorCoreConditionalStepDispatch::test_execute_complex_step_conditionalstep_telemetry_logging - assert False
 +  where False = any(<generator object TestExecutorCoreConditionalStepDispatch.test_execute_complex_step_conditionalstep_telemetry_logging.<locals>.<genexpr> at 0x1134b5f20>)
FAILED tests/application/core/test_executor_core_conditional_step_logic.py::TestExecutorCoreConditionalStepLogic::test_branch_not_found_no_default - assert "No branch found for key 'nonexistent_branch'" in "No branch matches condition 'nonexistent_branch' and no default branch provided"
 +  where "No branch matches condition 'nonexistent_branch' and no default branch provided" = StepResult(name='test_conditional', output='test_data', success=False, attempts=1, latency_s=0.00024929200299084187, t...hes condition 'nonexistent_branch' and no default branch provided", branch_context=None, metadata_={}, step_history=[]).feedback
FAILED tests/application/core/test_executor_core_conditional_step_logic.py::TestExecutorCoreConditionalStepLogic::test_branch_output_mapper_exception - AssertionError: assert 'Branch output mapper raised an exception' in 'Error executing conditional logic or branch: Mapper failed'
 +  where 'Error executing conditional logic or branch: Mapper failed' = StepResult(name='test_conditional', output=None, success=False, attempts=1, latency_s=0.00022187497233971953, token_co...l logic or branch: Mapper failed', branch_context=None, metadata_={'executed_branch_key': 'branch_a'}, step_history=[]).feedback
FAILED tests/application/core/test_executor_core_conditional_step_logic.py::TestExecutorCoreConditionalStepLogic::test_metrics_accumulation - AssertionError: assert 0.00022445799550041556 == 1.5
 +  where 0.00022445799550041556 = StepResult(name='test_conditional', output='test_output', success=True, attempts=1, latency_s=0.00022445799550041556, ...data', scratchpad={}, hitl_history=[], command_log=[]), metadata_={'executed_branch_key': 'branch_a'}, step_history=[]).latency_s
FAILED tests/application/core/test_executor_core_conditional_step_logic.py::TestExecutorCoreConditionalStepLogic::test_context_setter_called_on_success - AssertionError: Expected 'mock' to have been called once. Called 0 times.
FAILED tests/application/core/test_executor_core_conditional_step_logic.py::TestExecutorCoreConditionalStepLogic::test_branch_execution_with_resources - KeyError: 'resources'
FAILED tests/application/core/test_executor_core_conditional_step_logic.py::TestExecutorCoreConditionalStepLogic::test_branch_execution_with_limits - KeyError: 'limits'
FAILED tests/integration/test_crash_recovery.py::test_resume_after_crash_file_backend - assert 0 == 1
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_with_none_feedback - AssertionError: assert <AsyncMock name='mock.get().success' id='4616466768'> is True
 +  where <AsyncMock name='mock.get().success' id='4616466768'> = <AsyncMock name='mock.get()' id='4616250768'>.success
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_with_usage_limits - AssertionError: assert <AsyncMock name='mock.get().success' id='4614023568'> is True
 +  where <AsyncMock name='mock.get().success' id='4614023568'> = <AsyncMock name='mock.get()' id='4614545424'>.success
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_metadata_preservation - AssertionError: assert <AsyncMock name='mock.get().success' id='4617096080'> is True
 +  where <AsyncMock name='mock.get().success' id='4617096080'> = <AsyncMock name='mock.get()' id='4618563984'>.success
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_with_critical_exceptions - Failed: DID NOT RAISE <class 'flujo.exceptions.UsageLimitExceededError'>
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_with_multiple_retries - AssertionError: assert 4 == 5
 +  where 4 = StepResult(name='fallback_step', output='fallback success', success=True, attempts=4, latency_s=0.10023279199376703, t...riggered': True, 'original_error': 'Agent execution failed with Exception: Primary failed attempt 3'}, step_history=[]).attempts
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_with_usage_meter_tracking - assert (0.1, 10, 5) == (0.0, 0, 1)

  At index 0 diff: 0.1 != 0.0

  Full diff:
    (
  -     0.0,
  ?       ^
  +     0.1,
  ?       ^
  -     0,
  +     10,
  ?     +
  -     1,
  ?     ^
  +     5,
  ?     ^
    )
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_with_processor_pipeline - AssertionError: assert False is True
 +  where False = StepResult(name='fallback_step', output=None, success=False, attempts=6, latency_s=0.000495165993925184, token_counts=...fallback_triggered': True, 'original_error': 'Agent execution failed with Exception: Primary failed'}, step_history=[]).success
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_with_plugin_runner - AssertionError: assert False is True
 +  where False = StepResult(name='fallback_step', output=None, success=False, attempts=6, latency_s=0.00028962595388293266, token_count...fallback_triggered': True, 'original_error': 'Agent execution failed with Exception: Primary failed'}, step_history=[]).success
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_with_cache_backend - assert False is True
 +  where False = StepResult(name='primary_step', output=None, success=False, attempts=3, latency_s=0.0002884159912355244, token_counts=...llback error: unsupported operand type(s) for +: 'Mock' and 'int'", branch_context=None, metadata_={}, step_history=[]).success
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_with_telemetry - AssertionError: assert False is True
 +  where False = StepResult(name='fallback_step', output=None, success=False, attempts=6, latency_s=0.0005385010153986514, token_counts...fallback_triggered': True, 'original_error': 'Agent execution failed with Exception: Primary failed'}, step_history=[]).success
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_integration_real_pipeline - AssertionError: assert 'primary success' == 'fallback success'

  - fallback success
  + primary success
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_on_plugin_failure - AttributeError: 'StepResult' object has no attribute 'metadata'
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_on_validator_failure - AssertionError: assert 'processed: primary success' == 'fallback success'

  - fallback success
  + processed: primary success
FAILED tests/application/core/test_executor_core_fallback.py::TestExecutorCoreFallback::test_fallback_on_complex_failure_chain - TypeError: argument of type 'NoneType' is not iterable
FAILED tests/integration/test_mock_output_handling.py::test_mock_output_raises_type_error - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/integration/test_mock_output_handling.py::test_pipeline_stops_on_mock - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/integration/test_crash_recovery.py::test_resume_after_crash_sqlite_backend - assert 0 == 1
FAILED tests/integration/test_dynamic_parallel_router_with_context_updates.py::test_dynamic_router_branch_failure_context_preservation - assert 'support_failed' in ['router_called', 'billing_processed']
 +  where ['router_called', 'billing_processed'] = DynamicRouterContext(run_id='run_9d3acb0d8a9240c3ae58fa6159a27a32', initial_prompt='test', scratchpad={'status': 'fail...lling': 'billing:test'}, execution_count=0, router_called=True, context_updates=['router_called', 'billing_processed']).context_updates
 +    where DynamicRouterContext(run_id='run_9d3acb0d8a9240c3ae58fa6159a27a32', initial_prompt='test', scratchpad={'status': 'fail...lling': 'billing:test'}, execution_count=0, router_called=True, context_updates=['router_called', 'billing_processed']) = PipelineResult(step_history=[StepResult(name='dynamic_router', output={'billing': {'billing_result': 'billing:test'}, ...t': Agent execution failed with ValueError: Support step failed"}, children=[], status='failed')], status='completed')).final_pipeline_context
FAILED tests/integration/test_dynamic_router_with_context_updates.py::test_dynamic_router_with_context_updates_error_handling - assert "branch 'failing_branch' failed" in "parallel step failed: branch 'failing_branch': agent execution failed with runtimeerror: intentional router branch failure"
 +  where "parallel step failed: branch 'failing_branch': agent execution failed with runtimeerror: intentional router branch failure" = <built-in method lower of str object at 0x105829c60>()
 +    where <built-in method lower of str object at 0x105829c60> = "Parallel step failed: Branch 'failing_branch': Agent execution failed with RuntimeError: Intentional router branch failure".lower
 +      where "Parallel step failed: Branch 'failing_branch': Agent execution failed with RuntimeError: Intentional router branch failure" = StepResult(name='error_router', output={'failing_branch': StepResult(name='error_router_failing_branch', output=None, ...ch_executed='', branch_count=0, total_updates=0, router_metadata={}, branch_results={}), metadata_={}, step_history=[]).feedback
FAILED tests/integration/test_embedding_cost_integration.py::TestEmbeddingCostIntegration::test_embedding_cost_tracking_strict_mode_failure - Failed: DID NOT RAISE <class 'flujo.exceptions.PricingNotConfiguredError'>
FAILED tests/integration/test_embedding_regression.py::TestEmbeddingRegression::test_strict_mode_behavior_unchanged - Failed: DID NOT RAISE <class 'flujo.exceptions.PricingNotConfiguredError'>
FAILED tests/integration/test_agentic_loop_recipe.py::test_pause_and_resume_in_loop - AssertionError: assert 'failed' == 'paused'

  - paused
  + failed
FAILED tests/integration/test_executor_core_architecture_validation.py::TestComponentIntegration::test_component_interface_optimization - AssertionError: Serializer should be called
assert 0 > 0
 +  where 0 = <tests.integration.test_executor_core_architecture_validation.MockSerializer object at 0x13008c890>.serialize_calls
FAILED tests/integration/test_parallel_step.py::test_parallel_overwrite_multi_branch_order - KeyError: 'v'
FAILED tests/integration/test_agentic_loop_recipe.py::test_sync_resume - flujo.exceptions.OrchestratorError: Pipeline is not paused
FAILED tests/integration/test_as_step_composition.py::test_as_step_context_inheritance_error - Failed: DID NOT RAISE <class 'flujo.exceptions.ContextInheritanceError'>
FAILED tests/integration/test_as_step_composition.py::test_direct_context_inheritance_error - Failed: DID NOT RAISE <class 'flujo.exceptions.ContextInheritanceError'>
FAILED tests/integration/test_parallel_step_enhancements.py::test_context_include_keys_optimization - AttributeError: 'LargeContext' object has no attribute 'initial_prompt'
FAILED tests/integration/test_as_step_state_persistence.py::test_as_step_state_persistence_and_resumption - assert 0 == 1
FAILED tests/integration/test_executor_core_optimization_integration.py::TestErrorHandlingIntegration::test_error_recovery_integration - pydantic_core._pydantic_core.ValidationError: 1 validation error for StepResult
name
  Input should be a valid string [type=string_type, input_value=<Mock name='mock.step.name' id='4426035920'>, input_type=Mock]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
FAILED tests/integration/test_cache_with_context_updates.py::test_cache_with_context_updates_error_handling - AssertionError: assert 3 == 1
 +  where 3 = CacheContext(run_id='run_71c4856c11d5464487c34cfe22facca5', initial_prompt='test', scratchpad={'status': 'failed'}, hi... cached_results={}, processing_history=[], current_operation='', operation_count=3, cache_timestamps={}, cache_keys=[]).operation_count
 +    where CacheContext(run_id='run_71c4856c11d5464487c34cfe22facca5', initial_prompt='test', scratchpad={'status': 'failed'}, hi... cached_results={}, processing_history=[], current_operation='', operation_count=3, cache_timestamps={}, cache_keys=[]) = PipelineResult(step_history=[StepResult(name='failing_cache_step', output=None, success=False, attempts=3, latency_s=0...failed with RuntimeError: Intentional failure for cache testing'}, children=[], status='failed')], status='completed')).final_pipeline_context
FAILED tests/integration/test_executor_core_optimization_integration.py::TestErrorHandlingIntegration::test_circuit_breaker_integration - pydantic_core._pydantic_core.ValidationError: 1 validation error for StepResult
name
  Input should be a valid string [type=string_type, input_value=<Mock name='mock.step.name' id='5101950288'>, input_type=Mock]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
FAILED tests/integration/test_parallel_step_enhancements.py::test_context_include_keys_isolation - AttributeError: 'LargeContext' object has no attribute 'initial_prompt'
FAILED tests/integration/test_caching_and_fallbacks.py::test_caching_pipeline_speed_and_hits - AssertionError: assert ({'cache_hit': True} is None or 'cache_hit' not in {'cache_hit': True})
FAILED tests/integration/test_caching_and_fallbacks.py::test_loop_step_fallback_continues - AssertionError: assert False is True
 +  where False = StepResult(name='loop', output=PluginOutcome(success=True, feedback=None, redirect_to=None, new_solution=None), success...led'}, hitl_history=[], command_log=[]), metadata_={'iterations': 2, 'exit_reason': 'max_iterations'}, step_history=[]).success
FAILED tests/integration/test_validation_persistence.py::test_persist_feedback_and_results - assert ([])
 +  where [] = Ctx(feedback_history=[], validation_history=[]).feedback_history
FAILED tests/integration/test_validation_persistence.py::test_persist_results_on_success - assert 0 == 1
 +  where 0 = len([])
 +    where [] = Ctx(feedback_history=[], validation_history=[]).validation_history
FAILED tests/integration/test_cost_tracking_integration.py::TestStrictPricingModeIntegration::test_strict_mode_on_failure_case - Failed: DID NOT RAISE <class 'flujo.exceptions.PricingNotConfiguredError'>
FAILED tests/integration/test_cost_tracking_integration.py::TestStrictPricingModeIntegration::test_strict_mode_on_with_unknown_provider - Failed: DID NOT RAISE <class 'flujo.exceptions.PricingNotConfiguredError'>
FAILED tests/regression/test_executor_core_optimization_regression.py::TestOptimizationIntegration::test_configuration_management - AttributeError: 'dict' object has no attribute 'current_config'
FAILED tests/regression/test_executor_core_optimization_regression.py::TestOptimizationIntegration::test_performance_recommendations - AssertionError: assert 'type' in 'Consider increasing cache size for better performance'
FAILED tests/regression/test_conditional_step_regression.py::TestConditionalStepRegression::test_metrics_accumulation_regression - AssertionError: assert 0.00011962500866502523 == 1.0
 +  where 0.00011962500866502523 = StepResult(name='test_conditional', output='test_output', success=True, attempts=1, latency_s=0.00011962500866502523, ...data', scratchpad={}, hitl_history=[], command_log=[]), metadata_={'executed_branch_key': 'branch_a'}, step_history=[]).latency_s
FAILED tests/regression/test_conditional_step_regression.py::TestConditionalStepRegression::test_context_handling_regression - assert False is True
FAILED tests/regression/test_legacy_cleanup_impact.py::TestLegacyFunctionUsageAnalysis::test_import_dependency_analysis - Failed: DID NOT RAISE <class 'ModuleNotFoundError'>
FAILED tests/regression/test_executor_core_optimization_regression.py::TestOptimizationBackwardCompatibility::test_configuration_serialization - AttributeError: type object 'OptimizationConfig' has no attribute 'from_dict'
FAILED tests/regression/test_legacy_cleanup_impact.py::TestLegacyFunctionUsageAnalysis::test_backward_compatibility_verification - TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
FAILED tests/regression/test_executor_core_optimization_regression.py::TestOptimizationErrorHandling::test_invalid_step_handling - pydantic_core._pydantic_core.ValidationError: 1 validation error for StepResult
name
  Input should be a valid string [type=string_type, input_value=<Mock name='mock.step.name' id='5102819216'>, input_type=Mock]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
FAILED tests/regression/test_legacy_cleanup_impact.py::TestMigrationCompleteness::test_legacy_function_deprecation - TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
FAILED tests/regression/test_legacy_cleanup_impact.py::TestDeprecationDecorator::test_deprecation_warning_message - TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
FAILED tests/unit/test_adapter_step.py::test_adapter_pipeline_runs - flujo.exceptions.TypeMismatchError: Type mismatch: Output of 'adapt' (returns `<class 'str'>`) is not compatible with 'follow' (expects `<class 'tests.unit.test_adapter_step.ComplexInput'>`). For best results, use a static type checker like mypy to catch these issues before runtime.
FAILED tests/unit/test_agentic_loop_logging.py::TestAgenticLoopLogging::test_pause_and_resume_logging - flujo.exceptions.OrchestratorError: Pipeline is not paused
FAILED tests/unit/test_ci_compatibility.py::TestCIErrorRecovery::test_partial_failure_handling - AssertionError: assert False
 +  where False = isinstance('<unserializable: dict>', dict)
FAILED tests/integration/test_parallel_step_enhancements.py::test_proactive_cancellation_with_multiple_branches - assert 0.5482313749962486 < 0.3
FAILED tests/unit/test_default_backend.py::test_runner_uses_sqlite_by_default - assert False
 +  where False = isinstance(<tests.conftest.NoOpStateBackend object at 0x113e18350>, SQLiteBackend)
 +    where <tests.conftest.NoOpStateBackend object at 0x113e18350> = <flujo.application.runner.Flujo object at 0x113e1a890>.state_backend
FAILED tests/unit/test_dummy_remote_backend.py::test_dummy_remote_backend_dict_of_primitives - pydantic_core._pydantic_core.ValidationError: 1 validation error for Nested
  Input should be a valid dictionary or instance of Nested [type=model_type, input_value=None, input_type=NoneType]
    For further information visit https://errors.pydantic.dev/2.11/v/model_type
FAILED tests/unit/test_executor_components.py::TestDefaultValidatorRunner::test_validation_failure - Failed: DID NOT RAISE <class 'ValueError'>
FAILED tests/unit/test_executor_components.py::TestDefaultPluginRunner::test_plugin_execution - AssertionError: assert PluginOutcome(success=True, feedback=None, redirect_to=None, new_solution='processed data') == 'processed data'
FAILED tests/unit/test_executor_components.py::TestDefaultPluginRunner::test_plugin_with_priority_ordering - AssertionError: assert PluginOutcome(success=True, feedback=None, redirect_to=None, new_solution='processed by plugin2') == 'processed by plugin1'
FAILED tests/unit/test_executor_core_parallel_migration.py::TestExecutorCoreParallelMigration::test_executor_core_dynamic_router_delegates_to_parallel - TypeError: ExecutorCore._handle_dynamic_router_step() got an unexpected keyword argument 'router_step'
FAILED tests/integration/test_parallel_step_enhancements.py::test_proactive_cancellation_token_limits - AssertionError: Execution took too long: 0.560s (threshold: 0.400s). This indicates proactive cancellation may not be working correctly.
assert 0.5600467500044033 < 0.4
FAILED tests/unit/test_fallback_edge_cases.py::test_fallback_with_high_cost_agents - AssertionError: assert 1999.98 == 999.99
 +  where 1999.98 = StepResult(name='fb', output='fallback', success=True, attempts=2, latency_s=0.0001717920093616545, token_counts=19999... metadata_={'fallback_triggered': True, 'original_error': 'Plugin validation failed: primary failed'}, step_history=[]).cost_usd
FAILED tests/unit/test_fallback_edge_cases.py::test_fallback_with_negative_metrics - AssertionError: assert -0.2 == -0.1
 +  where -0.2 = StepResult(name='fb', output='negative', success=True, attempts=2, latency_s=0.00022316598667204381, token_counts=-10,... metadata_={'fallback_triggered': True, 'original_error': 'Plugin validation failed: primary failed'}, step_history=[]).cost_usd
FAILED tests/unit/test_fallback_edge_cases.py::test_fallback_with_complex_metadata - AssertionError: assert 'Plugin valid...omplex failed' == 'complex failed'

  - complex failed
  + Plugin validation failed: complex failed
FAILED tests/integration/test_parallel_step_enhancements.py::test_context_include_keys_with_nonexistent_fields - AttributeError: 'LargeContext' object has no attribute 'initial_prompt'
FAILED tests/unit/test_persistence_performance.py::TestPersistencePerformanceOverhead::test_default_backend_performance_overhead - AssertionError: Default persistence overhead (890.56%) exceeds 35.0% limit
assert 890.5554954248926 <= 35.0
FAILED tests/unit/test_persistence_performance.py::TestPersistencePerformanceOverhead::test_persistence_overhead_with_large_context - AssertionError: Persistence overhead with large context (884.36%) exceeds 35.0%
assert 884.3614790926946 <= 35.0
FAILED tests/unit/test_pipeline_context.py::test_plugin_receives_context_and_strict_plugin_errors - assert None == {}
 +  where None = <tests.unit.test_pipeline_context.KwargsPlugin object at 0x1141b5f50>.kwargs
FAILED tests/integration/test_persistence_backends.py::test_file_backend_resume_after_crash - AssertionError: assert 2 == 3
 +  where 2 = WorkflowState(run_id='run_file', pipeline_id='unknown', pipeline_name='unknown', pipeline_version='latest', current_st...ted_at=datetime.datetime(2025, 8, 5, 14, 57, 10, 889170), updated_at=datetime.datetime(2025, 8, 5, 14, 57, 10, 897858)).current_step_index
FAILED tests/unit/test_schema_migration_robustness.py::TestSchemaMigrationRobustness::test_migration_handles_schema_version_changes - sqlite3.OperationalError: table runs has no column named execution_time_ms
FAILED tests/integration/test_persistence_backends.py::test_sqlite_backend_resume_after_crash - AssertionError: assert 2 == 3
 +  where 2 = WorkflowState(run_id='run_sqlite', pipeline_id='unknown', pipeline_name='unknown', pipeline_version='latest', current_...ted_at=datetime.datetime(2025, 8, 5, 14, 57, 11, 535383), updated_at=datetime.datetime(2025, 8, 5, 14, 57, 11, 554389)).current_step_index
FAILED tests/integration/test_pipeline_runner.py::test_runner_respects_max_retries - assert 1 == 3
 +  where 1 = <flujo.testing.utils.StubAgent object at 0x11341c510>.call_count
FAILED tests/integration/test_pipeline_runner.py::test_feedback_enriches_prompt - assert 1 == 2
 +  where 1 = <flujo.testing.utils.StubAgent object at 0x1130b0050>.call_count
FAILED tests/integration/test_pipeline_runner.py::test_timeout_and_redirect_loop_detection - Failed: DID NOT RAISE <class 'flujo.exceptions.InfiniteRedirectError'>
FAILED tests/integration/test_pipeline_runner_with_resources.py::test_resources_passed_to_plugin - assert False
 +  where False = StepResult(name='plugin_step', output='queried_products', success=False, attempts=1, latency_s=-334744522224296.5, tok....validate() missing 1 required keyword-only argument: 'resources'", branch_context=None, metadata_={}, step_history=[]).success
FAILED tests/integration/test_processors.py::test_prompt_processor_modifies_input - AssertionError: assert 'hello' == 'hello world'

  - hello world
  + hello
FAILED tests/integration/test_processors.py::test_processor_receives_context - AssertionError: assert False
 +  where False = <built-in method startswith of str object at 0x1120a0770>('X:')
 +    where <built-in method startswith of str object at 0x1120a0770> = 'hello'.startswith
FAILED tests/integration/test_redirect_loop_unhashable.py::test_redirect_loop_detected_with_unhashable_agents - Failed: DID NOT RAISE <class 'flujo.exceptions.InfiniteRedirectError'>
FAILED tests/integration/test_refine_until_with_context_updates.py::test_refine_until_with_context_updates_error_handling - AssertionError: assert 'loop exited by condition, but last iteration body failed' in 'loop terminated after reaching max_loops (5)'
 +  where 'loop terminated after reaching max_loops (5)' = <built-in method lower of str object at 0x1136f6550>()
 +    where <built-in method lower of str object at 0x1136f6550> = 'Loop terminated after reaching max_loops (5)'.lower
 +      where 'Loop terminated after reaching max_loops (5)' = StepResult(name='error_refine', output='refined_content_6', success=False, attempts=5, latency_s=0.006436416995711625,....16999999999999998, refinement_data={}), metadata_={'iterations': 5, 'exit_reason': 'max_iterations'}, step_history=[]).feedback
FAILED tests/integration/test_refine_until_with_context_updates.py::test_refine_until_with_context_updates_metadata_conflicts - AssertionError: assert 'reached max_loops' in 'loop terminated after reaching max_loops (3)'
 +  where 'loop terminated after reaching max_loops (3)' = <built-in method lower of str object at 0x1136b9bf0>()
 +    where <built-in method lower of str object at 0x1136b9bf0> = 'Loop terminated after reaching max_loops (3)'.lower
 +      where 'Loop terminated after reaching max_loops (3)' = StepResult(name='metadata_refine', output='metadata_content_3', success=False, attempts=3, latency_s=0.003604208002798...amp': 'now', 'data': 'refinement_3'}}}), metadata_={'iterations': 3, 'exit_reason': 'max_iterations'}, step_history=[]).feedback
FAILED tests/integration/test_sqlite_backend_edge_cases.py::TestSQLiteBackendEdgeCases::test_backup_stat_error_handling - sqlite3.DatabaseError: file is not a database
FAILED tests/integration/test_sqlite_backend_edge_cases.py::TestSQLiteBackendEdgeCases::test_backup_cleanup_attempts_limit - sqlite3.DatabaseError: Database corruption recovery failed
FAILED tests/integration/test_sqlite_backend_edge_cases.py::TestSQLiteBackendEdgeCases::test_backup_stat_exception_handling - sqlite3.DatabaseError: file is not a database
FAILED tests/integration/test_sqlite_backend_edge_cases.py::TestSQLiteBackendEdgeCases::test_backup_fallback_timestamp_naming - sqlite3.DatabaseError: Database corruption recovery failed
FAILED tests/integration/test_sqlite_backend_edge_cases.py::TestSQLiteBackendEdgeCases::test_backup_all_slots_undeletable_fallback - sqlite3.DatabaseError: Database corruption recovery failed
FAILED tests/integration/test_sqlite_backend_edge_cases.py::TestSQLiteBackendEdgeCases::test_backup_stat_always_raises - OSError: stat failed
FAILED tests/integration/test_sqlite_backend_edge_cases.py::TestSQLiteBackendEdgeCases::test_backup_permission_and_race_conditions - OSError: stat failed
FAILED tests/integration/test_stateful_hitl.py::test_stateful_hitl_resume - KeyError: 'pre'
FAILED tests/integration/test_streaming_pipeline.py::test_non_streaming_pipeline - AssertionError: assert 2 == 1
 +  where 2 = len(['ok', PipelineResult(step_history=[StepResult(name='solution', output='ok', success=True, attempts=1, latency_s=0.000...'latency_s': 0.000252834, 'cost_usd': 0.0, 'token_counts': 1}, children=[], status='completed')], status='completed'))])
FAILED tests/integration/test_streaming_pipeline.py::test_pipeline_handles_streaming_agent_failure_gracefully - AssertionError: assert ['H', 'e', 'l...'e', 'l', ...] == ['H', 'e', 'l']

  Left contains 6 more items, first extra item: 'H'

  Full diff:
    [
        'H',
        'e',
        'l',
  +     'H',
  +     'e',
  +     'l',
  +     'H',
  +     'e',
  +     'l',
    ]
FAILED tests/integration/test_strict_validation.py::test_non_strict_validation_pass_through - AssertionError: assert False is True
 +  where False = StepResult(name='validate', output=None, success=False, attempts=3, latency_s=0.0005550410132855177, token_counts=1, c...Agent execution failed with IndexError: No more outputs available', branch_context=None, metadata_={}, step_history=[]).success
FAILED tests/integration/test_strict_validation.py::test_regular_step_keeps_output_on_validation_failure - AssertionError: assert None == 'value'
 +  where None = StepResult(name='regular', output=None, success=False, attempts=3, latency_s=0.000375000003259629, token_counts=1, cos...Agent execution failed with IndexError: No more outputs available', branch_context=None, metadata_={}, step_history=[]).output
FAILED tests/integration/test_unified_error_handling.py::test_error_information_preservation - AssertionError: assert 3 == 2
 +  where 3 = StepResult(name='failing', output=None, success=False, attempts=3, latency_s=0.00030170800164341927, token_counts=0, c... feedback='Agent execution failed with RuntimeError: Test failure', branch_context=None, metadata_={}, step_history=[]).attempts
FAILED tests/unit/test_ultra_executor_cumulative_limits.py::TestUltraExecutorCumulativeLimits::test_usage_tracker_cumulative_tracking - AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
FAILED tests/unit/test_ultra_executor_cumulative_limits.py::TestUltraExecutorCumulativeLimits::test_usage_tracker_limit_checking - AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
FAILED tests/unit/test_ultra_executor_cumulative_limits.py::TestUltraExecutorCumulativeLimits::test_usage_tracker_thread_safety - AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
FAILED tests/unit/test_ultra_executor_cumulative_limits.py::TestUltraExecutorCumulativeLimits::test_legacy_guard_method_compatibility - AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
FAILED tests/unit/test_ultra_executor_cumulative_limits.py::TestUltraExecutorCumulativeLimits::test_usage_tracker_multiple_limit_checks - AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
FAILED tests/unit/test_ultra_executor_cumulative_limits.py::TestUltraExecutorCumulativeLimits::test_usage_tracker_zero_limits - AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
FAILED tests/unit/test_ultra_executor_cumulative_limits.py::TestUltraExecutorCumulativeLimits::test_usage_tracker_precision_handling - AttributeError: '_UsageTracker' object has no attribute 'get_current_totals'
FAILED tests/unit/test_ultra_executor_v2.py::TestCacheKeyGeneration::test_agent_id_stability - AssertionError: assert '2770702b9b25...7f7e243a064d1' == 'a512b2dc57c1...07a66a56c57d9'

  - a512b2dc57c11187373b2ff49ab710aad1d94fee4a8602f9e9507a66a56c57d9
  + 2770702b9b25191adf2b2fe8356cde7536c87244bd87747b0c37f7e243a064d1
FAILED tests/unit/test_ultra_executor_v2.py::TestBackwardCompatibility::test_execute_step_signature - TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
FAILED tests/unit/test_ultra_executor_v2.py::TestErrorHandling::test_usage_limit_exception_propagation - Failed: DID NOT RAISE <class 'flujo.exceptions.UsageLimitExceededError'>
FAILED tests/e2e/test_golden_transcript_agentic_loop.py::test_golden_transcript_agentic_loop - AssertionError: assert 'failed' == 'paused'

  - paused
  + failed
FAILED tests/e2e/test_golden_transcript_dynamic_parallel.py::test_golden_transcript_dynamic_parallel - AssertionError: assert 0 == 1
 +  where 0 = len([])
 +    where [] = DynamicParallelContext(run_id='run_37f4f2764e8d4181952b895fa0097d6d', initial_prompt='test', scratchpad={'status': 'completed'}, hitl_history=[], command_log=[], executed_branches=[], branch_results={}, total_failures=0).executed_branches
FAILED tests/e2e/test_golden_transcript_dynamic_parallel.py::test_golden_transcript_dynamic_parallel_selective - AssertionError: assert 0 == 1
 +  where 0 = len([])
 +    where [] = DynamicParallelContext(run_id='run_bb9565495e1947b093288d1e0bc2e54a', initial_prompt='test', scratchpad={'status': 'completed'}, hitl_history=[], command_log=[], executed_branches=[], branch_results={}, total_failures=0).executed_branches
FAILED tests/e2e/test_golden_transcript_refine.py::test_golden_transcript_refine_max_iterations - AssertionError: assert False
 +  where False = isinstance({'value': 2}, <class 'flujo.domain.models.RefinementCheck'>)
FAILED tests/integration/test_hitl_step_migration_integration.py::TestHITLStepMigrationIntegration::test_hitl_step_with_different_contexts - KeyError: 'existing_key'
FAILED tests/integration/test_hybrid_validation.py::test_programmatic_check_failure - AssertionError: assert 'FailValidator' in 'Agent execution failed with IndexError: No more outputs available'
 +  where 'Agent execution failed with IndexError: No more outputs available' = StepResult(name='validate', output=None, success=False, attempts=3, latency_s=0.0003392089856788516, token_counts=1, c...Agent execution failed with IndexError: No more outputs available', branch_context=None, metadata_={}, step_history=[]).feedback
FAILED tests/integration/test_hybrid_validation.py::test_aggregated_feedback - AssertionError: assert 'plugin fail' in 'Agent execution failed with IndexError: No more outputs available'
FAILED tests/integration/test_legacy_cleanup_validation.py::TestRemainingFunctionPreservation::test_cache_step_logic_preservation - TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
FAILED tests/integration/test_legacy_cleanup_validation.py::TestRemainingFunctionPreservation::test_run_step_logic_preservation - TypeError: unsupported operand type(s) for +: 'Mock' and 'int'
FAILED tests/integration/test_legacy_cleanup_validation.py::TestLegacyCleanupSafety::test_error_handling_preserved - assert False
 +  where False = any(<generator object TestLegacyCleanupSafety.test_error_handling_preserved.<locals>.<genexpr> at 0x1121dda80>)
FAILED tests/integration/test_loop_step_execution.py::test_loop_step_iteration_spans_and_logging - assert "LoopStep 'loop_log' exit condition met at iteration 2." in ["LoopStep 'loop_log': Starting Iteration 1/2", "LoopStep 'loop_log': Starting Iteration 2/2"]
FAILED tests/integration/test_loop_step_execution.py::test_loop_step_error_logging_in_callables - assert False
 +  where False = any(<generator object test_loop_step_error_logging_in_callables.<locals>.<genexpr> at 0x113c76810>)
FAILED tests/integration/test_loop_with_context_updates.py::test_loop_with_context_updates_error_handling - AssertionError: assert False is True
 +  where False = StepResult(name='error_loop', output=None, success=False, attempts=2, latency_s=0.0011529590119607747, token_counts=0,...reason='', final_state={}), metadata_={'iterations': 2, 'exit_reason': 'condition_with_body_failure'}, step_history=[]).success
FAILED tests/integration/test_map_over_step.py::test_map_over_sequential - assert [2] == [2, 4, 6]

  Right contains 2 more items, first extra item: 4

  Full diff:
    [
        2,
  -     4,
  -     6,
    ]
FAILED tests/integration/test_map_over_step.py::test_map_over_parallel - assert [0] == [0, 1, 2, 3]

  Right contains 3 more items, first extra item: 1

  Full diff:
    [
        0,
  -     1,
  -     2,
  -     3,
    ]
FAILED tests/integration/test_map_over_step.py::test_map_over_reusable_after_empty - assert [6] == [6, 8]

  Right contains one more item: 8

  Full diff:
    [
        6,
  -     8,
    ]
FAILED tests/integration/test_map_over_step.py::test_map_over_concurrent_runs - assert [2] == [2, 4]

  Right contains one more item: 4

  Full diff:
    [
        2,
  -     4,
    ]
FAILED tests/integration/test_map_over_with_context_updates.py::test_map_over_with_context_updates_basic - AssertionError: assert False is True
 +  where False = StepResult(name='basic_map', output=['processed_item1'], success=False, attempts=1, latency_s=0.000671458023134619, to...processing_history=['processed_item1']), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
FAILED tests/integration/test_map_over_with_context_updates.py::test_map_over_with_context_updates_error_handling - AssertionError: assert False is True
 +  where False = StepResult(name='error_map', output=['processed_item1'], success=False, attempts=1, latency_s=0.0006040000007487833, t...processing_history=['attempted_item1']), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
FAILED tests/integration/test_map_over_with_context_updates.py::test_map_over_with_context_updates_context_dependent - AssertionError: assert False is True
 +  where False = StepResult(name='context_dependent_map', output=['early_processed_item1'], success=False, attempts=1, latency_s=0.0006...ng_history=['context_dependent_item1']), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
FAILED tests/integration/test_map_over_with_context_updates.py::test_map_over_with_context_updates_nested_context - assert False is True
 +  where False = StepResult(name='nested_context_map', output=["{'original_item': 'item1', 'processed_count': 1, 'history_length': 0}"]...', processing_history=['nested_item1']), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
FAILED tests/integration/test_map_over_with_context_updates.py::test_map_over_with_context_updates_state_isolation - assert False is True
 +  where False = StepResult(name='isolation_map', output=["{'item': 'item1', 'total_processed_at_start': 0, 'processed_count_at_start':...nt_item='item1', processing_history=[]), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
FAILED tests/integration/test_map_over_with_context_updates.py::test_map_over_with_context_updates_complex_aggregation - assert False is True
 +  where False = StepResult(name='aggregation_map', output=["{'item': 'item1', 'running_avg_length': 5.0, 'total_chars_processed': 5, '...nt_item='item1', processing_history=[]), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
FAILED tests/integration/test_map_over_with_context_updates.py::test_map_over_with_context_updates_metadata_conflicts - AssertionError: assert False is True
 +  where False = StepResult(name='metadata_map', output=['metadata_processed_item1'], success=False, attempts=1, latency_s=0.0006171250...nt_item='item1', processing_history=[]), metadata_={'iterations': 1, 'exit_reason': 'max_iterations'}, step_history=[]).success
ERROR tests/utils/test_serialization.py
147 failed, 2149 passed, 7 skipped, 1 error in 28.17s
âŒ Some tests failed. Run 'make test-fast-verbose' for detailed output.
make: *** [test-fast] Error 1
