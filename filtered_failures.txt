tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_context_preservation 
[gw0] [  3%] FAILED tests/application/core/test_executor_core.py::TestExecutorCoreSimpleStep::test_validator_failure_triggers_retry 
tests/application/core/test_executor_core.py::TestExecutorCoreSimpleStep::test_usage_limit_exceeded_error_propagates 
[gw1] [  3%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_context_preservation 
tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_mapper_errors 
[gw1] [  3%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_mapper_errors 
tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_exit_condition_errors 
[gw0] [  3%] PASSED tests/application/core/test_executor_core.py::TestExecutorCoreSimpleStep::test_usage_limit_exceeded_error_propagates 
[gw1] [  3%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_exit_condition_errors 
tests/application/core/test_executor_core.py::TestExecutorCoreSimpleStep::test_missing_agent_error 
tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_body_step_failures 
[gw1] [  3%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_body_step_failures 
tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_cost_limits 
[gw1] [  3%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_cost_limits 
tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_token_limits 
[gw0] [  3%] PASSED tests/application/core/test_executor_core.py::TestExecutorCoreSimpleStep::test_missing_agent_error 
tests/application/core/test_executor_core.py::TestExecutorCoreSimpleStep::test_mock_object_detection 
[gw1] [  3%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_token_limits 
tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_limits_accumulation 
[gw1] [  3%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_handle_loop_step_limits_accumulation 
tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_loopstep_complex_pipeline_integration 
[gw0] [  3%] PASSED tests/application/core/test_executor_core.py::TestExecutorCoreSimpleStep::test_mock_object_detection 
[gw1] [  3%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_loopstep_complex_pipeline_integration 
tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_loopstep_nested_control_flow 
tests/application/core/test_executor_core.py::TestExecutorCoreSimpleStep::test_plugin_validation_failure_with_feedback 
[gw1] [  3%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_loopstep_nested_control_flow 
tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_loopstep_with_caching 
[gw1] [  3%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_loopstep_with_caching 
tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_loopstep_with_telemetry 
[gw1] [  3%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_loopstep_with_telemetry 
tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_loopstep_existing_behavior_preservation 
[gw1] [  4%] PASSED tests/application/core/test_executor_core_loop_step_migration.py::TestLoopStepMigration::test_loopstep_existing_behavior_preservation 
--
tests/integration/test_local_tracer.py::test_default_local_tracer_added 
[gw1] [ 93%] PASSED tests/integration/test_local_tracer.py::test_default_local_tracer_added 
tests/integration/test_local_tracer.py::test_custom_console_tracer_instance 
[gw1] [ 93%] PASSED tests/integration/test_local_tracer.py::test_custom_console_tracer_instance 
tests/integration/test_local_tracer.py::test_tracer_outputs_info_level 
[gw1] [ 93%] PASSED tests/integration/test_local_tracer.py::test_tracer_outputs_info_level 
tests/integration/test_local_tracer.py::test_tracer_outputs_debug_level 
[gw1] [ 93%] PASSED tests/integration/test_local_tracer.py::test_tracer_outputs_debug_level 
tests/integration/test_loop_context_update_regression.py::test_regression_first_principles_guarantee 
[gw1] [ 93%] PASSED tests/integration/test_loop_context_update_regression.py::test_regression_first_principles_guarantee 
tests/integration/test_loop_context_update_regression.py::test_regression_assertion_catches_merge_failures 
[gw1] [ 93%] PASSED tests/integration/test_loop_context_update_regression.py::test_regression_assertion_catches_merge_failures 
tests/integration/test_loop_context_update_regression.py::test_regression_parallel_step_context_updates 
[gw1] [ 93%] PASSED tests/integration/test_loop_context_update_regression.py::test_regression_parallel_step_context_updates 
tests/integration/test_loop_context_update_regression.py::test_regression_conditional_step_context_updates 
[gw1] [ 93%] PASSED tests/integration/test_loop_context_update_regression.py::test_regression_conditional_step_context_updates 
tests/integration/test_loop_context_update_regression.py::test_regression_edge_case_deep_copy_isolation 
[gw1] [ 93%] PASSED tests/integration/test_loop_context_update_regression.py::test_regression_edge_case_deep_copy_isolation 
tests/integration/test_loop_context_update_regression.py::test_regression_serialization_edge_cases 
[gw1] [ 93%] PASSED tests/integration/test_loop_context_update_regression.py::test_regression_serialization_edge_cases 
tests/integration/test_loop_context_update_regression.py::test_regression_performance_under_load 
[gw1] [ 93%] FAILED tests/integration/test_loop_context_update_regression.py::test_regression_performance_under_load 
tests/integration/test_loop_context_updates_fix.py::test_loop_context_updates_basic 
[gw1] [ 93%] PASSED tests/integration/test_loop_context_updates_fix.py::test_loop_context_updates_basic 
tests/integration/test_loop_context_updates_fix.py::test_loop_context_updates_multiple_iterations 
[gw1] [ 93%] PASSED tests/integration/test_loop_context_updates_fix.py::test_loop_context_updates_multiple_iterations 
tests/integration/test_loop_context_updates_fix.py::test_loop_context_updates_max_loops 
[gw1] [ 94%] PASSED tests/integration/test_loop_context_updates_fix.py::test_loop_context_updates_max_loops 
tests/integration/test_loop_context_updates_fix.py::test_loop_context_updates_complex_state 
[gw1] [ 94%] PASSED tests/integration/test_loop_context_updates_fix.py::test_loop_context_updates_complex_state 
tests/integration/test_loop_context_updates_fix.py::test_loop_context_updates_error_handling 
[gw1] [ 94%] PASSED tests/integration/test_loop_context_updates_fix.py::test_loop_context_updates_error_handling 
--
[gw3] [ 99%] PASSED tests/unit/test_cost_tracking.py::TestStrictPricingMode::test_strict_mode_off_with_default_pricing 
tests/unit/test_cost_tracking.py::TestStrictPricingMode::test_strict_mode_on_with_user_config 
[gw3] [ 99%] PASSED tests/unit/test_cost_tracking.py::TestStrictPricingMode::test_strict_mode_on_with_user_config 
tests/unit/test_cost_tracking.py::TestStrictPricingMode::test_strict_mode_on_without_user_config_raises_error 
[gw3] [ 99%] PASSED tests/unit/test_cost_tracking.py::TestStrictPricingMode::test_strict_mode_on_without_user_config_raises_error 
tests/unit/test_cost_tracking.py::TestStrictPricingMode::test_strict_mode_on_with_unknown_model_raises_error 
[gw3] [ 99%] PASSED tests/unit/test_cost_tracking.py::TestStrictPricingMode::test_strict_mode_on_with_unknown_model_raises_error 
tests/unit/test_cost_tracking.py::TestStrictPricingMode::test_strict_mode_on_with_unknown_provider_raises_error 
[gw3] [100%] PASSED tests/unit/test_cost_tracking.py::TestStrictPricingMode::test_strict_mode_on_with_unknown_provider_raises_error 

=================================== FAILURES ===================================
_________________ test_golden_transcript_refine_max_iterations _________________
[gw2] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/e2e/test_golden_transcript_refine.py:142: in test_golden_transcript_refine_max_iterations
    assert isinstance(final_output, RefinementCheck)
E   AssertionError: assert False
E    +  where False = isinstance({'value': 2}, <class 'flujo.domain.models.RefinementCheck'>)
----------------------------- Captured stdout call -----------------------------
2025-08-06 07:34:45,930 - flujo - INFO - Starting LoopStep 'test_refinement_max' with max_loops=2, limits=None
2025-08-06 07:34:45,930 - flujo - INFO - LoopStep 'test_refinement_max': Starting Iteration 1/2
2025-08-06 07:34:45,931 - flujo - INFO - LoopStep 'test_refinement_max': Starting Iteration 2/2
2025-08-06 07:34:45,933 - flujo - WARNING - Step 'test_refinement_max' failed. Halting pipeline execution.
------------------------------ Captured log call -------------------------------
INFO     flujo:telemetry.py:54 Starting LoopStep 'test_refinement_max' with max_loops=2, limits=None
INFO     flujo:telemetry.py:54 LoopStep 'test_refinement_max': Starting Iteration 1/2
INFO     flujo:telemetry.py:54 LoopStep 'test_refinement_max': Starting Iteration 2/2
WARNING  flujo:telemetry.py:54 Step 'test_refinement_max' failed. Halting pipeline execution.
_______ TestExecutorCoreSimpleStep.test_validator_failure_triggers_retry _______
[gw0] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/application/core/test_executor_core.py:289: in test_validator_failure_triggers_retry
    assert result.attempts == 3  # max_retries (1 initial + 2 retries)
--
INFO     flujo:telemetry.py:54 LoopStep 'AgenticExplorationLoop': Starting Iteration 1/5
INFO     flujo:telemetry.py:54 LoopStep 'AgenticExplorationLoop': Starting Iteration 2/5
ERROR    flujo:telemetry.py:54 Step 'command_executor_step' encountered a non-retryable exception: PausedException
WARNING  flujo:telemetry.py:54 Step 'AgenticExplorationLoop' failed. Halting pipeline execution.
___________________ test_golden_transcript_dynamic_parallel ____________________
[gw1] darwin -- Python 3.11.0 /Users/alvaro/Documents/Code/flujo/.venv/bin/python3
tests/e2e/test_golden_transcript_dynamic_parallel.py:128: in test_golden_transcript_dynamic_parallel
    assert len(final_context.executed_branches) == 1
E   AssertionError: assert 0 == 1
E    +  where 0 = len([])
E    +    where [] = DynamicParallelContext(run_id='run_71544287e21444619b5007f72e0f376b', initial_prompt='test', scratchpad={'status': 'running'}, hitl_history=[], command_log=[], executed_branches=[], branch_results={}, total_failures=0).executed_branches
----------------------------- Captured stdout call -----------------------------
[DEBUG] Branch branch1 called with data: test_input
[DEBUG] Branch branch1 context is None: False
[DEBUG] Branch branch1 context.executed_branches before: []
[DEBUG] Branch branch1 context.executed_branches after: ['branch1']
[DEBUG] Branch branch1 context.branch_results: {'branch1': 'branch1_processed_test_input'}
2025-08-06 07:35:11,820 - flujo - INFO - Counting string output as 1 token for step 'branch1': 'branch1_processed_test_input'
[DEBUG] Branch branch2 called with data: test_input
[DEBUG] Branch branch2 context is None: False
[DEBUG] Branch branch2 context.executed_branches before: []
[DEBUG] Branch branch2 context.executed_branches after: ['branch2']
[DEBUG] Branch branch2 context.branch_results: {'branch2': 'branch2_processed_test_input'}
2025-08-06 07:35:11,820 - flujo - INFO - Counting string output as 1 token for step 'branch2': 'branch2_processed_test_input'
[DEBUG] Branch branch3 called with data: test_input
[DEBUG] Branch branch3 context is None: False
[DEBUG] Branch branch3 will fail intentionally
2025-08-06 07:35:11,820 - flujo - WARNING - Step 'branch3' agent execution attempt 1 failed: Intentional failure in branch3
[DEBUG] Branch branch3 called with data: test_input
[DEBUG] Branch branch3 context is None: False
[DEBUG] Branch branch3 will fail intentionally
--
  - failed
  + completed
FAILED tests/integration/test_strict_validation.py::test_non_strict_validation_pass_through - AssertionError: assert False is True
 +  where False = StepResult(name='validate', output='ok', success=False, attempts=1, latency_s=0.0001829999964684248, token_counts=1, cost_usd=0.0, feedback='FailValidator: bad', branch_context=None, metadata_={}, step_history=[]).success
FAILED tests/e2e/test_golden_transcript_agentic_loop.py::test_golden_transcript_agentic_loop - AssertionError: assert 'running' == 'paused'
  
  - paused
  + running
FAILED tests/e2e/test_golden_transcript_dynamic_parallel.py::test_golden_transcript_dynamic_parallel - AssertionError: assert 0 == 1
 +  where 0 = len([])
 +    where [] = DynamicParallelContext(run_id='run_71544287e21444619b5007f72e0f376b', initial_prompt='test', scratchpad={'status': 'running'}, hitl_history=[], command_log=[], executed_branches=[], branch_results={}, total_failures=0).executed_branches
FAILED tests/integration/test_fsd_12_tracing_complete.py::TestFSD12TracingComplete::test_trace_generation_and_persistence - assert None is not None
FAILED tests/integration/test_fsd_12_tracing_complete.py::TestFSD12TracingComplete::test_trace_persistence_recovery - assert None is not None
FAILED tests/integration/test_fsd_12_tracing_complete.py::TestFSD12TracingComplete::test_trace_large_pipeline - assert None is not None
FAILED tests/integration/test_legacy_cleanup_validation.py::TestLegacyCleanupSafety::test_error_handling_preserved - assert False
 +  where False = any(<generator object TestLegacyCleanupSafety.test_error_handling_preserved.<locals>.<genexpr> at 0x10cf24660>)
FAILED tests/integration/test_loop_context_update_regression.py::test_regression_performance_under_load - AssertionError: assert False is True
 +  where False = RegressionTestContext(run_id='run_642a0736d22549ffa78305700c5c0dca', initial_prompt='test', scratchpad={'status': 'running'}, hitl_history=[], command_log=[], iteration_count=2, accumulated_value=2, is_complete=False, debug_data={'performance_item_1_0': 0, 'performance_item_1_1': 1, 'performance_item_1_2': 2, 'performance_item_1_3': 3, 'performance_item_1_4': 4, 'performance_item_1_5': 5, 'performance_item_1_6': 6, 'performance_item_1_7': 7, 'performance_item_1_8': 8, 'performance_item_1_9': 9, 'performance_item_1_10': 10, 'performance_item_1_11': 11, 'performance_item_1_12': 12, 'performance_item_1_13': 13, 'performance_item_1_14': 14, 'performance_item_1_15': 15, 'performance_item_1_16': 16, 'performance_item_1_17': 17, 'performance_item_1_18': 18, 'performance_item_1_19': 19, 'performance_item_1_20': 20, 'performance_item_1_21': 21, 'performance_item_1_22': 22, 'performance_item_1_23': 23, 'performance_item_1_24': 24, 'performance_item_1_25': 25, 'performance_item_1_26': 26, 'performance_item_1_27': 27, 'performance_item_1_28': 28, 'performance_item_1_29': 29, 'performance_item_1_30': 30, 'performance_item_1_31': 31, 'performance_item_1_32': 32, 'performance_item_1_33': 33, 'p...ce_item_2_961': 961, 'performance_item_2_962': 962, 'performance_item_2_963': 963, 'performance_item_2_964': 964, 'performance_item_2_965': 965, 'performance_item_2_966': 966, 'performance_item_2_967': 967, 'performance_item_2_968': 968, 'performance_item_2_969': 969, 'performance_item_2_970': 970, 'performance_item_2_971': 971, 'performance_item_2_972': 972, 'performance_item_2_973': 973, 'performance_item_2_974': 974, 'performance_item_2_975': 975, 'performance_item_2_976': 976, 'performance_item_2_977': 977, 'performance_item_2_978': 978, 'performance_item_2_979': 979, 'performance_item_2_980': 980, 'performance_item_2_981': 981, 'performance_item_2_982': 982, 'performance_item_2_983': 983, 'performance_item_2_984': 984, 'performance_item_2_985': 985, 'performance_item_2_986': 986, 'performance_item_2_987': 987, 'performance_item_2_988': 988, 'performance_item_2_989': 989, 'performance_item_2_990': 990, 'performance_item_2_991': 991, 'performance_item_2_992': 992, 'performance_item_2_993': 993, 'performance_item_2_994': 994, 'performance_item_2_995': 995, 'performance_item_2_996': 996, 'performance_item_2_997': 997, 'performance_item_2_998': 998, 'performance_item_2_999': 999}).is_complete
FAILED tests/integration/test_loop_step_execution.py::test_loop_step_body_failure_with_robust_exit_condition - AssertionError: assert 'last iteration body failed' in (('Plugin failed: bad'))
 +  where 'Plugin failed: bad' = StepResult(name='loop_body_fail', output='oops', success=False, attempts=1, latency_s=0.000313415948767215, token_counts=1, cost_usd=0.0, feedback='Plugin failed: bad', branch_context=PipelineContext(run_id='run_fe405fefb32f498ca6433132d2d20813', initial_prompt='in', scratchpad={'status': 'running'}, hitl_history=[], command_log=[]), metadata_={'iterations': 1, 'exit_reason': 'body_failure'}, step_history=[]).feedback
FAILED tests/integration/test_loop_step_execution.py::test_loop_step_body_failure_causing_exit_condition_error - AssertionError: assert 'exception' in 'plugin failed: bad'
 +  where 'plugin failed: bad' = <built-in method lower of str object at 0x10d191c50>()
 +    where <built-in method lower of str object at 0x10d191c50> = ('Plugin failed: bad').lower
 +      where 'Plugin failed: bad' = StepResult(name='loop_exit_err', output={}, success=False, attempts=1, latency_s=0.00045204098569229245, token_counts=0, cost_usd=0.0, feedback='Plugin failed: bad', branch_context=PipelineContext(run_id='run_40b3b98c8bc2457bb5c42822dd874431', initial_prompt='in', scratchpad={'status': 'running'}, hitl_history=[], command_log=[]), metadata_={'iterations': 1, 'exit_reason': 'body_failure'}, step_history=[]).feedback
FAILED tests/integration/test_loop_step_execution.py::test_loop_step_error_logging_in_callables - assert False
 +  where False = any(<generator object test_loop_step_error_logging_in_callables.<locals>.<genexpr> at 0x10d1ad3c0>)
FAILED tests/integration/test_loop_with_context_updates.py::test_loop_with_context_updates_complex - AssertionError: assert False is True
 +  where False = StepResult(name='complex_loop', output={'should_exit': False, 'exit_reason': ''}, success=False, attempts=10, latency_s=0.0021302920067682862, token_counts=0, cost_usd=0.0, feedback='max_loops exceeded', branch_context=LoopContext(run_id='run_49f99675c6274443a7d08327ebbe69c7', initial_prompt='test', scratchpad={'status': 'running'}, hitl_history=[], command_log=[], iteration_count=2, accumulated_value=4, loop_exit_reason='', final_state={}), metadata_={'iterations': 10, 'exit_reason': 'max_loops'}, step_history=[]).success
FAILED tests/integration/test_loop_with_context_updates.py::test_loop_with_context_updates_error_handling - AssertionError: assert False is True
 +  where False = StepResult(name='error_loop', output=None, success=False, attempts=2, latency_s=0.0019737090333364904, token_counts=0, cost_usd=0.0, feedback='Agent execution failed with RuntimeError: Intentional failure', branch_context=LoopContext(run_id='run_c91e20f68d7645b39ec5b877fa6f1469', initial_prompt='test', scratchpad={'status': 'running'}, hitl_history=[], command_log=[], iteration_count=3, accumulated_value=0, loop_exit_reason='', final_state={}), metadata_={'iterations': 2, 'exit_reason': 'body_failure'}, step_history=[]).success
========== 116 failed, 2126 passed, 8 skipped, 12 warnings in 37.94s ===========
