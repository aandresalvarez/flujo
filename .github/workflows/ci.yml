# .github/workflows/ci.yml
# Continuous Integration workflow for the Flujo project.
#
# Dependency Management:
# - Uses uv sync --extra dev --extra templating --extra skills --extra aop-extras to ensure all dependencies are installed
# - Includes prometheus-client and httpx for comprehensive testing
# - All dependencies are properly declared in pyproject.toml

name: Flujo CI

on:
  push:
    branches: [ "main" ]
    tags: [ "v*" ]
  # Note: Pull requests are handled by pr-checks.yml for faster feedback

# Global environment to keep installs deterministic and isolated per job
env:
  UV_VERSION: "0.4.24"
  UV_LINK_MODE: copy
  # Note: UV_CACHE_DIR uses workspace-relative path since runner context unavailable at workflow level
  UV_CACHE_DIR: .uv-cache
  PYTHONHASHSEED: "0"
  PYTEST_RANDOMLY_SEED: "1"
  OMP_NUM_THREADS: "1"
  MKL_NUM_THREADS: "1"

# Cancel any in-progress jobs for the same PR/branch when new commits are pushed.
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ----------------------------------------------------------------------------
  # Job 1: Linting and Static Type Checking
  # ----------------------------------------------------------------------------
  lint-and-typecheck:
    name: Lint & Typecheck
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Set up uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --extra templating --extra skills --extra aop-extras --extra opentelemetry

      - name: Run Linter
        run: make lint

      - name: Run Type Checker
        run: make typecheck-fast

  # ----------------------------------------------------------------------------
  # Job 2: Run Fast Tests (Parallel) - Quick Feedback
  # ----------------------------------------------------------------------------
  test-fast:
    name: Fast Tests (Parallel)
    runs-on: ubuntu-latest
    needs: lint-and-typecheck
    strategy:
      fail-fast: true
      matrix:
        python-version: ["3.13", "3.14"]
        shard: [0, 1]
    env:
      CI: "true"
      FLUJO_CLI_PERF_THRESHOLD: "0.2"
      FLUJO_CV_THRESHOLD: "1.0"
      FLUJO_CI_DB_SIZE: "250"  # Optimized database size for mass CI (was 500)
      SHARD_COUNT: "2"
      # Limit xdist workers on 3.14 to reduce memory pressure and runner shutdowns.
      PYTEST_XDIST_AUTO_NUM_WORKERS: ${{ matrix.python-version == '3.14' && '1' || '2' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          allow-prereleases: ${{ matrix.python-version == '3.14' }}

      - name: Set up uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --extra templating --extra skills --extra aop-extras

      - name: Set dummy OpenAI API key for tests
        run: echo "OPENAI_API_KEY=dummy-key" >> $GITHUB_ENV

      - name: Run fast tests (sharded)
        run: |
          make test-shard-fast \
            SHARD_INDEX=${{ matrix.shard }} \
            SHARD_COUNT=${{ env.SHARD_COUNT }} \
            COVERAGE=1 \
            COVERAGE_FILE=.coverage.fast-${{ matrix.python-version }}-${{ matrix.shard }}

      - name: Store fast tests coverage file
        uses: actions/upload-artifact@v4
        with:
          name: coverage-fast-${{ matrix.python-version }}-${{ matrix.shard }}
          path: .coverage.*
          if-no-files-found: ignore

      - name: Check for stray xdist flags
        run: |
          # Check for pytest xdist parallel execution flags outside allowed locations
          # Allowed: CI workflows, Makefile, Documentation
          # The pattern uses a variable to avoid self-matching
          PATTERN='pytest[^\n]*\s-+n'
          if git grep -nE "$PATTERN" -- ':!**/.github/workflows/*' ':!Makefile' ':!**/Makefile' ':!docs/**'; then
            echo 'pytest xdist flags detected outside CI workflows and Makefile';
            exit 1;
          fi

  # ----------------------------------------------------------------------------
  # Job 3: Run Slow Tests (Serial) - Comprehensive Testing
  # ----------------------------------------------------------------------------
  test-slow:
    name: Slow Tests (Serial)
    runs-on: ubuntu-latest
    needs: lint-and-typecheck
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.13"]  # Only run slow tests on one Python version
    env:
      CI: "true"
      FLUJO_CLI_PERF_THRESHOLD: "0.2"
      FLUJO_CV_THRESHOLD: "1.0"
      FLUJO_CI_DB_SIZE: "250"  # Optimized database size for mass CI (was 1000)
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Set up uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --extra templating --extra skills --extra aop-extras

      - name: Set dummy OpenAI API key for tests
        run: echo "OPENAI_API_KEY=dummy-key" >> $GITHUB_ENV

      - name: Run slow tests with coverage
        run: |
          # Run slow tests serially with coverage (-n 0 ensures no parallel execution)
          # This includes HITL, SQLite-backed, and benchmark tests that need isolation
          uv run coverage run --source=flujo --parallel-mode -m pytest tests/ -m "slow or veryslow or serial or benchmark" -n 0 --randomly-seed=${PYTEST_RANDOMLY_SEED}

          # Run the comprehensive golden transcript tests (also serial)
          uv run coverage run --source=flujo --parallel-mode -m pytest tests/e2e/test_golden_transcript_*.py -n 0 --randomly-seed=${PYTEST_RANDOMLY_SEED}

      - name: Combine coverage data
        run: |
          # Combine parallel coverage files into a single .coverage file
          uv run coverage combine || true
          # Rename to unique name for artifact upload
          if [ -f .coverage ]; then
            mv .coverage .coverage.slow-${{ matrix.python-version }}
          fi

      - name: Store slow tests coverage file
        uses: actions/upload-artifact@v4
        with:
          name: coverage-slow-${{ matrix.python-version }}
          path: .coverage.*
          if-no-files-found: ignore

  # ----------------------------------------------------------------------------
  # Job 5: Combine and Report Code Coverage
  # ----------------------------------------------------------------------------
  coverage:
    name: Report Coverage
    runs-on: ubuntu-latest
    needs: [test-fast, test-slow]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Set up uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --extra templating --extra skills --extra aop-extras

      - name: Download coverage data
        uses: actions/download-artifact@v4
        with:
          path: .
          pattern: coverage-*
          merge-multiple: true

      - name: Combine coverage reports and check threshold
        run: |
          if ls .coverage.* 1> /dev/null 2>&1; then
            uv run coverage combine
            uv run coverage report --fail-under=90
            uv run coverage xml
            uv run coverage html
          else
            echo "No data to report."
          fi

      - name: Upload coverage report as artifact
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-html
          path: htmlcov

  # ----------------------------------------------------------------------------
  # Job 6a: Behavioral Evals (Deterministic Golden Cases)
  # ----------------------------------------------------------------------------
  behavioral-evals:
    name: Behavioral Evals
    runs-on: ubuntu-latest
    needs: lint-and-typecheck
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Set up uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --extra templating --extra skills --extra aop-extras

      - name: Run behavioral evals (serial)
        run: uv run pytest tests/evals/test_behavioral_golden.py -n 0 --randomly-seed=${PYTEST_RANDOMLY_SEED}

  # ----------------------------------------------------------------------------
  # Job 6b: Packaging & Release Smoke
  # ----------------------------------------------------------------------------
  packaging-smoke:
    name: Packaging & Import Smoke
    runs-on: ubuntu-latest
    needs: lint-and-typecheck
    if: github.event_name == 'push'
    permissions:
      id-token: write  # Required for OIDC signing with Sigstore
      contents: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Set up uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --extra templating --extra skills --extra aop-extras

      - name: Build distributions
        run: uv build

      - name: Dependency integrity check
        run: uv run python -m pip check

      - name: Import smoke test
        run: |
          uv run python - <<'PY'
          import flujo
          print("Imported flujo version", getattr(flujo, "__version__", "unknown"))
          PY

      - name: CLI smoke test
        run: |
          uv run flujo --help >/dev/null
          # Minimal non-network run: use echo piped input to avoid prompts
          echo "smoke" | uv run flujo run --input - --max-steps 1 --retries 0 || true

      - name: Generate checksums
        run: |
          cd dist
          shasum -a 256 * > SHA256SUMS
          cat SHA256SUMS
          cd -

      - name: Generate SBOM (CycloneDX via pip-audit)
        if: startsWith(github.ref, 'refs/tags/v')
        run: |
          # Upgrade pip to fix GHSA-4xh5-x5gv-qwph vulnerability
          uv run python -m pip install --upgrade pip
          uv run pip-audit --format cyclonedx-json --output sbom.json

      - name: Sign artifacts (Sigstore)
        if: startsWith(github.ref, 'refs/tags/v')
        env:
          COSIGN_EXPERIMENTAL: "1"
        run: |
          pip install sigstore==4.2.0
          for f in dist/*; do
            sigstore sign --yes "$f" --output-signature "$f.sig" --output-certificate "$f.crt"
          done

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-artifacts
          path: dist

      - name: Upload SBOM artifact
        if: startsWith(github.ref, 'refs/tags/v')
        uses: actions/upload-artifact@v4
        with:
          name: sbom
          path: sbom.json

      - name: Publish release assets
        if: startsWith(github.ref, 'refs/tags/v')
        uses: softprops/action-gh-release@v2
        with:
          files: |
            dist/**
            sbom.json
            dist/SHA256SUMS
            dist/*.sig
            dist/*.crt
            dist/SHA256SUMS

  # ----------------------------------------------------------------------------
  # Job 6: Performance Analysis (Optional)
  # ----------------------------------------------------------------------------
  test-performance:
    name: Performance Analysis
    runs-on: ubuntu-latest
    needs: lint-and-typecheck
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.13"]
    env:
      FLUJO_PERF_TARGET: tests/unit
      FLUJO_PERF_MARKERS: not slow and not serial and not benchmark
      FLUJO_PERF_TIMEOUT: "1200"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Set up uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --extra templating --extra skills --extra aop-extras

      - name: Set dummy OpenAI API key for tests
        run: echo "OPENAI_API_KEY=dummy-key" >> $GITHUB_ENV

      - name: Run performance analysis
        run: make test-perf

      - name: Upload performance report
        uses: actions/upload-artifact@v4
        with:
          name: performance-report
          path: test_performance_report.json

      - name: Upload raw performance log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-raw-log
          path: test_performance_raw.log

  # ----------------------------------------------------------------------------
  # Job 7: Ultra-Slow Tests (>30s, excluded from regular CI)
  # ----------------------------------------------------------------------------
  test-ultra-slow:
    name: Ultra-Slow Tests (>30s)
    runs-on: ubuntu-latest
    needs: lint-and-typecheck
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.13"]
    env:
      CI: "true"
      FLUJO_CLI_PERF_THRESHOLD: "0.2"
      FLUJO_CV_THRESHOLD: "1.0"
      FLUJO_CI_DB_SIZE: "250"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Set up uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --extra templating --extra skills --extra aop-extras

      - name: Set dummy OpenAI API key for tests
        run: echo "OPENAI_API_KEY=dummy-key-for-testing" >> $GITHUB_ENV

      - name: Run ultra-slow tests
        run: |
          echo "‚ö†Ô∏è Running ultra-slow tests (>30s each)"
          echo "These tests are excluded from regular CI due to long execution time"
          make test-ultra-slow

  # ----------------------------------------------------------------------------
  # Job 8: Flake Detection (Optional - runs on main only)
  # ----------------------------------------------------------------------------
  # Runs tests multiple times with different random seeds to catch flaky tests
  # before they cause "passes in PR, fails in main" scenarios.
  flake-detection:
    name: Flake Detection
    runs-on: ubuntu-latest
    needs: lint-and-typecheck
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    continue-on-error: true  # Don't fail the build, just report
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.13"]
    env:
      CI: "true"
      FLUJO_CLI_PERF_THRESHOLD: "0.2"
      FLUJO_CV_THRESHOLD: "1.0"
      FLUJO_CI_DB_SIZE: "250"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Set up uv
        uses: astral-sh/setup-uv@v1
        with:
          enable-cache: true
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: uv sync --extra dev --extra templating --extra skills --extra aop-extras

      - name: Set dummy OpenAI API key for tests
        run: echo "OPENAI_API_KEY=dummy-key" >> $GITHUB_ENV

      - name: Run tests 3x with different random seeds
        run: |
          echo "üîç Running flake detection (3 runs with different seeds)"
          FAILED=0
          for seed in 42 123 999; do
            echo ""
            echo "=========================================="
            echo "Run with seed $seed"
            echo "=========================================="
            if ! uv run pytest tests/ -m "not slow and not serial and not benchmark" -n 2 -p randomly --randomly-seed=$seed -q; then
              echo "‚ùå Failed with seed $seed"
              FAILED=1
            else
              echo "‚úÖ Passed with seed $seed"
            fi
          done
          if [ $FAILED -eq 1 ]; then
            echo ""
            echo "‚ö†Ô∏è Flaky tests detected! Some runs failed with different seeds."
            echo "Review the logs above to identify which tests are flaky."
            exit 1
          fi
          echo ""
          echo "‚úÖ All 3 runs passed - no obvious flakiness detected"

  # ----------------------------------------------------------------------------
  # Job 9: Live API Tests (Optional but Recommended)
  # ----------------------------------------------------------------------------
  # This job is a placeholder for a critical testing practice.
  # To enable it, you would need to:
  # 1. Create live tests in a separate directory (e.g., tests/live/).
  # 2. Add API key secrets to your GitHub repository settings.
  # 3. Uncomment this job.
  # test-live:
  #   name: Live API Tests
  #   runs-on: ubuntu-latest
  #   if: github.event_name == 'push' && github.ref == 'refs/heads/main'
  #   steps:
  #     - uses: actions/checkout@v4
  #     - uses: astral-sh/setup-uv@v1
  #     - name: Install dependencies
  #       run: uv sync --extra dev --extra templating --extra skills --extra aop-extras
  #     - name: Run live tests
  #       run: uv run pytest tests/live/
  #       env:
  #         OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  #         GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
  #         ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
